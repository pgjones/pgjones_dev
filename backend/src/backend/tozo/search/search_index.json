{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"The aim of this book is to build an app and run it in a production environment so that you can do the same. We'll build an app packed full of features that you can use in your app, and a few todo features as the app will need to do something. I've built the app described in this book, and it is running at tozo.dev with the code available here . I'm going to start by assuming you have no tooling installed but that you have a working knowledge of Typescript and Python . If you know more I'd just skip ahead to any of the sections that interest you, if you know less I'd seek to learn the basics of these languages first. Aims Whilst you are building an app to solve your customers' specific problems many of the techniques will be the same as in the app built here; for example, users will need to login, change their password etc regardless. Therefore the todo app built in this book will utilise as many of the techniques I'd expect you to need for your own app. Tech Choices It should be noted that many/most of the choices made are my personal preferences and that there are equally good alternatives. You can either follow me or take the parts that interest you. As mentioned above I'm starting by assuming you have a working knowledge of Typescript and Python i.e. you can follow along with code snippets in these languages. Typescript We will want our app to run in the browser, which means whatever language we choose it will need to compile to Javascript to run. To me Typescript is Javascript with additional type safety, which makes it an easy choice as I like Javascript and I find the type safety very helpful. Python + typing For the parts of the app that run on the server we have a much wider choice of languages. I'm very familiar with, and contribute to, Python so it is the obvious choice for me. As with Typescript though I find the additional type safety from Python's type hinting really helpful, so we'll use that as well. Naming the app You'll hear that naming things is hard, and naming is this app is no different. An early draft of this book called the app project which was a little to generic and boring. Therefore tozo is our new name (from a combination of todo and zero to production).","title":"Introduction"},{"location":"#aims","text":"Whilst you are building an app to solve your customers' specific problems many of the techniques will be the same as in the app built here; for example, users will need to login, change their password etc regardless. Therefore the todo app built in this book will utilise as many of the techniques I'd expect you to need for your own app.","title":"Aims"},{"location":"#tech-choices","text":"It should be noted that many/most of the choices made are my personal preferences and that there are equally good alternatives. You can either follow me or take the parts that interest you. As mentioned above I'm starting by assuming you have a working knowledge of Typescript and Python i.e. you can follow along with code snippets in these languages.","title":"Tech Choices"},{"location":"#typescript","text":"We will want our app to run in the browser, which means whatever language we choose it will need to compile to Javascript to run. To me Typescript is Javascript with additional type safety, which makes it an easy choice as I like Javascript and I find the type safety very helpful.","title":"Typescript"},{"location":"#python-typing","text":"For the parts of the app that run on the server we have a much wider choice of languages. I'm very familiar with, and contribute to, Python so it is the obvious choice for me. As with Typescript though I find the additional type safety from Python's type hinting really helpful, so we'll use that as well.","title":"Python + typing"},{"location":"#naming-the-app","text":"You'll hear that naming things is hard, and naming is this app is no different. An early draft of this book called the app project which was a little to generic and boring. Therefore tozo is our new name (from a combination of todo and zero to production).","title":"Naming the app"},{"location":"forward/","text":"This is the tech and tech stack I developed starting my own startup. My aim was to build high quality apps as quickly as possible in the languages and tooling I was familiar with. I'm hoping this proves to be a useful resource to junior engineers to see how a complete and deployed production app is developed. Ideally this will take a begineer from nothing to their own production app.","title":"Forward"},{"location":"under_construction/","text":"This page is under construction, please check back again soon. The source code for this book is available here .","title":"NVM"},{"location":"backend/aims/","text":"This project is to build a todo app that stores and allows editing of a user's todos. Therefore the backend needs to provide an API to Create, Read, Update, and Delete (CRUD) TODOs, Allow users to register, and delete accounts, Authenticate users, including login (including multi-factor authentication), logout, change and reset passwords, Serve the frontend Single Page App (SPA), Serve HTTP to HTTPS redirects to serve only over HTTPS. Tech choices To do all this I choose to use Quart as the base framework with various Quart-extensions to provide extra functionality. Quart is the Flask API re-implemented using async/await which I know it very well as I'm the Quart author. Alternatively you can adapt the code in this book to use Flask and Flask-extensions without too much difficulty.","title":"Backend aims"},{"location":"backend/aims/#tech-choices","text":"To do all this I choose to use Quart as the base framework with various Quart-extensions to provide extra functionality. Quart is the Flask API re-implemented using async/await which I know it very well as I'm the Quart author. Alternatively you can adapt the code in this book to use Flask and Flask-extensions without too much difficulty.","title":"Tech choices"},{"location":"backend/authentication-api/","text":"The session (authentication) API will need to provide routes to login and logout i.e. to create and delete sessions. Login should result in a cookie being set, and logout result in the cookie being deleted. As per the authentication setup, login should require an email and matching password. Creating the blueprint The blueprint itself can be created with the following code in backend/src/backend/blueprints/sessions.py , from quart import Blueprint blueprint = Blueprint ( \"sessions\" , __name__ ) and activated by adding the following to backend/src/backend/run.py , from backend.blueprints.sessions import blueprint as sessions_blueprint def create_app () -> Quart : ... app . register_blueprint ( sessions_blueprint ) Login For a RESTful API the session login (creation) route should be POST, expecting an email, password and remember flag returning 200 on success and 401 on invalid credentials. We'll need to rate limit the route to prevent malicious actors brute forcing the login and ensure that username enumeration is not possible. The following should be added to backend/src/backend/blueprints/sessions.py , from dataclasses import dataclass from datetime import timedelta import bcrypt from quart import current_app , ResponseReturnValue from quart_auth import AuthUser , login_user from quart_rate_limiter import rate_limit from quart_schema import validate_request from backend.lib.api_error import APIError from backend.models.member import select_member_by_email # Random characters valid bcrypt hash, for reference testing REFERENCE_HASH = \"$2b$12$VD7REWo6sjWiTF4T0QBOYumC0UAf/YIXZFvjkJNSixN7GBMmwC5rS\" @dataclass class LoginData : email : str password : str remember : bool = False @blueprint . post ( \"/sessions/\" ) @rate_limit ( 5 , timedelta ( minutes = 1 )) @validate_request ( LoginData ) async def login ( data : LoginData ) -> ResponseReturnValue : \"\"\"Login to the app. By providing credentials and then saving the returned cookie. \"\"\" result = await select_member_by_email ( current_app . db , data . email ) password_hash = REFERENCE_HASH if result is None else result . password_hash passwords_match = bcrypt . checkpw ( data . password . encode ( \"utf-8\" ), password_hash . encode ( \"utf-8\" ) ) if result is not None and passwords_match : login_user ( AuthUser ( str ( result . id )), data . remember ) return {}, 200 else : raise APIError ( 401 , \"INVALID_CREDENTIALS\" ) A key part is that checkpw is called even if there is no member with the given email . This is to mitigate malicious clients from attempting to enumerate the member's emails. Logout For a RESTful API the session logout (deletion) route should be DELETE, returning 200. The following should be merged (removing duplicated imports) to backend/src/backend/blueprints/sessions.py , from quart_auth import logout_user from quart_rate_limiter import rate_exempt @blueprint . delete ( \"/sessions/\" ) @rate_exempt async def logout () -> ResponseReturnValue : \"\"\"Logout from the app. Deletes the session cookie. \"\"\" logout_user () return {} Status It is useful to have a route that returns the current session (status). We'll use it for debugging and testing but it is likely to serve more purposes in your app. For a RESTful API this is should be a GET route, from quart_auth import current_user , login_required from quart_schema import validate_response @dataclass class Status : member_id : int @blueprint . get ( \"/sessions/\" ) @rate_limit ( 10 , timedelta ( minutes = 1 )) @login_required @validate_response ( Status ) async def status () -> ResponseReturnValue : return Status ( member_id = int ( current_user . auth_id )) Testing We should test that these routes work as a user would expect, starting with the login, get status, and then logout flow by adding the following to backend/tests/blueprints/test_sessions.py . import pytest from quart import Quart @pytest . mark . asyncio async def test_session_flow ( app : Quart ) -> None : test_client = app . test_client () await test_client . post ( \"/sessions/\" , json = { \"email\" : \"test@tozo.invalid\" , \"password\" : \"password\" }, ) response = await test_client . get ( \"/sessions/\" ) assert ( await response . get_json ())[ \"memberId\" ] == 1 await test_client . delete ( \"/sessions/\" ) response = await test_client . get ( \"/sessions/\" ) assert response . status_code == 401 In addition lets ensure that the crucial checkpw is called even for emails that aren't registered by adding, from unittest.mock import Mock import bcrypt from _pytest.monkeypatch import MonkeyPatch @pytest . mark . asyncio async def test_checkpw_called ( app : Quart , monkeypatch : MonkeyPatch ) -> None : checkpw_mock = Mock () monkeypatch . setattr ( bcrypt , \"checkpw\" , checkpw_mock ) test_client = app . test_client () await test_client . post ( \"/sessions/\" , json = { \"email\" : \"not-registered@tozo.invalid\" , \"password\" : \"password\" }, ) checkpw_mock . assert_called ()","title":"Login/Logout (Sessions)"},{"location":"backend/authentication-api/#creating-the-blueprint","text":"The blueprint itself can be created with the following code in backend/src/backend/blueprints/sessions.py , from quart import Blueprint blueprint = Blueprint ( \"sessions\" , __name__ ) and activated by adding the following to backend/src/backend/run.py , from backend.blueprints.sessions import blueprint as sessions_blueprint def create_app () -> Quart : ... app . register_blueprint ( sessions_blueprint )","title":"Creating the blueprint"},{"location":"backend/authentication-api/#login","text":"For a RESTful API the session login (creation) route should be POST, expecting an email, password and remember flag returning 200 on success and 401 on invalid credentials. We'll need to rate limit the route to prevent malicious actors brute forcing the login and ensure that username enumeration is not possible. The following should be added to backend/src/backend/blueprints/sessions.py , from dataclasses import dataclass from datetime import timedelta import bcrypt from quart import current_app , ResponseReturnValue from quart_auth import AuthUser , login_user from quart_rate_limiter import rate_limit from quart_schema import validate_request from backend.lib.api_error import APIError from backend.models.member import select_member_by_email # Random characters valid bcrypt hash, for reference testing REFERENCE_HASH = \"$2b$12$VD7REWo6sjWiTF4T0QBOYumC0UAf/YIXZFvjkJNSixN7GBMmwC5rS\" @dataclass class LoginData : email : str password : str remember : bool = False @blueprint . post ( \"/sessions/\" ) @rate_limit ( 5 , timedelta ( minutes = 1 )) @validate_request ( LoginData ) async def login ( data : LoginData ) -> ResponseReturnValue : \"\"\"Login to the app. By providing credentials and then saving the returned cookie. \"\"\" result = await select_member_by_email ( current_app . db , data . email ) password_hash = REFERENCE_HASH if result is None else result . password_hash passwords_match = bcrypt . checkpw ( data . password . encode ( \"utf-8\" ), password_hash . encode ( \"utf-8\" ) ) if result is not None and passwords_match : login_user ( AuthUser ( str ( result . id )), data . remember ) return {}, 200 else : raise APIError ( 401 , \"INVALID_CREDENTIALS\" ) A key part is that checkpw is called even if there is no member with the given email . This is to mitigate malicious clients from attempting to enumerate the member's emails.","title":"Login"},{"location":"backend/authentication-api/#logout","text":"For a RESTful API the session logout (deletion) route should be DELETE, returning 200. The following should be merged (removing duplicated imports) to backend/src/backend/blueprints/sessions.py , from quart_auth import logout_user from quart_rate_limiter import rate_exempt @blueprint . delete ( \"/sessions/\" ) @rate_exempt async def logout () -> ResponseReturnValue : \"\"\"Logout from the app. Deletes the session cookie. \"\"\" logout_user () return {}","title":"Logout"},{"location":"backend/authentication-api/#status","text":"It is useful to have a route that returns the current session (status). We'll use it for debugging and testing but it is likely to serve more purposes in your app. For a RESTful API this is should be a GET route, from quart_auth import current_user , login_required from quart_schema import validate_response @dataclass class Status : member_id : int @blueprint . get ( \"/sessions/\" ) @rate_limit ( 10 , timedelta ( minutes = 1 )) @login_required @validate_response ( Status ) async def status () -> ResponseReturnValue : return Status ( member_id = int ( current_user . auth_id ))","title":"Status"},{"location":"backend/authentication-api/#testing","text":"We should test that these routes work as a user would expect, starting with the login, get status, and then logout flow by adding the following to backend/tests/blueprints/test_sessions.py . import pytest from quart import Quart @pytest . mark . asyncio async def test_session_flow ( app : Quart ) -> None : test_client = app . test_client () await test_client . post ( \"/sessions/\" , json = { \"email\" : \"test@tozo.invalid\" , \"password\" : \"password\" }, ) response = await test_client . get ( \"/sessions/\" ) assert ( await response . get_json ())[ \"memberId\" ] == 1 await test_client . delete ( \"/sessions/\" ) response = await test_client . get ( \"/sessions/\" ) assert response . status_code == 401 In addition lets ensure that the crucial checkpw is called even for emails that aren't registered by adding, from unittest.mock import Mock import bcrypt from _pytest.monkeypatch import MonkeyPatch @pytest . mark . asyncio async def test_checkpw_called ( app : Quart , monkeypatch : MonkeyPatch ) -> None : checkpw_mock = Mock () monkeypatch . setattr ( bcrypt , \"checkpw\" , checkpw_mock ) test_client = app . test_client () await test_client . post ( \"/sessions/\" , json = { \"email\" : \"not-registered@tozo.invalid\" , \"password\" : \"password\" }, ) checkpw_mock . assert_called ()","title":"Testing"},{"location":"backend/authentication/","text":"Authentication is required to ensure that the client is who they claim to be, and for our project to ensure that each user only gets to see their own todos and only after they've proved they are the user. This is typically achieved by the user entering a username and password which are then checked against stored versions. We will need to authenticate every request the user makes to the backend, however we ideally only want the user to enter their username and password once (until they logout). We can acheive this by saving information to a cookie when the user logs in, as the browser will then send us the cookie with every request. Cookie session storage We will need to save a piece of identifying information to the cookie when the user logs in (starts a session), for example a user ID. We can then read the cookie on every request and identify which user it is. However, cookies can be edited, or faked, by the client so we need to ensure that the information in the cookie hasn't been tampered with. We can prevent tampering by signing the information in the cookie. Signing is where a cryptographic function is applied to the data using a secret key to create a signature. This signature is then stored with the data, allowing the stored signature to be checked against a recalculated version. Quart-Auth can be used to manage the cookies. Quart-Auth will sign the data, and ensure that the cookies are securely stored in the browser. poetry add quart-auth Then by activating the AuthManager when creating the app in backend/src/backend/run.py from quart_auth import AuthManager auth_manager = AuthManager () def create_app (): ... auth_manager . init_app ( app ) ... Password storage The user will log in by providing their email and password which we can check against a password we store when they create their account. This password must not be stored directly as if an attacker gains access to the database they likely gain the user's password to many other websites. Therefore instead of the password a hash of the password is calculated and stored. bcrypt is a great library to hash passwords. It can be installed, poetry add bcrypt JSON error responses User attempts to access login_required routes without valid credentials result in an Unauthorized exception being raised. This by default results in a HTML response, whereas we need a standardised JSON based response. We can achieve this via an error handler by adding the following to backend/src/backend/run.py , ... from werkzeug.exceptions import Unauthorized def create_app () -> Quart : ... @app . errorhandler ( Unauthorized ) async def handle_unauthorized ( _ : Unauthorized ) -> ResponseReturnValue : return { \"code\" : \"UNAUTHORIZED\" }, 401 Signed tokens We'll want to send links to users that they can use to prove they are a certain user, for example to change a forgotten password. We can do this by including a token that identifies the user in the link. To create the token we can sign the user's ID using a cryptographic hash function, secret key, and salt. This will ensure that a malicious user cannot alter the token without generating a correct signature, which requires our secret key. To do this we can use itsdangerous , which is installed via poetry, poetry add itsdangerous The downside to this approach is that users will be able to read anything we place in the token. It is important therefore not to put anything sensitive in the token (the user ID is not sensitive). Note We should ensure we use a different salt for each token flow so that a malicious user cannot use a token generated for one flow in another. We should also encode the date the token was generated and reject tokens that are too old, as this will protect users if a malicious user gets hold of old emails/tokens.","title":"Authentication"},{"location":"backend/authentication/#cookie-session-storage","text":"We will need to save a piece of identifying information to the cookie when the user logs in (starts a session), for example a user ID. We can then read the cookie on every request and identify which user it is. However, cookies can be edited, or faked, by the client so we need to ensure that the information in the cookie hasn't been tampered with. We can prevent tampering by signing the information in the cookie. Signing is where a cryptographic function is applied to the data using a secret key to create a signature. This signature is then stored with the data, allowing the stored signature to be checked against a recalculated version. Quart-Auth can be used to manage the cookies. Quart-Auth will sign the data, and ensure that the cookies are securely stored in the browser. poetry add quart-auth Then by activating the AuthManager when creating the app in backend/src/backend/run.py from quart_auth import AuthManager auth_manager = AuthManager () def create_app (): ... auth_manager . init_app ( app ) ...","title":"Cookie session storage"},{"location":"backend/authentication/#password-storage","text":"The user will log in by providing their email and password which we can check against a password we store when they create their account. This password must not be stored directly as if an attacker gains access to the database they likely gain the user's password to many other websites. Therefore instead of the password a hash of the password is calculated and stored. bcrypt is a great library to hash passwords. It can be installed, poetry add bcrypt","title":"Password storage"},{"location":"backend/authentication/#json-error-responses","text":"User attempts to access login_required routes without valid credentials result in an Unauthorized exception being raised. This by default results in a HTML response, whereas we need a standardised JSON based response. We can achieve this via an error handler by adding the following to backend/src/backend/run.py , ... from werkzeug.exceptions import Unauthorized def create_app () -> Quart : ... @app . errorhandler ( Unauthorized ) async def handle_unauthorized ( _ : Unauthorized ) -> ResponseReturnValue : return { \"code\" : \"UNAUTHORIZED\" }, 401","title":"JSON error responses"},{"location":"backend/authentication/#signed-tokens","text":"We'll want to send links to users that they can use to prove they are a certain user, for example to change a forgotten password. We can do this by including a token that identifies the user in the link. To create the token we can sign the user's ID using a cryptographic hash function, secret key, and salt. This will ensure that a malicious user cannot alter the token without generating a correct signature, which requires our secret key. To do this we can use itsdangerous , which is installed via poetry, poetry add itsdangerous The downside to this approach is that users will be able to read anything we place in the token. It is important therefore not to put anything sensitive in the token (the user ID is not sensitive). Note We should ensure we use a different salt for each token flow so that a malicious user cannot use a token generated for one flow in another. We should also encode the date the token was generated and reject tokens that are too old, as this will protect users if a malicious user gets hold of old emails/tokens.","title":"Signed tokens"},{"location":"backend/basic/","text":"To begin it makes sense to setup a basic API that responds to pings (requests) with a pong. This firstly requires Quart as a (full) dependency, poetry add quart which installed Quart 0.14.1. For the basic setup we can add a simple ping route, which simply responses with pong when requested. I like to group routes like this into a control blueprint, by adding the following to backed/src/backend/blueprints/control.py , from quart import Blueprint , ResponseReturnValue blueprint = Blueprint ( \"control\" , __name__ ) @blueprint . route ( \"/control/ping/\" ) async def ping () -> ResponseReturnValue : return { \"ping\" : \"pong\" } and then the following to backed/src/backend/run.py to create the app using the factory pattern, from quart import Quart from backend.blueprints.control import blueprint as control_blueprint def create_app () -> Quart : app = Quart ( __name__ ) app . register_blueprint ( control_blueprint ) return app if __name__ == \"__main__\" : app = create_app () app . run () Note Using a Blueprint and the factory pattern to create the app will seem overly complex at this stage (it is ). As we are about to add a few blueprints and further testing though, this is worthwhile doing from the outset. For quick prototyping though I'd recommend the Quart quickstart (all in one file) setup. Now there is code to create the app with a ping route we should setup the tooling such that the server starts locally and serves requets. As with the backend tooling we need to add to backend/pyproject.toml , [tool.poetry.scripts] start = \"scripts:start\" ... and to backend/scripts.py def start () -> None : _check_call_quiet ([ \"python\" , \"src/backend/run.py\" ]) which allows, poetry run start to start our application. You can test it works manually using the curl tool, curl localhost:5000/control/ping/ or visiting localhost:5000/control/ping/ in your browser. Testing Lets test this route, first by setting up a test app fixture via this code in backend/tests/conftest.py , from typing import AsyncGenerator import pytest from quart import Quart from backend.run import create_app @pytest . fixture ( name = \"app\" , scope = \"function\" ) async def _app () -> AsyncGenerator [ Quart , None ]: app = create_app () async with app . test_app (): yield app which allows any test to accept an app argument set to the value yielded by this fixture. This allows a test in backend/tests/blueprints/test_control.py , import pytest from quart import Quart @pytest . mark . asyncio async def test_control ( app : Quart ) -> None : test_client = app . test_client () response = await test_client . get ( \"/control/ping/\" ) assert ( await response . get_json ())[ \"ping\" ] == \"pong\" Note It is quite common to mistakenly write, assert await response . get_json ()[ \"ping\" ] == \"pong\" which will fail with a coroutine cannot be indexed error as the coroutine returned by response.get_json() must be awaited before it is indexed. Full structure If you've setup the local backend tooling, and the basic API setup described here you should have this folder structure, tozo \u2514\u2500\u2500 backend \u251c\u2500\u2500 poetry.lock \u251c\u2500\u2500 pyproject.toml \u251c\u2500\u2500 scripts.py \u251c\u2500\u2500 setup.cfg \u251c\u2500\u2500 src \u2502 \u2514\u2500\u2500 backend \u2502 \u251c\u2500\u2500 blueprints \u2502 \u2502 \u251c\u2500\u2500 __init__.py \u2502 \u2502 \u2514\u2500\u2500 control.py \u2502 \u251c\u2500\u2500 __init__.py \u2502 \u2514\u2500\u2500 run.py \u2514\u2500\u2500 tests \u251c\u2500\u2500 blueprints \u2502 \u251c\u2500\u2500 __init__.py \u2502 \u2514\u2500\u2500 test_control.py \u251c\u2500\u2500 __init__.py \u2514\u2500\u2500 conftest.py Note The __init__.py files are empty, but exist to make the directories importable as python modules. Note The testing code is located in a folder structure that shadows the src structure as this helps locate the tests i.e. the tests for src / backend/blueprints/control.py are in tests / blueprints/test_control.py .","title":"Basic Quart app"},{"location":"backend/basic/#testing","text":"Lets test this route, first by setting up a test app fixture via this code in backend/tests/conftest.py , from typing import AsyncGenerator import pytest from quart import Quart from backend.run import create_app @pytest . fixture ( name = \"app\" , scope = \"function\" ) async def _app () -> AsyncGenerator [ Quart , None ]: app = create_app () async with app . test_app (): yield app which allows any test to accept an app argument set to the value yielded by this fixture. This allows a test in backend/tests/blueprints/test_control.py , import pytest from quart import Quart @pytest . mark . asyncio async def test_control ( app : Quart ) -> None : test_client = app . test_client () response = await test_client . get ( \"/control/ping/\" ) assert ( await response . get_json ())[ \"ping\" ] == \"pong\" Note It is quite common to mistakenly write, assert await response . get_json ()[ \"ping\" ] == \"pong\" which will fail with a coroutine cannot be indexed error as the coroutine returned by response.get_json() must be awaited before it is indexed.","title":"Testing"},{"location":"backend/basic/#full-structure","text":"If you've setup the local backend tooling, and the basic API setup described here you should have this folder structure, tozo \u2514\u2500\u2500 backend \u251c\u2500\u2500 poetry.lock \u251c\u2500\u2500 pyproject.toml \u251c\u2500\u2500 scripts.py \u251c\u2500\u2500 setup.cfg \u251c\u2500\u2500 src \u2502 \u2514\u2500\u2500 backend \u2502 \u251c\u2500\u2500 blueprints \u2502 \u2502 \u251c\u2500\u2500 __init__.py \u2502 \u2502 \u2514\u2500\u2500 control.py \u2502 \u251c\u2500\u2500 __init__.py \u2502 \u2514\u2500\u2500 run.py \u2514\u2500\u2500 tests \u251c\u2500\u2500 blueprints \u2502 \u251c\u2500\u2500 __init__.py \u2502 \u2514\u2500\u2500 test_control.py \u251c\u2500\u2500 __init__.py \u2514\u2500\u2500 conftest.py Note The __init__.py files are empty, but exist to make the directories importable as python modules. Note The testing code is located in a folder structure that shadows the src structure as this helps locate the tests i.e. the tests for src / backend/blueprints/control.py are in tests / blueprints/test_control.py .","title":"Full structure"},{"location":"backend/configuration/","text":"Configuration allows the app to run in multiple environments without having to alter the code. For example it makes sense to enable error tracking in production, but to disable it in local development (where errors are tracked in the console). It also allows secrets to be managed separately from the code, and hence more securely. I like to use environment variables to configure the app, with different values per environment. To load the environment python-dotenv can be used, which is installed with poetry, poetry add python-dotenv We have four environments we need consider, development, testing, ci, and production. Each will require different settings and so I manage the environments via backend/development.env , backend/test.env , backend/ci.env , and production environment variables - see LINK?? for the production setup. These environments are then loaded in the backend/scripts.py by adding the following, ... from dotenv import load_dotenv def start () -> None : load_dotenv ( \"development.env\" ) ... def test () -> None : load_dotenv ( \"test.env\" ) ... def test_ci () -> None : load_dotenv ( \"ci.env\" ) ... We can then utilise the environment variables in the app by loading them into the app's config during initialisation, import os from quart import Quart def create_app () -> Quart : app = Quart ( __name__ ) for key in [ \"BASE_URL\" , \"SECRET_KEY\" ]: app . config [ key ] = os . environ [ key ] ... with an initial configuration as given in the files, backend/development.env BASE_URL = \"http://localhost:3000\" SECRET_KEY = \"secret key\" backend/test.env BASE_URL = \"http://localhost:3000\" SECRET_KEY = \"secret key\" backend/ci.env BASE_URL = \"http://localhost:3000\" SECRET_KEY = \"secret key\"","title":"Configuration"},{"location":"backend/database-data/","text":"It is helpful when developing, and testing, to have consistent data available in the database. To do this set data can be added to the repository and loaded into the database as part of the setup. Loading the data We'll store the data as SQL queries in a specific data file which we'll load after the database migrations have run, but only if the all the migrations have been run i.e. we'll only load the data into an empty database. To load the data we'll use a environment variable DATABASE_DATA to indicate which data file to load (or not to if it isn't present) and add the following to backend/src/backend/lib/database.py , from typing import Optional async def create_database ( url : str , data_file : Optional [ str ]) -> Database : ... initial_migration = await _setup_schema ( db ) if initial_migration == - 1 and data_file is not None : await _load_database_data ( db , data_file ) return db async def _load_database_data ( db : Database , data_file : str ) -> None : with open ( data_file , \"r\" ) as file_ : for query in file_ . read () . split ( \";\" ): await db . execute ( query ) We also need to adapt the create_app function in src/backend/run.py as follows, def create_app () -> None : ... @app . before_serving async def startup () -> None : app . db = await create_database ( os . environ [ \"DATABASE_URL\" ], os . environ . get ( \"DATABASE_DATA\" ), ) This allows the data file location to be specified in the configuration, backend/development.env DATABASE_DATA = \"db/development_data.sql\" ... backend/test.env DATABASE_DATA = \"db/test_data.sql\" ... backend/ci.env DATABASE_DATA = \"db/test_data.sql\" ... Example data An example password hash can be created using bcrypt , bcrypt . hashpw ( b \"password\" , bcrypt . gensalt ( 14 )) which can be used to create development and testing data, backend/db/development_data.sql INSERT INTO members ( email , password_hash ) VALUES ( 'member@tozo.invalid' , '$2b$14$bziHHTsmQixWO30gBuNOGOiP6A1oSG97gOiDLyyJqmLUhUQE6aL96' ); INSERT INTO todos ( due , member_id , task ) VALUES ( now (), 1 , 'Task' ); backend/db/test_data.sql INSERT INTO members ( email , password_hash ) VALUES ( 'test@tozo.invalid' , '$2b$14$bziHHTsmQixWO30gBuNOGOiP6A1oSG97gOiDLyyJqmLUhUQE6aL96' ); INSERT INTO todos ( due , member_id , task ) VALUES ( now (), 1 , 'Task' );","title":"Database development & testing data"},{"location":"backend/database-data/#loading-the-data","text":"We'll store the data as SQL queries in a specific data file which we'll load after the database migrations have run, but only if the all the migrations have been run i.e. we'll only load the data into an empty database. To load the data we'll use a environment variable DATABASE_DATA to indicate which data file to load (or not to if it isn't present) and add the following to backend/src/backend/lib/database.py , from typing import Optional async def create_database ( url : str , data_file : Optional [ str ]) -> Database : ... initial_migration = await _setup_schema ( db ) if initial_migration == - 1 and data_file is not None : await _load_database_data ( db , data_file ) return db async def _load_database_data ( db : Database , data_file : str ) -> None : with open ( data_file , \"r\" ) as file_ : for query in file_ . read () . split ( \";\" ): await db . execute ( query ) We also need to adapt the create_app function in src/backend/run.py as follows, def create_app () -> None : ... @app . before_serving async def startup () -> None : app . db = await create_database ( os . environ [ \"DATABASE_URL\" ], os . environ . get ( \"DATABASE_DATA\" ), ) This allows the data file location to be specified in the configuration, backend/development.env DATABASE_DATA = \"db/development_data.sql\" ... backend/test.env DATABASE_DATA = \"db/test_data.sql\" ... backend/ci.env DATABASE_DATA = \"db/test_data.sql\" ...","title":"Loading the data"},{"location":"backend/database-data/#example-data","text":"An example password hash can be created using bcrypt , bcrypt . hashpw ( b \"password\" , bcrypt . gensalt ( 14 )) which can be used to create development and testing data, backend/db/development_data.sql INSERT INTO members ( email , password_hash ) VALUES ( 'member@tozo.invalid' , '$2b$14$bziHHTsmQixWO30gBuNOGOiP6A1oSG97gOiDLyyJqmLUhUQE6aL96' ); INSERT INTO todos ( due , member_id , task ) VALUES ( now (), 1 , 'Task' ); backend/db/test_data.sql INSERT INTO members ( email , password_hash ) VALUES ( 'test@tozo.invalid' , '$2b$14$bziHHTsmQixWO30gBuNOGOiP6A1oSG97gOiDLyyJqmLUhUQE6aL96' ); INSERT INTO todos ( due , member_id , task ) VALUES ( now (), 1 , 'Task' );","title":"Example data"},{"location":"backend/database-schema/","text":"Members table The members table stores the login credentials for the users that can use the app. The SQL to create this database is, CREATE TABLE members ( id SERIAL PRIMARY KEY , created TIMESTAMP NOT NULL DEFAULT now (), email TEXT NOT NULL , email_verified TIMESTAMP , password_hash TEXT NOT NULL ); CREATE UNIQUE INDEX members_unique_email_idx on members ( LOWER ( email )); The id , email , and password_hash columns are the minimum requirements for a login system. Note that a password hash and not the raw password should be stored. The created column is useful as it allows you to track user growth over time. The email_verified column indicates if the user has verified that they control the email, which is a crucial thing to check before sending the user emails. This could be a boolean, but storing the timestamp helps understand the user's actions. See a note with the models that explains why the unique index is used with LOWER . Todo table The todos table stores all the todos, linked to the user, CREATE TABLE todos ( id BIGSERIAL PRIMARY KEY , complete BOOLEAN NOT NULL DEFAULT FALSE , due TIMESTAMPTZ , member_id INT NOT NULL REFERENCES members ( id ), task TEXT NOT NULL ); Complete migration The initial setup of the database should be contained in backend/db/0.py , which should be, from databases import Database async def migrate ( db : Database ) -> None : await db . execute ( \"\"\"CREATE TABLE members( id SERIAL PRIMARY KEY, email TEXT UNIQUE NOT NULL, password TEXT NOT NULL ) \"\"\" , ) await db . execute ( \"\"\"CREATE TABLE todos( id BIGSERIAL PRIMARY KEY, complete BOOLEAN NOT NULL DEFAULT FALSE, due TIMESTAMPTZ, member_id INT NOT NULL UNIQUE REFERENCES members(id), task TEXT NOT NULL ); \"\"\" , ) Note Whilst there isn't an autoformatter I'm aware of, I prefer to write SQL using the sqlstyle.guide guide.","title":"Database schema"},{"location":"backend/database-schema/#members-table","text":"The members table stores the login credentials for the users that can use the app. The SQL to create this database is, CREATE TABLE members ( id SERIAL PRIMARY KEY , created TIMESTAMP NOT NULL DEFAULT now (), email TEXT NOT NULL , email_verified TIMESTAMP , password_hash TEXT NOT NULL ); CREATE UNIQUE INDEX members_unique_email_idx on members ( LOWER ( email )); The id , email , and password_hash columns are the minimum requirements for a login system. Note that a password hash and not the raw password should be stored. The created column is useful as it allows you to track user growth over time. The email_verified column indicates if the user has verified that they control the email, which is a crucial thing to check before sending the user emails. This could be a boolean, but storing the timestamp helps understand the user's actions. See a note with the models that explains why the unique index is used with LOWER .","title":"Members table"},{"location":"backend/database-schema/#todo-table","text":"The todos table stores all the todos, linked to the user, CREATE TABLE todos ( id BIGSERIAL PRIMARY KEY , complete BOOLEAN NOT NULL DEFAULT FALSE , due TIMESTAMPTZ , member_id INT NOT NULL REFERENCES members ( id ), task TEXT NOT NULL );","title":"Todo table"},{"location":"backend/database-schema/#complete-migration","text":"The initial setup of the database should be contained in backend/db/0.py , which should be, from databases import Database async def migrate ( db : Database ) -> None : await db . execute ( \"\"\"CREATE TABLE members( id SERIAL PRIMARY KEY, email TEXT UNIQUE NOT NULL, password TEXT NOT NULL ) \"\"\" , ) await db . execute ( \"\"\"CREATE TABLE todos( id BIGSERIAL PRIMARY KEY, complete BOOLEAN NOT NULL DEFAULT FALSE, due TIMESTAMPTZ, member_id INT NOT NULL UNIQUE REFERENCES members(id), task TEXT NOT NULL ); \"\"\" , ) Note Whilst there isn't an autoformatter I'm aware of, I prefer to write SQL using the sqlstyle.guide guide.","title":"Complete migration"},{"location":"backend/database/","text":"We have chosen to store the data the app needs in a postgres database, which we will need to connect to and manage the schema of via the app. To connect I like to use databases which is a great wrapper around fast lower level postgres drivers. It is installed via poetry, poetry add databases [ postgresql ] As the app starts up it will need to connect to the database, ideally by setting up a connection pool. The connection pool ensures that each query can reuse a connection from the pool rather than having to create a new connection. This improves the user experience as connecting to the database is much slower than using an existing connection from the pool. The following code which should be added to backend/src/backend/lib/database.py , from databases import Database async def create_database ( url : str ) -> Database : db = Database ( url ) await db . connect () return db The following should then be added to backend/src/backend/run.py to make a db app attribute available, from backend.lib.database import create_database ... def create_app () -> Quart : ... @app . before_serving async def startup () -> None : app . db = await create_database ( os . environ [ \"DATABASE_URL\" ]) @app . after_serving async def shutdown () -> None : await app . db . disconnect () ... As the database changes depending on the environment we'll need to make the following changes to the environment configuration files, backend/development.env DATABASE_URL = \"postgresql://tozo:tozo@0.0.0.0:5432/tozo\" backend/test.env DATABASE_URL = \"postgresql://tozo:tozo@0.0.0.0:5432/tozo_test\" backend/ci.env DATABASE_URL = \"postgresql://tozo:tozo@postgres:5432/tozo_test\" Schema management The schema (structure of the database) needs to be set and then changed over time. Each change to the schema, and any accompanying data change, is termed a migration. I find migrations work best if they are considered forward only, i.e. changes are sequential and take the database from a state into a new state. For this reason I manage migrations as numbered scripts, whereby migration 0 is the initial setup and 1 then next etc... To manage the migrations we need to keep track of which migrations have been applied to the database, we can do this by creating a single rowed table to store the last migration by adding the following to backend/src/backend/database.py , async def create_database ( url : str ) -> Database : ... await _create_migration_table ( db ) return db async def _create_migration_table ( db : Database ) -> None : await db . execute ( \"\"\"CREATE TABLE IF NOT EXISTS schema_migration ( onerow_id BOOL PRIMARY KEY DEFAULT TRUE, version INTEGER NOT NULL, CONSTRAINT onerow_uni CHECK (onerow_id) )\"\"\" , ) await db . execute ( \"\"\"INSERT INTO schema_migration (version) VALUES(-1) ON CONFLICT DO NOTHING \"\"\" ) The migrations themselves the migrations must be run, but only one once (to prevent data corruption). To do this the following code should be placed in backend/src/backend/lib/database.py , import importlib.util from databases import Database async def create_database ( url : str ) -> Database : ... await _setup_schema ( db ) return db async def _setup_schema ( db : Database ) -> int : migration = await db . fetch_val ( \"SELECT version FROM schema_migration\" ) initial_migration = migration while True : migration += 1 try : await _run_migration ( db , migration ) except FileNotFoundError : break return initial_migration async def _run_migration ( db : Database , migration : int ) -> None : spec = importlib . util . spec_from_file_location ( f \"db_ { migration } \" , f \"db/ { migration } .py\" ) module = importlib . util . module_from_spec ( spec ) spec . loader . exec_module ( module ) await module . migrate ( db ) await db . execute ( \"UPDATE schema_migration SET version = :version\" , values = { \"version\" : migration }, ) which will run migrations in sequential order as saved in python files in the backend/db folder, for example the first migration must be backend/db/0.sql .","title":"Database setup"},{"location":"backend/database/#schema-management","text":"The schema (structure of the database) needs to be set and then changed over time. Each change to the schema, and any accompanying data change, is termed a migration. I find migrations work best if they are considered forward only, i.e. changes are sequential and take the database from a state into a new state. For this reason I manage migrations as numbered scripts, whereby migration 0 is the initial setup and 1 then next etc... To manage the migrations we need to keep track of which migrations have been applied to the database, we can do this by creating a single rowed table to store the last migration by adding the following to backend/src/backend/database.py , async def create_database ( url : str ) -> Database : ... await _create_migration_table ( db ) return db async def _create_migration_table ( db : Database ) -> None : await db . execute ( \"\"\"CREATE TABLE IF NOT EXISTS schema_migration ( onerow_id BOOL PRIMARY KEY DEFAULT TRUE, version INTEGER NOT NULL, CONSTRAINT onerow_uni CHECK (onerow_id) )\"\"\" , ) await db . execute ( \"\"\"INSERT INTO schema_migration (version) VALUES(-1) ON CONFLICT DO NOTHING \"\"\" ) The migrations themselves the migrations must be run, but only one once (to prevent data corruption). To do this the following code should be placed in backend/src/backend/lib/database.py , import importlib.util from databases import Database async def create_database ( url : str ) -> Database : ... await _setup_schema ( db ) return db async def _setup_schema ( db : Database ) -> int : migration = await db . fetch_val ( \"SELECT version FROM schema_migration\" ) initial_migration = migration while True : migration += 1 try : await _run_migration ( db , migration ) except FileNotFoundError : break return initial_migration async def _run_migration ( db : Database , migration : int ) -> None : spec = importlib . util . spec_from_file_location ( f \"db_ { migration } \" , f \"db/ { migration } .py\" ) module = importlib . util . module_from_spec ( spec ) spec . loader . exec_module ( module ) await module . migrate ( db ) await db . execute ( \"UPDATE schema_migration SET version = :version\" , values = { \"version\" : migration }, ) which will run migrations in sequential order as saved in python files in the backend/db folder, for example the first migration must be backend/db/0.sql .","title":"Schema management"},{"location":"backend/email/","text":"When a user signs up we should send them a confirmation email including a link they can click to prove they've received it and hence have access to the email. We'll also want to send emails to users who have forgotten their password and you'll likely want to send emails to your users for other needs. Rendering the email content Most email clients support HTML emails 1 , however not all our users will have a HTML supporting client. For this reason I like to send out multipart emails with plain text and HTML parts 2 . Rather than writing HTML and plain emails I prefer a single markdown email that is rendered to HTML and plain text. Which we can do using the markdown library, as installed with poetry, poetry add markdown poetry add --dev types-Markdown we will then need to add the the following to backend/src/backend/lib/markdown.py as the markdown library does not natively support plain text, from typing import Any , Tuple from markdown import Markdown def to_plain_string ( element : Any ) -> str : result = \"\" if element . tag == \"a\" : result = f \" { element . text } ( { element . attrib [ 'href' ] } ) \\n \" elif element . text : result = element . text for node in element : result += to_plain_string ( node ) if element . tail : result += element . tail return result class PlainMarkdown ( Markdown ): def __init__ ( self , ** kwargs : Any ) -> None : self . output_formats [ \"plain\" ] = to_plain_string # type: ignore kwargs [ \"output_format\" ] = \"plain\" super () . __init__ ( ** kwargs ) self . stripTopLevelTags = False def render_markdown ( md_text : str ) -> Tuple [ str , str ]: \"\"\"Returns plain and html renderings of the *md_text*\"\"\" return PlainMarkdown () . convert ( md_text ), Markdown () . convert ( md_text ) Sending the email It is possible to send emails directly I prefer to use a service like Postmark . This is to ensure that our emails are sent reliably, from a setup that helps ensure a low spam score - this is a production app after all . In development and testing I prefer not to send emails, but rather just log them out. I find this makes development easier and quicker (no checking any email inboxes). To do so lets add a logging mail client to backend/src/backend/lib/mail_client.py , import logging from backend.lib.markdown import render_markdown log = logging . getLogger ( __name__ ) class LoggingMailClient : async def send ( self , email : str , subject : str , body : str , tag : str ) -> None : plain , html = render_markdown ( body ) log . info ( \"Sending %s to %s \\n %s \" , tag , email , plain ) We'll also need to configure the logging, which we can do with a basic setup by adding the following to backend/src/backend/run.py , import logging def create_app () -> Quart : logging . basicConfig ( level = logging . INFO ) ... In production we'll need to send the email via a HTTP request to Postmark. We can do this using the async compatible httpx which is installable via poetry, poetry add httpx allowing the following to be added to backend/src/backend/lib/mail_client.py to send emails via postmark, from typing import cast import httpx class PostmarkError ( Exception ): def __init__ ( self , error_code : int , message : str ) -> None : self . error_code = error_code self . message = message class PostmarkMailClient : def __init__ ( self , token : str ) -> None : self . _default_from = \"Tozo <help@tozo.dev>\" self . _token = token async def send ( self , email : str , subject : str , body : str , tag : str ) -> None : plain , html = render_markdown ( body ) async with httpx . AsyncClient () as client : response = await client . post ( \"https://api.postmarkapp.com/email\" , json = { \"From\" : self . _default_from , \"To\" : email , \"Subject\" : subject , \"Tag\" : tag , \"HtmlBody\" : html , \"TextBody\" : plain , }, headers = { \"X-Postmark-Server-Token\" : self . _token }, ) data = cast ( dict , response . json ()) if response . status_code != 200 : raise PostmarkError ( data [ \"ErrorCode\" ], data [ \"Message\" ]) finally we can add the following to backend/src/backend/run.py to create the mail client and assign it to the app , from backend.lib.mail_client import LoggingMailClient , PostmarkMailClient ... def create_app () -> Quart : ... if \"POSTMARK_TOKEN\" in os . environ : app . mail_client = PostmarkMailClient ( os . environ [ \"POSTMARK_TOKEN\" ]) else : app . mail_client = LoggingMailClient () With restrictions and caveats, see caniemail to check if the feature you'd like to use is supported. \u21a9 I'd also like to support multilingual parts, but most clients do not support this. \u21a9","title":"Email"},{"location":"backend/email/#rendering-the-email-content","text":"Most email clients support HTML emails 1 , however not all our users will have a HTML supporting client. For this reason I like to send out multipart emails with plain text and HTML parts 2 . Rather than writing HTML and plain emails I prefer a single markdown email that is rendered to HTML and plain text. Which we can do using the markdown library, as installed with poetry, poetry add markdown poetry add --dev types-Markdown we will then need to add the the following to backend/src/backend/lib/markdown.py as the markdown library does not natively support plain text, from typing import Any , Tuple from markdown import Markdown def to_plain_string ( element : Any ) -> str : result = \"\" if element . tag == \"a\" : result = f \" { element . text } ( { element . attrib [ 'href' ] } ) \\n \" elif element . text : result = element . text for node in element : result += to_plain_string ( node ) if element . tail : result += element . tail return result class PlainMarkdown ( Markdown ): def __init__ ( self , ** kwargs : Any ) -> None : self . output_formats [ \"plain\" ] = to_plain_string # type: ignore kwargs [ \"output_format\" ] = \"plain\" super () . __init__ ( ** kwargs ) self . stripTopLevelTags = False def render_markdown ( md_text : str ) -> Tuple [ str , str ]: \"\"\"Returns plain and html renderings of the *md_text*\"\"\" return PlainMarkdown () . convert ( md_text ), Markdown () . convert ( md_text )","title":"Rendering the email content"},{"location":"backend/email/#sending-the-email","text":"It is possible to send emails directly I prefer to use a service like Postmark . This is to ensure that our emails are sent reliably, from a setup that helps ensure a low spam score - this is a production app after all . In development and testing I prefer not to send emails, but rather just log them out. I find this makes development easier and quicker (no checking any email inboxes). To do so lets add a logging mail client to backend/src/backend/lib/mail_client.py , import logging from backend.lib.markdown import render_markdown log = logging . getLogger ( __name__ ) class LoggingMailClient : async def send ( self , email : str , subject : str , body : str , tag : str ) -> None : plain , html = render_markdown ( body ) log . info ( \"Sending %s to %s \\n %s \" , tag , email , plain ) We'll also need to configure the logging, which we can do with a basic setup by adding the following to backend/src/backend/run.py , import logging def create_app () -> Quart : logging . basicConfig ( level = logging . INFO ) ... In production we'll need to send the email via a HTTP request to Postmark. We can do this using the async compatible httpx which is installable via poetry, poetry add httpx allowing the following to be added to backend/src/backend/lib/mail_client.py to send emails via postmark, from typing import cast import httpx class PostmarkError ( Exception ): def __init__ ( self , error_code : int , message : str ) -> None : self . error_code = error_code self . message = message class PostmarkMailClient : def __init__ ( self , token : str ) -> None : self . _default_from = \"Tozo <help@tozo.dev>\" self . _token = token async def send ( self , email : str , subject : str , body : str , tag : str ) -> None : plain , html = render_markdown ( body ) async with httpx . AsyncClient () as client : response = await client . post ( \"https://api.postmarkapp.com/email\" , json = { \"From\" : self . _default_from , \"To\" : email , \"Subject\" : subject , \"Tag\" : tag , \"HtmlBody\" : html , \"TextBody\" : plain , }, headers = { \"X-Postmark-Server-Token\" : self . _token }, ) data = cast ( dict , response . json ()) if response . status_code != 200 : raise PostmarkError ( data [ \"ErrorCode\" ], data [ \"Message\" ]) finally we can add the following to backend/src/backend/run.py to create the mail client and assign it to the app , from backend.lib.mail_client import LoggingMailClient , PostmarkMailClient ... def create_app () -> Quart : ... if \"POSTMARK_TOKEN\" in os . environ : app . mail_client = PostmarkMailClient ( os . environ [ \"POSTMARK_TOKEN\" ]) else : app . mail_client = LoggingMailClient () With restrictions and caveats, see caniemail to check if the feature you'd like to use is supported. \u21a9 I'd also like to support multilingual parts, but most clients do not support this. \u21a9","title":"Sending the email"},{"location":"backend/exceptions/","text":"Error responses are usually signified by the status code (being in the 400-500 range). However the status code alone cannot always convey enough information, for example when registering a new member a status code of 400 is expected for a request with an invalid email address and for a request with weak password. Hence there is a need to return an additional code for these cases. As the frontend expects JSON this is best acheived by a custom error handler and exception class. The exception class is defined below and should be added to backend/src/backend/lib/api_error.py , class APIError ( Exception ): def __init__ ( self , status_code : int , code : str ) -> None : self . status_code = status_code self . code = code the error handler should be added to backend/src/backend/run.py ... from backend.lib.api_error import APIError def create_app () -> Quart : ... @app . errorhandler ( APIError ) # type: ignore async def handle_api_error ( error : APIError ) -> ResponseReturnValue : return { \"code\" : error . code }, error . status_code Note The type ignore comment is required to work around a Quart bug.","title":"JSON error responses"},{"location":"backend/member-api/","text":"The member API will need to provide routes to create members, and update aspects e.g. their password. Creating the blueprint The blueprint itself can be created with the following code in backend/src/backend/blueprints/members.py , from quart import Blueprint blueprint = Blueprint ( \"members\" , __name__ ) and activated by adding the following to backend/src/backend/run.py , from backend.blueprints.members import blueprint as members_blueprint def create_app () -> Quart : ... app . register_blueprint ( members_blueprint ) Creating a member For a RESTFul API the member creation route should use the POST method and require an email and a password. In the route we should check the passwod is sufficiently complex (see password strength ), create a new member and send a welcome email. We can include a verification token in the welcome email in order for the email address owner to prove they signed up. We can do this by first creating an email template by adding the following to backend/src/backend/templates/emails/welcome.md , Hello and welcome to tozo! Please confirm you signed up by following this [link]( {{ config [ \"BASE_URL\" ] }} /confirm-email/ {{ token }} /). Thanks The route should return 201 on success, and if the email provided is already a member to prevent user enumeration. This is all achieved by adding the following to backend/src/backend/blueprints/members.py , from dataclasses import dataclass from datetime import timedelta import asyncpg import bcrypt from itsdangerous import URLSafeTimedSerializer from quart import current_app , render_template , ResponseReturnValue from quart_schema import validate_request from quart_rate_limiter import rate_limit from zxcvbn import zxcvbn from lib.api_error import APIError from models.members import insert_member MINIMUM_STRENGTH = 3 EMAIL_VERIFICATION_SALT = \"email verify\" @dataclass class MemberData : email : str password : str @blueprint . post ( \"/members/\" ) @rate_limit ( 10 , timedelta ( seconds = 10 )) @validate_request ( MemberData ) async def register ( data : MemberData ) -> ResponseReturnValue : \"\"\"Create a new Member. This allows a Member to be created. \"\"\" strength = zxcvbn ( data . password ) if strength [ \"score\" ] < MINIMUM_STRENGTH : raise APIError ( 400 , \"WEAK_PASSWORD\" ) salt = bcrypt . gensalt ( 14 ) hashed_password = bcrypt . hashpw ( data . password . encode ( \"utf-8\" ), salt ) try : member = await insert_member ( current_app . db , data . email , hashed_password . decode () ) except asyncpg . exceptions . UniqueViolationError : pass else : serializer = URLSafeTimedSerializer ( current_app . secret_key , salt = EMAIL_VERIFICATION_SALT ) token = serializer . dumps ( member . id ) body = await render_template ( \"emails/welcome.md\" , token = token ) await current_app . mail_client . send ( member . email , \"Welcome\" , body , \"WELCOME\" ) return {}, 201 Changing password A user will want to change their password which will require a route that accepts their new password whilst checking the old password also supplied is correct. This route should also inform the user that the password has changed, by adding the following to backend/src/backend/templates/emails/password_changed.md , Hello, Your Tozo password has been successfully changed. Thanks For a RESTFul API the change member password should be PUT, returning 200 on success (we'll use the same rate limit). The following should be merged (removing duplicated imports) to backend/src/backend/blueprints/members.py , from quart_auth import current_user , login_required from backend.models.member import select_member_by_id , update_member_password @dataclass class PasswordData : current_password : str new_password : str @blueprint . put ( \"/members/password/\" ) @rate_limit ( 5 , timedelta ( minutes = 1 )) @login_required @validate_request ( PasswordData ) async def change_password ( data : PasswordData ) -> ResponseReturnValue : \"\"\"Update the members password. This allows the user to update their password. \"\"\" strength = zxcvbn ( data . password ) if strength [ \"score\" ] < MINIMUM_STRENGTH : raise APIError ( 400 , \"WEAK_PASSWORD\" ) member = await select_member_by_id ( current_app . db , int ( current_user . auth_id )) passwords_match = bcrypt . checkpw ( data . current_password . encode ( \"utf-8\" ), member . password_hash . encode ( \"utf-8\" ), ) if not passwords_match : raise APIError ( 401 , \"INVALID_PASSWORD\" ) salt = bcrypt . gensalt ( 14 ) hashed_password = bcrypt . hashpw ( data . new_password . encode ( \"utf-8\" ), salt ) await update_member_password ( current_app . db , int ( current_user . auth_id ), hashed_password ) body = await render_template ( \"emails/password_changed.md\" ) await current_app . mail_client . send ( member . email , \"Password changed\" , body , \"PASSWORD_CHANGED\" ) return {} Confirming the email address When a user creates their account they are sent a link back to the tozo app that includes a token. This route should test the token and if valid confirm the email address. This is achieved by adding the following to backend/src/backend/blueprints/members.py , from backend.models.member import update_member_email_verified @dataclass class TokenData : token : str @blueprint . put ( \"/members/email/\" ) @rate_limit ( 5 , timedelta ( minutes = 1 )) @validate_request ( TokenData ) async def verify_email ( data : TokenData ) -> ResponseReturnValue : \"\"\"Call to verify an email. This requires the user to supply a valid token. \"\"\" serializer = URLSafeTimedSerializer ( current_app . secret_key , salt = EMAIL_VERIFICATION_SALT ) try : member_id = serializer . loads ( data . token , max_age = ONE_MONTH ) except SignatureExpired : raise APIError ( 403 , \"TOKEN_EXPIRED\" ) except BadSignature : raise APIError ( 400 , \"TOKEN_INVALID\" ) else : await update_member_email_verified ( current_app . db , member_id ) return {} Forgotten password If a user forgets their password they'll want us to send a password reset link to their email address. To do so we need a route that accepts the user's email address and sends out the following email, as added to backend/src/backend/templates/emails/forgotten_password.md , Hello, You can use this [link]( {{ config [ \"BASE_URL\" ] }} /reset-password/ {{ token }} /) to reset your password. Thanks from backend.models.member import select_member_by_email FORGOTTEN_PASSWORD_SALT = \"forgotten password\" @dataclass class ForgottenPasswordData : email : str @blueprint . put ( \"/members/email/\" ) @rate_limit ( 5 , timedelta ( minutes = 1 )) @validate_request ( ForgottenPasswordData ) async def forgotten_password ( data : ForgottenPasswordData ) -> ResponseReturnValue : \"\"\"Call to trigger a forgotten password email. This requires a valid member email. \"\"\" member = await select_member_by_email ( current_app . db , data . email ) if member is not None : serializer = URLSafeTimedSerializer ( current_app . secret_key , salt = FORGOTTEN_PASSWORD_SALT ) token = serializer . dumps ( member . id ) body = await render_template ( \"emails/forgotten_password.md\" , token = token ) await current_app . mail_client . send ( member . email , \"Forgotten password\" , body , \"FORGOTTEN_PASSWORD\" ) return {} Reseting the password PUT \"/members/reset-password/\" @dataclass class ResetPasswordData : password : str token : str @blueprint . put ( \"/members/reset-password/\" ) @rate_limit ( 5 , timedelta ( minutes = 1 )) @validate_request ( ResetPasswordData ) async def reset_password ( data : ResetPasswordData ) -> ResponseReturnValue : \"\"\"Call to reset a password using a token. This requires the user to supply a valid token and a new password. \"\"\" serializer = URLSafeTimedSerializer ( current_app . secret_key , salt = FORGOTTEN_PASSWORD_SALT ) try : member_id = serializer . loads ( data . token , max_age = ONE_MONTH ) except SignatureExpired : raise APIError ( 403 , \"TOKEN_EXPIRED\" ) except BadSignature : raise APIError ( 400 , \"TOKEN_INVALID\" ) else : strength = zxcvbn ( data . password ) if strength [ \"score\" ] < MINIMUM_STRENGTH : raise APIError ( 400 , \"WEAK_PASSWORD\" ) salt = bcrypt . gensalt ( 14 ) hashed_password = bcrypt . hashpw ( data . password . encode ( \"utf-8\" ), salt ) await update_member_password ( current_app . db , member_id , hashed_password . decode () ) return {}","title":"Member API"},{"location":"backend/member-api/#creating-the-blueprint","text":"The blueprint itself can be created with the following code in backend/src/backend/blueprints/members.py , from quart import Blueprint blueprint = Blueprint ( \"members\" , __name__ ) and activated by adding the following to backend/src/backend/run.py , from backend.blueprints.members import blueprint as members_blueprint def create_app () -> Quart : ... app . register_blueprint ( members_blueprint )","title":"Creating the blueprint"},{"location":"backend/member-api/#creating-a-member","text":"For a RESTFul API the member creation route should use the POST method and require an email and a password. In the route we should check the passwod is sufficiently complex (see password strength ), create a new member and send a welcome email. We can include a verification token in the welcome email in order for the email address owner to prove they signed up. We can do this by first creating an email template by adding the following to backend/src/backend/templates/emails/welcome.md , Hello and welcome to tozo! Please confirm you signed up by following this [link]( {{ config [ \"BASE_URL\" ] }} /confirm-email/ {{ token }} /). Thanks The route should return 201 on success, and if the email provided is already a member to prevent user enumeration. This is all achieved by adding the following to backend/src/backend/blueprints/members.py , from dataclasses import dataclass from datetime import timedelta import asyncpg import bcrypt from itsdangerous import URLSafeTimedSerializer from quart import current_app , render_template , ResponseReturnValue from quart_schema import validate_request from quart_rate_limiter import rate_limit from zxcvbn import zxcvbn from lib.api_error import APIError from models.members import insert_member MINIMUM_STRENGTH = 3 EMAIL_VERIFICATION_SALT = \"email verify\" @dataclass class MemberData : email : str password : str @blueprint . post ( \"/members/\" ) @rate_limit ( 10 , timedelta ( seconds = 10 )) @validate_request ( MemberData ) async def register ( data : MemberData ) -> ResponseReturnValue : \"\"\"Create a new Member. This allows a Member to be created. \"\"\" strength = zxcvbn ( data . password ) if strength [ \"score\" ] < MINIMUM_STRENGTH : raise APIError ( 400 , \"WEAK_PASSWORD\" ) salt = bcrypt . gensalt ( 14 ) hashed_password = bcrypt . hashpw ( data . password . encode ( \"utf-8\" ), salt ) try : member = await insert_member ( current_app . db , data . email , hashed_password . decode () ) except asyncpg . exceptions . UniqueViolationError : pass else : serializer = URLSafeTimedSerializer ( current_app . secret_key , salt = EMAIL_VERIFICATION_SALT ) token = serializer . dumps ( member . id ) body = await render_template ( \"emails/welcome.md\" , token = token ) await current_app . mail_client . send ( member . email , \"Welcome\" , body , \"WELCOME\" ) return {}, 201","title":"Creating a member"},{"location":"backend/member-api/#changing-password","text":"A user will want to change their password which will require a route that accepts their new password whilst checking the old password also supplied is correct. This route should also inform the user that the password has changed, by adding the following to backend/src/backend/templates/emails/password_changed.md , Hello, Your Tozo password has been successfully changed. Thanks For a RESTFul API the change member password should be PUT, returning 200 on success (we'll use the same rate limit). The following should be merged (removing duplicated imports) to backend/src/backend/blueprints/members.py , from quart_auth import current_user , login_required from backend.models.member import select_member_by_id , update_member_password @dataclass class PasswordData : current_password : str new_password : str @blueprint . put ( \"/members/password/\" ) @rate_limit ( 5 , timedelta ( minutes = 1 )) @login_required @validate_request ( PasswordData ) async def change_password ( data : PasswordData ) -> ResponseReturnValue : \"\"\"Update the members password. This allows the user to update their password. \"\"\" strength = zxcvbn ( data . password ) if strength [ \"score\" ] < MINIMUM_STRENGTH : raise APIError ( 400 , \"WEAK_PASSWORD\" ) member = await select_member_by_id ( current_app . db , int ( current_user . auth_id )) passwords_match = bcrypt . checkpw ( data . current_password . encode ( \"utf-8\" ), member . password_hash . encode ( \"utf-8\" ), ) if not passwords_match : raise APIError ( 401 , \"INVALID_PASSWORD\" ) salt = bcrypt . gensalt ( 14 ) hashed_password = bcrypt . hashpw ( data . new_password . encode ( \"utf-8\" ), salt ) await update_member_password ( current_app . db , int ( current_user . auth_id ), hashed_password ) body = await render_template ( \"emails/password_changed.md\" ) await current_app . mail_client . send ( member . email , \"Password changed\" , body , \"PASSWORD_CHANGED\" ) return {}","title":"Changing password"},{"location":"backend/member-api/#confirming-the-email-address","text":"When a user creates their account they are sent a link back to the tozo app that includes a token. This route should test the token and if valid confirm the email address. This is achieved by adding the following to backend/src/backend/blueprints/members.py , from backend.models.member import update_member_email_verified @dataclass class TokenData : token : str @blueprint . put ( \"/members/email/\" ) @rate_limit ( 5 , timedelta ( minutes = 1 )) @validate_request ( TokenData ) async def verify_email ( data : TokenData ) -> ResponseReturnValue : \"\"\"Call to verify an email. This requires the user to supply a valid token. \"\"\" serializer = URLSafeTimedSerializer ( current_app . secret_key , salt = EMAIL_VERIFICATION_SALT ) try : member_id = serializer . loads ( data . token , max_age = ONE_MONTH ) except SignatureExpired : raise APIError ( 403 , \"TOKEN_EXPIRED\" ) except BadSignature : raise APIError ( 400 , \"TOKEN_INVALID\" ) else : await update_member_email_verified ( current_app . db , member_id ) return {}","title":"Confirming the email address"},{"location":"backend/member-api/#forgotten-password","text":"If a user forgets their password they'll want us to send a password reset link to their email address. To do so we need a route that accepts the user's email address and sends out the following email, as added to backend/src/backend/templates/emails/forgotten_password.md , Hello, You can use this [link]( {{ config [ \"BASE_URL\" ] }} /reset-password/ {{ token }} /) to reset your password. Thanks from backend.models.member import select_member_by_email FORGOTTEN_PASSWORD_SALT = \"forgotten password\" @dataclass class ForgottenPasswordData : email : str @blueprint . put ( \"/members/email/\" ) @rate_limit ( 5 , timedelta ( minutes = 1 )) @validate_request ( ForgottenPasswordData ) async def forgotten_password ( data : ForgottenPasswordData ) -> ResponseReturnValue : \"\"\"Call to trigger a forgotten password email. This requires a valid member email. \"\"\" member = await select_member_by_email ( current_app . db , data . email ) if member is not None : serializer = URLSafeTimedSerializer ( current_app . secret_key , salt = FORGOTTEN_PASSWORD_SALT ) token = serializer . dumps ( member . id ) body = await render_template ( \"emails/forgotten_password.md\" , token = token ) await current_app . mail_client . send ( member . email , \"Forgotten password\" , body , \"FORGOTTEN_PASSWORD\" ) return {}","title":"Forgotten password"},{"location":"backend/member-api/#reseting-the-password","text":"PUT \"/members/reset-password/\" @dataclass class ResetPasswordData : password : str token : str @blueprint . put ( \"/members/reset-password/\" ) @rate_limit ( 5 , timedelta ( minutes = 1 )) @validate_request ( ResetPasswordData ) async def reset_password ( data : ResetPasswordData ) -> ResponseReturnValue : \"\"\"Call to reset a password using a token. This requires the user to supply a valid token and a new password. \"\"\" serializer = URLSafeTimedSerializer ( current_app . secret_key , salt = FORGOTTEN_PASSWORD_SALT ) try : member_id = serializer . loads ( data . token , max_age = ONE_MONTH ) except SignatureExpired : raise APIError ( 403 , \"TOKEN_EXPIRED\" ) except BadSignature : raise APIError ( 400 , \"TOKEN_INVALID\" ) else : strength = zxcvbn ( data . password ) if strength [ \"score\" ] < MINIMUM_STRENGTH : raise APIError ( 400 , \"WEAK_PASSWORD\" ) salt = bcrypt . gensalt ( 14 ) hashed_password = bcrypt . hashpw ( data . password . encode ( \"utf-8\" ), salt ) await update_member_password ( current_app . db , member_id , hashed_password . decode () ) return {}","title":"Reseting the password"},{"location":"backend/models/","text":"The data processed by the app is best represented by models, as this ensures that the correct structure and types are used. To achieve this I like to make use of Pydantic 's dataclass as it leads to very clear code and integrates directly with Quart-Schema's validation. Question I prefer to write the SQL queries rather than use an ORM, however if you prefer ORM is a great library that integrates well with Databases. Todo models The Todo model should be split into a model for the data entered by the users and a model for the complete todo (including data calculated by the server). Spliting the model allows validation of data sent to and returned by the server. The models should be added to backend/src/backend/models/todo.py , and are, from dataclasses import dataclass from datetime import datetime from typing import Optional @dataclass class TodoData : complete : bool due : Optional [ datetime ] task : str @dataclass class Todo ( TodoData ): id : int In addition we should add functions to backend/src/backend/models/todo.py to manipulate the todo data in the database, from dataclasses import asdict from databases import Database async def insert_todo ( db : Database , data : TodoData , member_id : int ) -> Todo : result = await db . fetch_one ( \"\"\"INSERT INTO todos (complete, due, member_id, task) VALUES (:complete, :due, :member_id, :task) RETURNING id, complete, due, task\"\"\" , values = asdict ( data ) | { \"member_id\" : member_id }, ) return Todo ( ** result ) async def select_todos ( db : Database , member_id : int , complete : Optional [ bool ] = None ) -> list [ Todo ]: if complete is None : query = \"\"\"SELECT id, complete, due, task FROM todos WHERE member_id = :member_id\"\"\" values = { \"member_id\" : member_id } else : query = \"\"\"SELECT id, complete, due, task FROM todos WHERE member_id = :member_id AND complete = :complete\"\"\" values = { \"member_id\" : member_id , \"complete\" : complete } return [ Todo ( ** row ) async for row in db . iterate ( query , values )] async def select_todo ( db : Database , id : int , member_id : int ) -> Optional [ Todo ]: result = await db . fetch_one ( \"\"\"SELECT id, complete, due, task FROM todos WHERE id = :id AND member_id = :member_id\"\"\" , values = { \"id\" : id , \"member_id\" : member_id }, ) return None if result is None else Todo ( ** result ) async def update_todo ( db : Database , id : int , data : TodoData , member_id : int ) -> Optional [ Todo ]: result = await db . fetch_one ( \"\"\"UPDATE todos SET complete = :complete, due = :due, task = :task WHERE id = :id AND member_id = :member_id RETURNING id, complete, due, task\"\"\" , values = asdict ( data ) | { \"id\" : id , \"member_id\" : member_id }, ) return None if result is None else Todo ( ** result ) async def delete_todo ( db : Database , id : int , member_id : int ) -> None : await db . execute ( \"DELETE FROM todos WHERE id = :id AND member_id = :member_id\" , values = { \"id\" : id , \"member_id\" : member_id }, ) Member model The member model is simpler, and should be added to backend/src/backend/models/member.py , from dataclasses import dataclass from datetime import datetime from typing import Optional @dataclass class Member : id : int email : str password_hash : str created : datetime email_verified : Optional [ datetime ] In addition we should add these functions to backend/src/backend/models/member.py to manipulate the member data in the database, from databases import Database async def select_member_by_email ( db : Database , email : str ) -> Optional [ Member ]: result = await db . fetch_one ( \"\"\"SELECT id, email, password_hash, created, email_verified FROM members WHERE LOWER(email) = LOWER(:email)\"\"\" , values = { \"email\" : email }, ) return None if result is None else Member ( ** result ) async def select_member_by_id ( db : Database , id : int ) -> Optional [ Member ]: result = await db . fetch_one ( \"\"\"SELECT id, email, password_hash, created, email_verified FROM members WHERE id = :id\"\"\" , values = { \"id\" : id }, ) return None if result is None else Member ( ** result ) async def insert_member ( db : Database , email : str , password_hash : str ) -> Member : result = await db . fetch_one ( \"\"\"INSERT INTO members (email, password_hash) VALUES (:email, :password_hash) RETURNING id, email, password_hash, created, email_verified\"\"\" , values = { \"email\" : email , \"password_hash\" : password_hash }, ) return Member ( ** result ) async def update_member_password ( db : Database , id : int , password_hash : str ) -> None : await db . execute ( \"UPDATE members SET password_hash = :password_hash WHERE id = :id\" , values = { \"id\" : id , \"password_hash\" : password_hash }, ) async def update_member_email_verified ( db : Database , id : int ) -> None : await db . execute ( \"UPDATE members SET email_verified = now() id = :id\" , values = { \"id\" : id }, ) Email casing According to the specification the local part of an email address (to the left of the @ ) is case sensitive, whereas the domain part (to the righ of the @ ) is case insensitive. In practice, however, email addresses are considered case insensitive. To account for this apparent contradiction, we store the email address in the casing provided by the user as this ensures any case sensitivity is preserved when sending them emails whilst lowercasing the email for login checks thereby ensuring that email addresses are case insensitive in practice.","title":"Data models"},{"location":"backend/models/#todo-models","text":"The Todo model should be split into a model for the data entered by the users and a model for the complete todo (including data calculated by the server). Spliting the model allows validation of data sent to and returned by the server. The models should be added to backend/src/backend/models/todo.py , and are, from dataclasses import dataclass from datetime import datetime from typing import Optional @dataclass class TodoData : complete : bool due : Optional [ datetime ] task : str @dataclass class Todo ( TodoData ): id : int In addition we should add functions to backend/src/backend/models/todo.py to manipulate the todo data in the database, from dataclasses import asdict from databases import Database async def insert_todo ( db : Database , data : TodoData , member_id : int ) -> Todo : result = await db . fetch_one ( \"\"\"INSERT INTO todos (complete, due, member_id, task) VALUES (:complete, :due, :member_id, :task) RETURNING id, complete, due, task\"\"\" , values = asdict ( data ) | { \"member_id\" : member_id }, ) return Todo ( ** result ) async def select_todos ( db : Database , member_id : int , complete : Optional [ bool ] = None ) -> list [ Todo ]: if complete is None : query = \"\"\"SELECT id, complete, due, task FROM todos WHERE member_id = :member_id\"\"\" values = { \"member_id\" : member_id } else : query = \"\"\"SELECT id, complete, due, task FROM todos WHERE member_id = :member_id AND complete = :complete\"\"\" values = { \"member_id\" : member_id , \"complete\" : complete } return [ Todo ( ** row ) async for row in db . iterate ( query , values )] async def select_todo ( db : Database , id : int , member_id : int ) -> Optional [ Todo ]: result = await db . fetch_one ( \"\"\"SELECT id, complete, due, task FROM todos WHERE id = :id AND member_id = :member_id\"\"\" , values = { \"id\" : id , \"member_id\" : member_id }, ) return None if result is None else Todo ( ** result ) async def update_todo ( db : Database , id : int , data : TodoData , member_id : int ) -> Optional [ Todo ]: result = await db . fetch_one ( \"\"\"UPDATE todos SET complete = :complete, due = :due, task = :task WHERE id = :id AND member_id = :member_id RETURNING id, complete, due, task\"\"\" , values = asdict ( data ) | { \"id\" : id , \"member_id\" : member_id }, ) return None if result is None else Todo ( ** result ) async def delete_todo ( db : Database , id : int , member_id : int ) -> None : await db . execute ( \"DELETE FROM todos WHERE id = :id AND member_id = :member_id\" , values = { \"id\" : id , \"member_id\" : member_id }, )","title":"Todo models"},{"location":"backend/models/#member-model","text":"The member model is simpler, and should be added to backend/src/backend/models/member.py , from dataclasses import dataclass from datetime import datetime from typing import Optional @dataclass class Member : id : int email : str password_hash : str created : datetime email_verified : Optional [ datetime ] In addition we should add these functions to backend/src/backend/models/member.py to manipulate the member data in the database, from databases import Database async def select_member_by_email ( db : Database , email : str ) -> Optional [ Member ]: result = await db . fetch_one ( \"\"\"SELECT id, email, password_hash, created, email_verified FROM members WHERE LOWER(email) = LOWER(:email)\"\"\" , values = { \"email\" : email }, ) return None if result is None else Member ( ** result ) async def select_member_by_id ( db : Database , id : int ) -> Optional [ Member ]: result = await db . fetch_one ( \"\"\"SELECT id, email, password_hash, created, email_verified FROM members WHERE id = :id\"\"\" , values = { \"id\" : id }, ) return None if result is None else Member ( ** result ) async def insert_member ( db : Database , email : str , password_hash : str ) -> Member : result = await db . fetch_one ( \"\"\"INSERT INTO members (email, password_hash) VALUES (:email, :password_hash) RETURNING id, email, password_hash, created, email_verified\"\"\" , values = { \"email\" : email , \"password_hash\" : password_hash }, ) return Member ( ** result ) async def update_member_password ( db : Database , id : int , password_hash : str ) -> None : await db . execute ( \"UPDATE members SET password_hash = :password_hash WHERE id = :id\" , values = { \"id\" : id , \"password_hash\" : password_hash }, ) async def update_member_email_verified ( db : Database , id : int ) -> None : await db . execute ( \"UPDATE members SET email_verified = now() id = :id\" , values = { \"id\" : id }, ) Email casing According to the specification the local part of an email address (to the left of the @ ) is case sensitive, whereas the domain part (to the righ of the @ ) is case insensitive. In practice, however, email addresses are considered case insensitive. To account for this apparent contradiction, we store the email address in the casing provided by the user as this ensures any case sensitivity is preserved when sending them emails whilst lowercasing the email for login checks thereby ensuring that email addresses are case insensitive in practice.","title":"Member model"},{"location":"backend/passwords/","text":"We'll want to enforce a minimum password complexity to help ensure our user's information is safe. To do this I use zxcvbn to measure the complexity. It is installed via poetry, poetry add zxcvbn and gives a score [0, 4] of which I usually consider scores of 3 or 4 good enough.","title":"Password strength"},{"location":"backend/rate-limiting/","text":"Shortly after you deploy your app in production users will at best misuse it and at worse attack it. It is worthwhile then being defensive from the outset by adding rate limiting, which limits the rate at which a remote client can make requests to the app. We'll use the Quart extension Quart-Rate-Limiter to enforce rate limits, first by installing, poetry add quart-rate-limiter which installed 0.4.0. Then by activating the RateLimiter when creating the app in backend/src/backend/run.py , from quart_rate_limiter import RateLimiter rate_limiter = RateLimiter () def create_app () -> None : ... rate_limiter . init_app ( app ) ... With this any route in the app can be given rate limit protection, for example to limit to 6 requests per minute, from datetime import timedelta from quart_rate_limiter import rate_limit @blueprint . route ( \"/\" ) @rate_limit ( 6 , timedelta ( minutes = 1 )) async def handler (): ... It would be useful to provide a JSON response if the client exceeds the rate limit, we can do this by adding the following error handler to be backend/src/backend/run.py from quart_rate_limiter import RateLimitExceeded def create_app () -> Quart : ... @app . errorhandler ( RateLimitExceeded ) async def handle_rate_limit_exceeded_error ( error : RateLimitExceeded , ) -> ResponseReturnValue : return {}, error . get_headers (), 429 Testing I like to check that all routes have rate limits or are marked as exempt using the rate_exempt decorator. To do this I add the following to tests/test_rate_limits.py , from quart import Quart from quart_rate_limiter import ( QUART_RATE_LIMITER_EXEMPT_ATTRIBUTE , QUART_RATE_LIMITER_LIMITS_ATTRIBUTE ) def test_routes_have_rate_limits ( app : Quart ) -> None : for rule in app . url_map . iter_rules (): endpoint = rule . endpoint if endpoint == \"static\" : continue exempt = getattr ( app . view_functions [ endpoint ], QUART_RATE_LIMITER_EXEMPT_ATTRIBUTE , False , ) if not exempt : rate_limits = getattr ( app . view_functions [ endpoint ], QUART_RATE_LIMITER_LIMITS_ATTRIBUTE , [], ) assert rate_limits != [] For this to pass will also need to add the rate_exempt decorator to the control ping endpoint in backend/src/backend/blueprints/control.py , ... from quart_rate_limiter import rate_exempt @blueprint . route ( \"/control/ping/\" ) @rate_exempt async def ping () -> ResponseReturnValue : return { \"ping\" : \"pong\" }","title":"Rate limiting"},{"location":"backend/rate-limiting/#testing","text":"I like to check that all routes have rate limits or are marked as exempt using the rate_exempt decorator. To do this I add the following to tests/test_rate_limits.py , from quart import Quart from quart_rate_limiter import ( QUART_RATE_LIMITER_EXEMPT_ATTRIBUTE , QUART_RATE_LIMITER_LIMITS_ATTRIBUTE ) def test_routes_have_rate_limits ( app : Quart ) -> None : for rule in app . url_map . iter_rules (): endpoint = rule . endpoint if endpoint == \"static\" : continue exempt = getattr ( app . view_functions [ endpoint ], QUART_RATE_LIMITER_EXEMPT_ATTRIBUTE , False , ) if not exempt : rate_limits = getattr ( app . view_functions [ endpoint ], QUART_RATE_LIMITER_LIMITS_ATTRIBUTE , [], ) assert rate_limits != [] For this to pass will also need to add the rate_exempt decorator to the control ping endpoint in backend/src/backend/blueprints/control.py , ... from quart_rate_limiter import rate_exempt @blueprint . route ( \"/control/ping/\" ) @rate_exempt async def ping () -> ResponseReturnValue : return { \"ping\" : \"pong\" }","title":"Testing"},{"location":"backend/todo-api/","text":"The Todo resource API will need to provide a RESTFul CRUD interface for the frontend to Create, Read, Update, and Delete Todos. This API is best implemented as a Blueprint, placed in backend/src/backend/blueprints/todos.py , putting all the features e.g. authentication, rate-limiting, models etc... that we've setup together. Creating the blueprint The blueprint itself can be created with the following code in backend/src/backend/blueprints/todos.py , from quart import Blueprint blueprint = Blueprint ( \"todos\" , __name__ ) and activated by adding the following to backend/src/backend/run.py , from backend.blueprints.todos import blueprint as todos_blueprint def create_app () -> Quart : ... app . register_blueprint ( todos_blueprint ) Creating a todo For a RESTFul API the todo creation route should be POST, expecting the todo data and returning the complete todo with a 201 status code on success, we'll assume that a fast real user can create no more than 10 todos in 10 seconds on average. The following should be added to backend/src/backend/blueprints/todos.py , from datetime import timedelta from quart import current_app from quart_auth import current_user , login_required from quart_schema import validate_request , validate_response from quart_rate_limiter import rate_limit from backend.models.todo import insert_todo , Todo , TodoData @blueprint . post ( \"/todos/\" ) @rate_limit ( 10 , timedelta ( seconds = 10 )) @login_required @validate_request ( TodoData ) @validate_response ( Todo , 201 ) async def post_todo ( data : TodoData ) -> tuple [ Todo , int ]: \"\"\"Create a new Todo. This allows todos to be created and stored. \"\"\" todo = await insert_todo ( current_app . db , data , int ( current_user . auth_id )) return todo , 201 Reading a todo For a RESTFul API the read route should be GET, returning a todo on success (we'll use the same rate limit) and a 404 if the todo does not exist. The following should be added to backend/src/backend/blueprints/todos.py , from backend.lib.api_error import APIError from backend.models.todo import select_todo @blueprint . get ( \"/todos/<int:id>/\" ) @rate_limit ( 10 , timedelta ( seconds = 10 )) @login_required @validate_response ( Todo ) async def get_todo ( id : int ) -> Todo : \"\"\"Get a todo. Fetch a Todo by its ID. \"\"\" todo = await select_todo ( current_app . db , id , int ( current_user . auth_id )) if todo is None : raise APIError ( 404 , \"NOT_FOUND\" ) else : return todo Reading the todos For a RESTFul API the read route should be GET, returning a list of todos on success (we'll use the same rate limit). To demonstrate how to do server side filtering we'll provide a read route that can optionally filter on the complete todo attribute. The following should be added to backend/src/backend/blueprints/todos.py , from dataclasses import dataclass from typing import Optional from quart_schema import validate_querystring from models.todo import select_todos @dataclass class Todos : todos : list [ Todo ] @dataclass class TodoFilter : complete : Optional [ bool ] = None @blueprint . get ( \"/todos/\" ) @rate_limit ( 10 , timedelta ( seconds = 10 )) @login_required @validate_response ( Todos ) @validate_querystring ( TodoFilter ) async def get_todos ( query_args : TodoFilter ) -> Todos : \"\"\"Get the todos. Fetch all the Todos optionally based on the complete status. \"\"\" todos = await select_todos ( current_app . db , int ( current_user . auth_id ), query_args . complete ) return Todos ( todos = todos ) Updating a todo For a RESTFul API the todo update route should be PUT, expecting the todo data and returning the complete todo on success (we'll use the same rate limit) and a 404 if the todo does not exist. The following should be added to backend/src/backend/blueprints/todos.py , from models.todo import update_todo @blueprint . put ( \"/todos/<int:id>/\" ) @rate_limit ( 10 , timedelta ( seconds = 10 )) @login_required @validate_request ( TodoData ) @validate_response ( Todo ) async def put_todo ( id : int , data : TodoData ) -> Todo : \"\"\"Update the identified todo This allows the todo to be replaced with the request data. \"\"\" todo = await update_todo ( current_app . db , id , data , int ( current_user . auth_id )) if todo is None : raise APIError ( 404 , \"NOT_FOUND\" ) else : return todo Deleting a todo For a RESTFul API the todo deletion route should be DELETE, returning 202 on success and if the todo does not exist (we'll use the same rate limit). The following should be added to backend/src/backend/blueprints/todos.py , from quart import ResponseReturnValue from models.todo import delete_todo @blueprint . delete ( \"/todos/<int:id>/\" ) @rate_limit ( 10 , timedelta ( seconds = 10 )) @login_required async def todo_delete ( id : int ) -> ResponseReturnValue : \"\"\"Delete the identified todo This will delete the todo. \"\"\" await delete_todo ( current_app . db , id , int ( current_user . auth_id )) return \"\" , 202 Testing We should test that these routes work as a user would expect, starting by testing that the get route returns the test data todo by adding the following to backend/tests/blueprints/test_todos.py , import pytest from quart import Quart @pytest . mark . asyncio async def test_get_todo ( app : Quart ) -> None : test_client = app . test_client () async with test_client . authenticated ( \"1\" ): response = await test_client . get ( \"/todos/1/\" ) todo = await response . get_json () assert todo [ \"task\" ] == \"Task\" Next we can test creating, updating, retreiving and then deleting a todo i.e. the full user flow, by adding the following to backend/tests/blueprints/test_todos.py . @pytest . mark . asyncio async def test_todo_flow ( app : Quart ) -> None : test_client = app . test_client () async with test_client . authenticated ( \"1\" ): response = await test_client . get ( \"/todos/\" ) todos = ( await response . get_json ())[ \"todos\" ] response = await test_client . post ( \"/todos/\" , json = { \"complete\" : False , \"due\" : None , \"task\" : \"New Todo\" }, ) todo_id = ( await response . get_json ())[ \"id\" ] response = await test_client . get ( \"/todos/\" ) new_todos = ( await response . get_json ())[ \"todos\" ] assert len ( new_todos ) == len ( todos ) + 1 await test_client . put ( f \"/todos/ { todo_id } /\" , json = { \"complete\" : True , \"due\" : None , \"task\" : \"New Todo\" }, ) response = await test_client . get ( f \"/todos/ { todo_id } /\" ) todo = await response . get_json () assert todo [ \"complete\" ] await test_client . delete ( f \"/todos/ { todo_id } /\" ) response = await test_client . get ( \"/todos/\" ) final_todos = ( await response . get_json ())[ \"todos\" ] assert len ( final_todos ) == len ( todos )","title":"Todo CRUD API"},{"location":"backend/todo-api/#creating-the-blueprint","text":"The blueprint itself can be created with the following code in backend/src/backend/blueprints/todos.py , from quart import Blueprint blueprint = Blueprint ( \"todos\" , __name__ ) and activated by adding the following to backend/src/backend/run.py , from backend.blueprints.todos import blueprint as todos_blueprint def create_app () -> Quart : ... app . register_blueprint ( todos_blueprint )","title":"Creating the blueprint"},{"location":"backend/todo-api/#creating-a-todo","text":"For a RESTFul API the todo creation route should be POST, expecting the todo data and returning the complete todo with a 201 status code on success, we'll assume that a fast real user can create no more than 10 todos in 10 seconds on average. The following should be added to backend/src/backend/blueprints/todos.py , from datetime import timedelta from quart import current_app from quart_auth import current_user , login_required from quart_schema import validate_request , validate_response from quart_rate_limiter import rate_limit from backend.models.todo import insert_todo , Todo , TodoData @blueprint . post ( \"/todos/\" ) @rate_limit ( 10 , timedelta ( seconds = 10 )) @login_required @validate_request ( TodoData ) @validate_response ( Todo , 201 ) async def post_todo ( data : TodoData ) -> tuple [ Todo , int ]: \"\"\"Create a new Todo. This allows todos to be created and stored. \"\"\" todo = await insert_todo ( current_app . db , data , int ( current_user . auth_id )) return todo , 201","title":"Creating a todo"},{"location":"backend/todo-api/#reading-a-todo","text":"For a RESTFul API the read route should be GET, returning a todo on success (we'll use the same rate limit) and a 404 if the todo does not exist. The following should be added to backend/src/backend/blueprints/todos.py , from backend.lib.api_error import APIError from backend.models.todo import select_todo @blueprint . get ( \"/todos/<int:id>/\" ) @rate_limit ( 10 , timedelta ( seconds = 10 )) @login_required @validate_response ( Todo ) async def get_todo ( id : int ) -> Todo : \"\"\"Get a todo. Fetch a Todo by its ID. \"\"\" todo = await select_todo ( current_app . db , id , int ( current_user . auth_id )) if todo is None : raise APIError ( 404 , \"NOT_FOUND\" ) else : return todo","title":"Reading a todo"},{"location":"backend/todo-api/#reading-the-todos","text":"For a RESTFul API the read route should be GET, returning a list of todos on success (we'll use the same rate limit). To demonstrate how to do server side filtering we'll provide a read route that can optionally filter on the complete todo attribute. The following should be added to backend/src/backend/blueprints/todos.py , from dataclasses import dataclass from typing import Optional from quart_schema import validate_querystring from models.todo import select_todos @dataclass class Todos : todos : list [ Todo ] @dataclass class TodoFilter : complete : Optional [ bool ] = None @blueprint . get ( \"/todos/\" ) @rate_limit ( 10 , timedelta ( seconds = 10 )) @login_required @validate_response ( Todos ) @validate_querystring ( TodoFilter ) async def get_todos ( query_args : TodoFilter ) -> Todos : \"\"\"Get the todos. Fetch all the Todos optionally based on the complete status. \"\"\" todos = await select_todos ( current_app . db , int ( current_user . auth_id ), query_args . complete ) return Todos ( todos = todos )","title":"Reading the todos"},{"location":"backend/todo-api/#updating-a-todo","text":"For a RESTFul API the todo update route should be PUT, expecting the todo data and returning the complete todo on success (we'll use the same rate limit) and a 404 if the todo does not exist. The following should be added to backend/src/backend/blueprints/todos.py , from models.todo import update_todo @blueprint . put ( \"/todos/<int:id>/\" ) @rate_limit ( 10 , timedelta ( seconds = 10 )) @login_required @validate_request ( TodoData ) @validate_response ( Todo ) async def put_todo ( id : int , data : TodoData ) -> Todo : \"\"\"Update the identified todo This allows the todo to be replaced with the request data. \"\"\" todo = await update_todo ( current_app . db , id , data , int ( current_user . auth_id )) if todo is None : raise APIError ( 404 , \"NOT_FOUND\" ) else : return todo","title":"Updating a todo"},{"location":"backend/todo-api/#deleting-a-todo","text":"For a RESTFul API the todo deletion route should be DELETE, returning 202 on success and if the todo does not exist (we'll use the same rate limit). The following should be added to backend/src/backend/blueprints/todos.py , from quart import ResponseReturnValue from models.todo import delete_todo @blueprint . delete ( \"/todos/<int:id>/\" ) @rate_limit ( 10 , timedelta ( seconds = 10 )) @login_required async def todo_delete ( id : int ) -> ResponseReturnValue : \"\"\"Delete the identified todo This will delete the todo. \"\"\" await delete_todo ( current_app . db , id , int ( current_user . auth_id )) return \"\" , 202","title":"Deleting a todo"},{"location":"backend/todo-api/#testing","text":"We should test that these routes work as a user would expect, starting by testing that the get route returns the test data todo by adding the following to backend/tests/blueprints/test_todos.py , import pytest from quart import Quart @pytest . mark . asyncio async def test_get_todo ( app : Quart ) -> None : test_client = app . test_client () async with test_client . authenticated ( \"1\" ): response = await test_client . get ( \"/todos/1/\" ) todo = await response . get_json () assert todo [ \"task\" ] == \"Task\" Next we can test creating, updating, retreiving and then deleting a todo i.e. the full user flow, by adding the following to backend/tests/blueprints/test_todos.py . @pytest . mark . asyncio async def test_todo_flow ( app : Quart ) -> None : test_client = app . test_client () async with test_client . authenticated ( \"1\" ): response = await test_client . get ( \"/todos/\" ) todos = ( await response . get_json ())[ \"todos\" ] response = await test_client . post ( \"/todos/\" , json = { \"complete\" : False , \"due\" : None , \"task\" : \"New Todo\" }, ) todo_id = ( await response . get_json ())[ \"id\" ] response = await test_client . get ( \"/todos/\" ) new_todos = ( await response . get_json ())[ \"todos\" ] assert len ( new_todos ) == len ( todos ) + 1 await test_client . put ( f \"/todos/ { todo_id } /\" , json = { \"complete\" : True , \"due\" : None , \"task\" : \"New Todo\" }, ) response = await test_client . get ( f \"/todos/ { todo_id } /\" ) todo = await response . get_json () assert todo [ \"complete\" ] await test_client . delete ( f \"/todos/ { todo_id } /\" ) response = await test_client . get ( \"/todos/\" ) final_todos = ( await response . get_json ())[ \"todos\" ] assert len ( final_todos ) == len ( todos )","title":"Testing"},{"location":"backend/validation/","text":"Clients, including the frontend you are writing, will often send the wrong data to the backend. The backend should therefore validate the structure and format of the data sent to it, and respond with a 400 response if it doesn't pass validation. We'll use the Quart extension Quart-Schema to validate the structure (schema) of the data sent to the backend, first by installing, poetry add quart-schema Then by activating the QuartSchema when creating the app in backend/src/backend/run.py , from quart_schema import QuartSchema schema = QuartSchema ( convert_casing = True , openapi_path = None ) def create_app () -> None : ... schema . init_app ( app ) ... We can then use Pydantic dataclasses to define and validate the data the backend expects to receive and to validate we send the correct data back to the frontend. It would be useful to provide an informative response if the client sends the wrong data, we can do this by adding the following error handler to be backend/src/backend/run.py ... from quart_schema import RequestSchemaValidationError def create_app () -> Quart : ... @app . errorhandler ( RequestSchemaValidationError ) # type: ignore async def handle_request_validation_error ( error : RequestSchemaValidationError , ) -> ResponseReturnValue : if isinstance ( error . validation_error , TypeError ): return { \"errors\" : str ( error . validation_error )}, 400 else : return { \"errors\" : error . validation_error . json ()}, 400","title":"Validation"},{"location":"deployment/aims/","text":"This project is to build a Todo app that users can use anywhere via a browser. Therefore the deployment needs to be accessible via the internet, specifically via a domain name. In addition we want to spend the minimal possible effort maintaining and deploying the app. Provider choices I've used Google Cloud , AWS , and Heroku to host applications in the past. Heroku is the easiest to get started with and therefore it is the best choice for this book. However we'll only use Heroku products that are available on the other clouds, for example we'll containerise the app rather than using Heroku's python deployment. The domain name is the identity of the website, control over it is crucial to prove ownership and to setup the hosting. For these reasons I prefer to use a different provider to manage the domain name alone and I trust Gandi to do so.","title":"Deployment aims"},{"location":"deployment/aims/#provider-choices","text":"I've used Google Cloud , AWS , and Heroku to host applications in the past. Heroku is the easiest to get started with and therefore it is the best choice for this book. However we'll only use Heroku products that are available on the other clouds, for example we'll containerise the app rather than using Heroku's python deployment. The domain name is the identity of the website, control over it is crucial to prove ownership and to setup the hosting. For these reasons I prefer to use a different provider to manage the domain name alone and I trust Gandi to do so.","title":"Provider choices"},{"location":"deployment/asgi/","text":"So far in development we've used app.run to run and serve the backend. Whilst this works well, it is explicitly not meant for production. Rather the ASGI server Hypercorn is recommended by Quart. It is also something I know very well as I'm the Hypercorn author. To use Hypercorn in the production environment we need to configure how it should work. I prefer to do this via a TOML configuration file. At this stage we should configure the logging, by adding the following to hypercorn.toml , accesslog = \"-\" access_log_format = \"%(t)s %(h)s %(f)s - %(S)s '%(r)s' %(s)s %(b)s %(D)s\" errorlog = \"-\" The hypercon server can be started via the following command, hypercorn --config hypercorn.toml 'run:create_app()' which we'll add to a short script backend/start , #!/bin/sh hypercorn --bind 0 .0.0.0: $PORT --config hypercorn.toml 'backend.run:create_app()' note that the port is set using an environment variable, as this will help us configure the server in Heroku.","title":"ASGI Server"},{"location":"deployment/cd/","text":"Deploying the app is an activity that is best done continuously and automatically. I'd optimise to make it as easy and as quick as possible to deploy, this way when bugs affect users they only do so for a short period. We can enable continuous deployment for our app by adding it to the Gitlab CI/CD script. To do this we first need credentials to interact with Heroku to be available to the Gitlab CI runner. We can do this by adding the following to infrastructure/gitlab.tf , resource \"gitlab_project_variable\" \"heroku_app\" { key = \"HEROKU_APP\" value = heroku_app.tozo.name project = gitlab_project.tozo.id protected = true } resource \"gitlab_project_variable\" \"heroku_token\" { key = \"HEROKU_API_KEY\" value = var.heroku_api_key project = gitlab_project.tozo.id protected = true } resource \"gitlab_project_variable\" \"heroku_username\" { key = \"HEROKU_USERNAME\" value = var.heroku_username project = gitlab_project.tozo.id protected = true } The deployment requires four steps, firstly we need to login to Heroku's docker repository, then build the docker image, followed by pushing it to Heroku's respository, and finally instruct Heroku to use our new image for the app. This is achieved by adding the following to .gitlab-ci.yml , heroku-cd : stage : deploy image : docker:latest services : - docker:dind before_script : - apk add --update curl script : - > docker login registry.heroku.com --username $HEROKU_USERNAME --password $HEROKU_API_KEY - > docker build --build-arg CI_COMMIT_SHA=$CI_COMMIT_SHA -t registry.heroku.com/$HEROKU_APP/web . - docker push registry.heroku.com/$HEROKU_APP/web - > curl --fail -X PATCH \"https://api.heroku.com/apps/$HEROKU_APP/formation\" -H 'Content-Type:application/json' -H 'Accept:application/vnd.herokujson; version=3.docker-releases' -H \"Authorization:Bearer $HEROKU_API_KEY\" -d '{\"updates\":[{\"type\":\"web\",\"docker_image\":\"'$(docker inspect registry.heroku.com/$HEROKU_APP/web --format={{.Id}})'\"}]}' only : - main To prevent us accidently trying to deploy a broken commit I've introduced stages to the CI, with the above being in the deploy stage. This is achieved by adding the following to .gitlab-ci.yml , stages : - lint-test - deploy and adding, stage : lint-test to the existing CI jobs.","title":"Continuous deployment"},{"location":"deployment/dns/","text":"We'll want a memorable domain name for users to find and identify our app. I've gone for tozo.dev which I've purchased from Gandi. Now we have a domain name we need visitors to it to find our app running on Heroku. This is where DNS comes in, DNS allows the visitor to lookup our domain name and find the location it is served from. We'll need to add the correct root DNS record so that it points at our Heroku app. To do so we should first delete any DNS records already assigned in Gandi - this is something that frustratingly we'll have to do manually. However after this we can use the Gandi Terraform provider, after activating it by adding the following to infrastructure/main.tf, terraform { required_providers { ... gandi = { version = \"2.0.0-rc2-fork-3\" source = \"manvalls/gandi\" } } } and running terraform init to initialise it. Next we should retreive an api key from Gand, and then add it to infrastructure/secrets.auto.tfvars , gandi_api_key = \"abcd\" Which we can use to configure the provider by adding the following to infrastructure/dns.tf , variable \"gandi_api_key\" { sensitive = true } provider \"gandi\" { key = var.gandi_api_key } As we only need to configure the root record as an ALIAS to the Heroku app CNAME we can add the following to infrastructure/dns.tf , data \"gandi_domain\" \"tozo_dev\" { name = \"tozo.dev\" } resource \"gandi_livedns_record\" \"tozo_dev_ALIAS\" { zone = data.gandi_domain.tozo_dev.id name = \"@\" type = \"ALIAS\" ttl = 3600 values = [ heroku_domain.tozo.cname ] } and the following to infrastructure/heroku.tf to ensure the Heroku app responds to the tozo.dev domain, resource \"heroku_domain\" \"tozo\" { app = heroku_app.tozo.name hostname = \"tozo.dev\" }","title":"Domain name & DNS"},{"location":"deployment/docker/","text":"To serve our app we need to setup the server by installing all the dependencies it requires to run (e.g. Python), then we need to copy over the latest code and finally run it. This combination is something that Docker makes easy to bundle together into a container image. A docker image can be built using a Dockerfile, which I find to be very expressive and clear. We can use a multi-stage Dockerfile to first build the frontend assets and then to create the server. Note Previously I've used scripts to install all the dependencies on a computer and then copied the code over (e.g. via rsync). Docker is an improvement on this as it allows this entire process to be managed in a single concise Dockerfile. Frontend stage The frontend stage is used to build the frontend assets i.e. bundle together the Javascript and css. It is separated from the production image as none of the dependencies required to build the frontend are required in production. Hence splitting the stages saves image size, and reduces the code that is susceptible to attack. As Docker images are built as a series of layers in the order given in the Dockerfile it is best to put layers that rarely change before those that change often. Hence npm install before the code is copied into the image. The following should be added to the Dockerfile file in the root of our repository. Firstly as we are using node 15 we should create the image from a node 15 image, FROM node:15-alpine as frontend we should then install all the dependencies to a /frontend/ folder, WORKDIR /frontend/ COPY frontend/package.json frontend/package-lock.json /frontend/ RUN npm install finally we can copy over our code and build the frontend, COPY frontend /frontend/ RUN npm run build Production image The production image must include everything required to serve the app in production. In our case this means it must run the backend, and have the frontend assets copied to the correct locations (see the serving blueprint ). The following should be added to the Dockerfile file following the frontend stage. Firstly as we are using Python 3.9 we should create the image from a Python 3.9 image, FROM python:3.9-alpine then we can copy over the hypercorn settings , instruct Docker to run the start script in the image (when the container starts), WORKDIR /app COPY start hypercorn.toml /app/ ENTRYPOINT [ \"dumb-init\" ] CMD [ \"./start\" ] Note We'll utilise dumb-init as our init system to ensure signals are correctly handled and processes are properly exited. next we can install the required system dependencies (brew does this locally) and setup a Python virtual environment, RUN apk --no-cache add alpine-sdk build-base cargo gcc git libffi-dev \\ musl-dev openssl openssl-dev RUN python -m venv /ve ENV PATH = /ve/bin: ${ PATH } and then the specific Python dependencies our project uses, RUN pip install --no-cache-dir dumb-init poetry RUN mkdir -p /app/db /app/backend/static /app/backend/templates /root/.config/pypoetry COPY backend/poetry.lock backend/pyproject.toml /app/ RUN poetry config virtualenvs.create false \\ && poetry install --no-root \\ && poetry cache clear pypi --all --no-interaction followed by copying over the frontend bundle, as built in the frontend stage above, COPY --from = frontend /frontend/build/index.html /app/backend/templates/ COPY --from = frontend /frontend/build/static/. /app/backend/static/ then our backend code (including the relevant database migrations), COPY backend/db/. /app/db/ COPY backend/src/ /app/ and finally switching user to nobody so that our code doesn't run as root in the contianer, USER nobody","title":"Docker"},{"location":"deployment/docker/#frontend-stage","text":"The frontend stage is used to build the frontend assets i.e. bundle together the Javascript and css. It is separated from the production image as none of the dependencies required to build the frontend are required in production. Hence splitting the stages saves image size, and reduces the code that is susceptible to attack. As Docker images are built as a series of layers in the order given in the Dockerfile it is best to put layers that rarely change before those that change often. Hence npm install before the code is copied into the image. The following should be added to the Dockerfile file in the root of our repository. Firstly as we are using node 15 we should create the image from a node 15 image, FROM node:15-alpine as frontend we should then install all the dependencies to a /frontend/ folder, WORKDIR /frontend/ COPY frontend/package.json frontend/package-lock.json /frontend/ RUN npm install finally we can copy over our code and build the frontend, COPY frontend /frontend/ RUN npm run build","title":"Frontend stage"},{"location":"deployment/docker/#production-image","text":"The production image must include everything required to serve the app in production. In our case this means it must run the backend, and have the frontend assets copied to the correct locations (see the serving blueprint ). The following should be added to the Dockerfile file following the frontend stage. Firstly as we are using Python 3.9 we should create the image from a Python 3.9 image, FROM python:3.9-alpine then we can copy over the hypercorn settings , instruct Docker to run the start script in the image (when the container starts), WORKDIR /app COPY start hypercorn.toml /app/ ENTRYPOINT [ \"dumb-init\" ] CMD [ \"./start\" ] Note We'll utilise dumb-init as our init system to ensure signals are correctly handled and processes are properly exited. next we can install the required system dependencies (brew does this locally) and setup a Python virtual environment, RUN apk --no-cache add alpine-sdk build-base cargo gcc git libffi-dev \\ musl-dev openssl openssl-dev RUN python -m venv /ve ENV PATH = /ve/bin: ${ PATH } and then the specific Python dependencies our project uses, RUN pip install --no-cache-dir dumb-init poetry RUN mkdir -p /app/db /app/backend/static /app/backend/templates /root/.config/pypoetry COPY backend/poetry.lock backend/pyproject.toml /app/ RUN poetry config virtualenvs.create false \\ && poetry install --no-root \\ && poetry cache clear pypi --all --no-interaction followed by copying over the frontend bundle, as built in the frontend stage above, COPY --from = frontend /frontend/build/index.html /app/backend/templates/ COPY --from = frontend /frontend/build/static/. /app/backend/static/ then our backend code (including the relevant database migrations), COPY backend/db/. /app/db/ COPY backend/src/ /app/ and finally switching user to nobody so that our code doesn't run as root in the contianer, USER nobody","title":"Production image"},{"location":"deployment/heroku/","text":"We've chosen to use Heroku to host the app, yet we'll avoid any Heroku specific features so that we can easily move the app elsewhere as required. To start we need to activate the Heroku Terraform provider by adding the following to infrastructure/main.tf , terraform { required_providers { ... heroku = { source = \"heroku/heroku\" version = \">=4.6.0\" } } } and running terraform init to initialise it. Next we should register with Heroku and retreive an api key from the settings, and then add it and your username to infrastructure/secrets.auto.tfvars , heroku_api_key = \"abcd\" heroku_username = \"you@something.tld\" Which we can use to configure the provider by adding the following to infrastructure/heroku.tf , variable \"heroku_api_key\" { sensitive = true } variable \"heroku_username\" { sensitive = true } provider \"heroku\" { email = var.heroku_username api_key = var.heroku_api_key } Heroku splits deployments into apps and we'll need one for our app. This should be based in the eu or us and use the container stack (as we'll deploy our docker container). In addition we should add the minimal configuration, consisting of a secret key and a base url. The following should be added to infrastructure/heroku.tf , variable \"secret_key\" { sensitive = true } resource \"heroku_app\" \"tozo\" { name = \"tozo\" region = \"eu\" stack = \"container\" config_vars = { BASE_URL = \"https://tozo.dev\" } sensitive_config_vars = { SECRET_KEY = var.secret_key } } Note You'll need to create a value for the secret key and place it in infrastructure/secrets.auto.tfvars . We'll then need to add a postgresql database to this app by adding the following to infrastructure/heroku.tf , resource \"heroku_addon\" \"tozo-db\" { app = heroku_app.tozo.name plan = \"heroku-postgresql:hobby-dev\" } Fortunately this adds the DATABASE_URL environment (config) variable for us. Tip After the first deployment you may want to define a formation, which is Heroku's term for the actual instances that run the app. We want a web formation, which is defined by adding the following to infrastructure/heroku.tf , resource \"heroku_formation\" \"tozo-web\" { app = heroku_app.tozo.name type = \"web\" quantity = 1 size = \"Hobby\" } We've used small hobby instances for the DB and app instances, you may want bigger machines depending on your workload.","title":"Heroku"},{"location":"deployment/serving-api/","text":"In the production environment we will use the backend to serve the frontend (in development we used the frontend to serve itself and proxy requests to the backend). Creating the blueprint The blueprint itself can be created with the following code in backend/src/backend/blueprints/serving.py , from quart import Blueprint blueprint = Blueprint ( \"serving\" , __name__ ) and activated by adding the following to backend/src/backend/run.py , from backend.blueprints.serving import blueprint as serving_blueprint def create_app () -> Quart : ... app . register_blueprint ( serving_blueprint ) Serving static assets Quart will by default serve any assets placed in the backend/src/backend/static/ ( app.root_path / static ) directory. So there is nothing for us to do here other than ensure that static assets are placed in this directory. Serving pages As the frontend routes paths to the displayed page the backend has no knowledge which paths are valid. For this reason the route handler should serve any path and let the frontend decide if it is valid or not. This is done in quart using a <path:path> url variable. In addition the served page should be as secure as we can make it using secure headers, such as a Content Security Policy , and various others. The following should be added to backend/src/backend/blueprints/serving.py , from typing import Optional from quart import make_response , render_template , ResponseReturnValue from quart_rate_limiter import rate_exempt from werkzeug.http import COEP , COOP @blueprint . route ( \"/\" ) @blueprint . route ( \"/<path:path>\" ) @rate_exempt async def index ( path : Optional [ str ] = None ) -> ResponseReturnValue : response = await make_response ( await render_template ( \"index.html\" )) response . headers [ \"Content-Security-Policy\" ] = \"\" response . content_security_policy . default_src = \"'self'\" response . content_security_policy . base_uri = \"'self'\" response . content_security_policy . font_src = \"'self' data:\" response . content_security_policy . form_action = \"'self'\" response . content_security_policy . frame_ancestors = \"'none'\" response . content_security_policy . img_src = \"'self' data:\" response . content_security_policy . style_src = \"'self' 'unsafe-inline'\" response . cross_origin_embedder_policy = COEP . REQUIRE_CORP response . cross_origin_opener_policy = COOP . SAME_ORIGIN response . headers [ \"Referrer-Policy\" ] = \"no-referrer, strict-origin-when-cross-origin\" response . headers [ \"Strict-Transport-Security\" ] = \"max-age=63072000; includeSubDomains; preload\" response . headers [ \"X-Content-Type-Options\" ] = \"nosniff\" response . headers [ \"X-Frame-Options\" ] = \"SAMEORIGIN\" response . headers [ \"X-XSS-Protection\" ] = \"1; mode=block\" return response Note The frontend build creates an index.html which should be placed in the backend/src/backend/templates folder and creates static files that should be placed in the backend/src/backend/static folder for the above to work. See the Docker section for more.","title":"Serving blueprint"},{"location":"deployment/serving-api/#creating-the-blueprint","text":"The blueprint itself can be created with the following code in backend/src/backend/blueprints/serving.py , from quart import Blueprint blueprint = Blueprint ( \"serving\" , __name__ ) and activated by adding the following to backend/src/backend/run.py , from backend.blueprints.serving import blueprint as serving_blueprint def create_app () -> Quart : ... app . register_blueprint ( serving_blueprint )","title":"Creating the blueprint"},{"location":"deployment/serving-api/#serving-static-assets","text":"Quart will by default serve any assets placed in the backend/src/backend/static/ ( app.root_path / static ) directory. So there is nothing for us to do here other than ensure that static assets are placed in this directory.","title":"Serving static assets"},{"location":"deployment/serving-api/#serving-pages","text":"As the frontend routes paths to the displayed page the backend has no knowledge which paths are valid. For this reason the route handler should serve any path and let the frontend decide if it is valid or not. This is done in quart using a <path:path> url variable. In addition the served page should be as secure as we can make it using secure headers, such as a Content Security Policy , and various others. The following should be added to backend/src/backend/blueprints/serving.py , from typing import Optional from quart import make_response , render_template , ResponseReturnValue from quart_rate_limiter import rate_exempt from werkzeug.http import COEP , COOP @blueprint . route ( \"/\" ) @blueprint . route ( \"/<path:path>\" ) @rate_exempt async def index ( path : Optional [ str ] = None ) -> ResponseReturnValue : response = await make_response ( await render_template ( \"index.html\" )) response . headers [ \"Content-Security-Policy\" ] = \"\" response . content_security_policy . default_src = \"'self'\" response . content_security_policy . base_uri = \"'self'\" response . content_security_policy . font_src = \"'self' data:\" response . content_security_policy . form_action = \"'self'\" response . content_security_policy . frame_ancestors = \"'none'\" response . content_security_policy . img_src = \"'self' data:\" response . content_security_policy . style_src = \"'self' 'unsafe-inline'\" response . cross_origin_embedder_policy = COEP . REQUIRE_CORP response . cross_origin_opener_policy = COOP . SAME_ORIGIN response . headers [ \"Referrer-Policy\" ] = \"no-referrer, strict-origin-when-cross-origin\" response . headers [ \"Strict-Transport-Security\" ] = \"max-age=63072000; includeSubDomains; preload\" response . headers [ \"X-Content-Type-Options\" ] = \"nosniff\" response . headers [ \"X-Frame-Options\" ] = \"SAMEORIGIN\" response . headers [ \"X-XSS-Protection\" ] = \"1; mode=block\" return response Note The frontend build creates an index.html which should be placed in the backend/src/backend/templates folder and creates static files that should be placed in the backend/src/backend/static folder for the above to work. See the Docker section for more.","title":"Serving pages"},{"location":"deployment/ssl/","text":"It is best practice, to ensure communication between the user and the app's server be encrypted. It is essential however when the communication consists of sensitive information such as the user's password. As it is quite easy to enable this encryption I'd recommend only using encrypted communication. To do so we can utilise HTTPS using SSL (or TLS) which is widely supported and easy to use. To do so we need to get a certificate that browsers will recognise. Fortunately Let's Encrypt will issue us a certificate for free. Let's Encrypt is usable with Terraform via the acme provider, which is activated by adding the following to infrastructure/main.tf , terraform { required_providers { ... acme = { source = \"vancluever/acme\" version = \"~> 2.0\" } } } and running terraform init to initialise it. To acquire a certificate for a domain name we'll need to prove to Let's Encrypt that we control the domain name. Fortunately this is doable via the acme provider via the following added to infrastructure/certs.tf , provider \"acme\" { server_url = \"https://acme-v02.api.letsencrypt.org/directory\" } resource \"tls_private_key\" \"private_key\" { algorithm = \"RSA\" } resource \"acme_registration\" \"me\" { account_key_pem = tls_private_key.private_key.private_key_pem email_address = var.heroku_username } resource \"acme_certificate\" \"tozo_dev\" { account_key_pem = acme_registration.me.account_key_pem common_name = \"tozo.dev\" dns_challenge { provider = \"gandiv5\" config = { GANDIV5_API_KEY = var.gandi_api_key } } } Now we have a certificate we can ask Heroku to use it when serving our app, via the following additions to infrastructure/heroku.tf , resource \"heroku_domain\" \"tozo\" { ... sni_endpoint_id = heroku_ssl.tozo_dev.id } resource \"heroku_ssl\" \"tozo_dev\" { app_id = heroku_app.tozo.uuid certificate_chain = \"${acme_certificate.tozo_dev.certificate_pem}${acme_certificate.tozo_dev.issuer_pem}\" private_key = acme_certificate.tozo_dev.private_key_pem depends_on = [ heroku_formation.tozo-web ] }","title":"SSL"},{"location":"frontend/aims/","text":"This project is to build a todo app that stores and allows editing of a user's todos. Therefore the frontend needs to provide interfaces to Register a new account, including confirming the email Login and logout, and changing the password Manage TODOs (creating, editing, completing, and deleting) ideally as a Single Page App (for a better user experience) and provide the ability to become a progressive web app. Tech choices To do this I've chosen to use React as the base framework with various libraries to add additional functionality.","title":"Frontend aims"},{"location":"frontend/aims/#tech-choices","text":"To do this I've chosen to use React as the base framework with various libraries to add additional functionality.","title":"Tech choices"},{"location":"frontend/authentication/","text":"Many parts of the app, e.g. the routing, will need to know if the user is currently logged in (authenticated). This is made available via a React context, specifically an AuthContext as defined in frontend/src/AuthContext.tsx , as, import React from \"react\" ; interface IAuth { authenticated : boolean ; setAuthenticated : ( value : boolean ) => void ; } export const AuthContext = React . createContext < IAuth > ({ authenticated : true , setAuthenticated : ( value : boolean ) => {}, }); interface IProps { children? : React.ReactNode ; } export const AuthContextProvider = ({ children } : IProps ) => { const [ authenticated , setAuthenticated ] = React . useState ( true ); return ( < AuthContext . Provider value = {{ authenticated , setAuthenticated }} > { children } < /AuthContext.Provider> ); }; which allows the authentication state to be used in any component via a useContext hook, import { AuthContext } from \"AuthContext\" ; ... const { authenticated } = React . useContext ( AuthContext ); when setup and initialised by adding the following to src/App.tsx , ... import { AuthContextProvider } from \"src/AuthContext\" ; const App = () => { ... return ( < AuthContextProvider > ... < /AuthContextProvider> ); }","title":"Authentication Context"},{"location":"frontend/change-password-page/","text":"The user will need a way to change their password, which should only be available if they are logged in and they provide their existing password. In addition as they are logged in, we can help prompt them if they get their existing password wrong. Finally as with the registration and reset password pages we can use a metered password to let the user know how strong their new password is. The following should be added to frontend/src/pages/ChangePassword.tsx , import Box from \"@material-ui/core/Box\" ; import Typography from \"@material-ui/core/Typography\" ; import axios from \"axios\" ; import { Form , Formik , FormikHelpers } from \"formik\" ; import React , { Suspense , useContext } from \"react\" ; import { useTranslation } from \"react-i18next\" ; import * as yup from \"yup\" ; import PasswordField from \"src/components/PasswordField\" ; import SecondaryButton from \"src/components/SecondaryButton\" ; import SubmitButton from \"src/components/SubmitButton\" ; import { useMutation } from \"src/query\" ; import { ToastContext } from \"src/ToastContext\" ; const MeteredPasswordField = React . lazy ( () => import ( \"src/components/MeteredPasswordField\" ), ); interface IForm { currentPassword : string ; newPassword : string ; } const ChangePassword = () => { const { t } = useTranslation (); const { addToast } = useContext ( ToastContext ); const { mutateAsync : changePassword } = useMutation ( async ( data : IForm ) => { await axios . put ( \"/members/password/\" , data ); }); const validationSchema = yup . object ({ currentPassword : yup.string (). required ( t ( \"generic.required\" )), newPassword : yup.string (). required ( t ( \"generic.required\" )), }); const onSubmit = async ( data : IForm , { setFieldError } : FormikHelpers < IForm > , ) => { await changePassword ( data , { onError : ( error ) => { if ( error . response ) { if ( error . response . status === 400 ) { setFieldError ( \"newPassword\" , t ( \"generic.weakPassword\" )); } else if ( error . response . status === 401 ) { setFieldError ( \"currentPassword\" , t ( \"ChangePassword.incorrectPassword\" ), ); } else { addToast ({ category : \"error\" , message : t ( \"generic.tryAgainError\" ), }); } } else { addToast ({ category : \"error\" , message : t ( \"generic.tryAgainError\" ) }); } }, }); }; return ( <> < Box mb = { 1 } mt = { 2 } > < Typography component = \"h1\" variant = \"h5\" > { t ( \"ChangePassword.lead\" )} < /Typography> < /Box> < Formik < IForm > initialValues = {{ currentPassword : \"\" , newPassword : \"\" , }} onSubmit = { onSubmit } validationSchema = { validationSchema } > {({ isSubmitting }) => ( < Form > < PasswordField autoComplete = \"current-password\" fullWidth = { true } label = { t ( \"generic.password\" )} name = \"currentPassword\" required = { true } /> < Suspense fallback = { < PasswordField autoComplete = \"new-password\" fullWidth = { true } label = { t ( \"ChangePassword.newPassword\" )} name = \"newPassword\" required = { true } /> } > < MeteredPasswordField autoComplete = \"new-password\" fullWidth = { true } label = { t ( \"ChangePassword.newPassword\" )} name = \"newPassword\" required = { true } /> < /Suspense> < SubmitButton label = { t ( \"ChangePassword.change\" )} submitting = { isSubmitting } /> < SecondaryButton label = { t ( \"generic.back\" )} to = \"/todos/\" /> < /Form> )} < /Formik> < /> ); }; export default ChangePassword ; Then we can add the page to the routing by adding the following to frontend/src/Router.tsx , import PrivateRoute from \"src/components/PrivateRoute\" ; import ChangePassword from \"src/pages/ChangePassword\" ; ... const Router = () => ( < BrowserRouter > ... < PrivateRoute exact = { true } path = \"/change-password/\" > < ChangePassword /> < /PrivateRoute> < /BrowserRouter> );","title":"Change password"},{"location":"frontend/configuration/","text":"First lets setup a couple of small configuration options that will make the following pages easier. Proxying requests In development we will want api requests to be proxied to the backend, which we can simply do by adding to frontend/package.json , { ... , \"proxy\" : \"http://localhost:5000\" } Absolute imports It is much easier to write imports relative to the src directory, which I'll term absolute, than to write relative imports i.e. components/Component is eaiser than ../../components/Component especially when refactoring code. To achieve this the frontend/tsconfig.json file should be updated to include, { ... \"compilerOptions\" : { \"baseUrl\" : \"./\" , ... }, } where ... represnts the existing values. Globally unique ids We will need to assign unique id values to dom elements, often to improve accessibility, which we can do using React-UID . React-UID is installed via npm, npm install --save react-uid","title":"Project configuration"},{"location":"frontend/configuration/#proxying-requests","text":"In development we will want api requests to be proxied to the backend, which we can simply do by adding to frontend/package.json , { ... , \"proxy\" : \"http://localhost:5000\" }","title":"Proxying requests"},{"location":"frontend/configuration/#absolute-imports","text":"It is much easier to write imports relative to the src directory, which I'll term absolute, than to write relative imports i.e. components/Component is eaiser than ../../components/Component especially when refactoring code. To achieve this the frontend/tsconfig.json file should be updated to include, { ... \"compilerOptions\" : { \"baseUrl\" : \"./\" , ... }, } where ... represnts the existing values.","title":"Absolute imports"},{"location":"frontend/configuration/#globally-unique-ids","text":"We will need to assign unique id values to dom elements, often to improve accessibility, which we can do using React-UID . React-UID is installed via npm, npm install --save react-uid","title":"Globally unique ids"},{"location":"frontend/confirm-email-page/","text":"The confirm email page like the reset password page is only accessed via a link sent to the user in an email. This link contains a token which we need to send to the backend thereby proving the user has access to the email address. It is therefore a fairly simple page that sends data and then redirects the user to the homepage. To make the experience better for the user we'll display a progress element to indicate that something is happening whilst the request to the backend is made. The following should be added to frontend/src/pages/ConfirmEmail.tsx , import Box from \"@material-ui/core/Box\" ; import LinearProgress from \"@material-ui/core/LinearProgress\" ; import axios from \"axios\" ; import React , { useContext } from \"react\" ; import { useTranslation } from \"react-i18next\" ; import { useParams } from \"react-router\" ; import { Redirect } from \"react-router-dom\" ; import { useQuery } from \"src/query\" ; import { ToastContext } from \"src/ToastContext\" ; interface IParams { token? : string ; } const ConfirmEmail = () => { const { t } = useTranslation (); const { addToast } = useContext ( ToastContext ); const params = useParams < IParams > (); const token = params . token ?? \"\" ; const { isLoading } = useQuery ( \"Email\" , async () => { await axios . put ( \"/members/email/\" , { token }); }, { onError : ( error ) => { if ( error . response ? . status === 400 ) { if ( error . response . data . code === \"TOKEN_INVALID\" ) { addToast ({ category : \"error\" , message : t ( \"generic.invalidToken\" ) }); } else if ( error . response . data . code === \"TOKEN_EXPIRED\" ) { addToast ({ category : \"error\" , message : t ( \"generic.expiredToken\" ) }); } } else { addToast ({ category : \"error\" , message : t ( \"generic.tryAgainError\" ) }); } }, onSuccess : () => { addToast ({ category : \"success\" , message : t ( \"generic.thanks\" ) }); }, }, ); if ( isLoading ) { return ( < Box mt = { 4 } > < LinearProgress /> < /Box> ); } else { return < Redirect to = \"/\" /> ; } }; export default ConfirmEmail ; Then we can add the page to the routing by adding the following to frontend/src/Router.tsx , import ConfirmEmail from \"src/pages/ConfirmEmail\" ; ... const Router = () => ( < BrowserRouter > ... < Route exact = { true } path = \"/confirm-email/:token/\" > < ConfirmEmail /> < /Route> < /BrowserRouter> );","title":"Confirm email"},{"location":"frontend/css-in-js/","text":"Placing the css to style components next to the code (within the JS) makes it much easier to manage and understand, compared to placing the css in a separate file. There are many options to do this, including a built in styling system for Material-UI, however I find styled-components to be the best. Styled-components is installed via npm, npm install --save styled-components npm install --save-dev @types/styled-components which installed 5.2.1. Normalizing Each browser applies differing css styles to elements meaning that it is possible that your pages will look different in each browser making it harder to have a correct and consistent product. These differences can be normalized using normalize.css via the styled-normalize package, npm install --save styled-normalize which installed 8.0.7. It is used by adding to the frontend/src/App.tsx as the first child of the <StylesProvider> element, import { Normalize } from \"styled-normalize\" ; ... const App = () => { ... return ( <> < Normalize /> ... < /> ); } Theming Styled-components allows for themes to be used, which is helpful as they provide a singular location to define the colour palette, spacing, etc... A theme is an associate array that maps any named property to a value, which in order to work with Typescript requires the following in frontend/src/styled.d.ts , (assuming you export a theme from frontend/src/theme.ts - see Material-UI ), import {} from \"styled-components\" ; import theme from \"theme\" ; declare module \"styled-components\" { type Theme = typeof theme ; export interface DefaultTheme extends Theme {} }","title":"CSS in JS"},{"location":"frontend/css-in-js/#normalizing","text":"Each browser applies differing css styles to elements meaning that it is possible that your pages will look different in each browser making it harder to have a correct and consistent product. These differences can be normalized using normalize.css via the styled-normalize package, npm install --save styled-normalize which installed 8.0.7. It is used by adding to the frontend/src/App.tsx as the first child of the <StylesProvider> element, import { Normalize } from \"styled-normalize\" ; ... const App = () => { ... return ( <> < Normalize /> ... < /> ); }","title":"Normalizing"},{"location":"frontend/css-in-js/#theming","text":"Styled-components allows for themes to be used, which is helpful as they provide a singular location to define the colour palette, spacing, etc... A theme is an associate array that maps any named property to a value, which in order to work with Typescript requires the following in frontend/src/styled.d.ts , (assuming you export a theme from frontend/src/theme.ts - see Material-UI ), import {} from \"styled-components\" ; import theme from \"theme\" ; declare module \"styled-components\" { type Theme = typeof theme ; export interface DefaultTheme extends Theme {} }","title":"Theming"},{"location":"frontend/fetching/","text":"We will need to make requests from the frontend to the backend to retrieve the todo data and to carry out any action related to them. To do this we'll use axios as it has a nice API for sending and receiving JSON. Axios is installed via npm, npm install --save axios","title":"Fetching data"},{"location":"frontend/forgotten-page/","text":"The forgotten password page exists to allow users to request a password reset email when they have forgotten their password. We therefore need the user to enter their email and then we'll use the members API to send them a password reset email or if that fails display a generic error. This page is helpful to the user, but doesn't add any value, so we'll need to make it as quick and easy to complete as possible, by only asking for their email address. User's are likely to navigate between the registration, login, and forgotten password pages as they often can't remember if they have an account or what the password was. For this reason we can reduce their effort by persisting any email address they've typed in across these pages and offer links between the pages. The following code to do all this should be placed in frontend/src/pages/ForgottenPassword.tsx , import Box from \"@material-ui/core/Box\" ; import Typography from \"@material-ui/core/Typography\" ; import axios from \"axios\" ; import { Form , Formik } from \"formik\" ; import React , { useContext } from \"react\" ; import { useTranslation } from \"react-i18next\" ; import { useHistory , useLocation } from \"react-router\" ; import * as yup from \"yup\" ; import EmailField from \"src/components/EmailField\" ; import SecondaryButton from \"src/components/SecondaryButton\" ; import SubmitButton from \"src/components/SubmitButton\" ; import { useMutation } from \"src/query\" ; import { ToastContext } from \"src/ToastContext\" ; interface IForm { email : string ; } interface ILocationState { email? : string ; } const ForgottenPassword = () => { const { t } = useTranslation (); const history = useHistory (); const location = useLocation < ILocationState > (); const { addToast } = useContext ( ToastContext ); const { mutateAsync : forgottenPassword } = useMutation ( async ( data : IForm ) => { await axios . post ( \"/members/forgotten-password/\" , data ); }, ); const validationSchema = yup . object ({ email : yup . string () . email ( t ( \"generic.emailRequired\" )) . required ( t ( \"generic.required\" )), }); const onSubmit = async ( data : IForm ) => { try { await forgottenPassword ( data ); addToast ({ category : \"success\" , message : t ( \"ForgottenPassword.success\" ), }); history . push ( \"/login/\" ); } catch { addToast ({ category : \"error\" , message : t ( \"generic.tryAgainError\" ) }); } }; return ( <> < Box mb = { 1 } mt = { 2 } > < Typography component = \"h1\" variant = \"h5\" > { t ( \"ForgottenPassword.lead\" )} < /Typography> < /Box> < Formik < IForm > initialValues = {{ email : location.state?.email ?? \"\" , }} onSubmit = { onSubmit } validationSchema = { validationSchema } > {({ isSubmitting , values }) => ( < Form > < EmailField fullWidth = { true } label = { t ( \"generic.email\" )} name = \"email\" required = { true } /> < SubmitButton label = { t ( \"ForgottenPassword.submit\" )} submitting = { isSubmitting } /> < SecondaryButton label = { t ( \"generic.register\" )} to = {{ pathname : \"/register/\" , state : { email : values.email }, }} /> < SecondaryButton label = { t ( \"generic.login\" )} to = {{ pathname : \"/login/\" , state : { email : values.email }, }} /> < /Form> )} < /Formik> < /> ); }; export default ForgottenPassword ; Then we can add the page to the routing by adding the following to frontend/src/Router.tsx , import ForgottenPassword from \"src/pages/ForgottenPassword\" ; ... const Router = () => ( < BrowserRouter > ... < Route exact = { true } path = \"/forgotten-password/\" > < ForgottenPassword /> < /Route> < /BrowserRouter> );","title":"Forgotten password"},{"location":"frontend/forms/","text":"Building forms with a good user experience takes a lot of effort, for example the touched, error, and focused states must be managed for each field. This is made much easier by using Formik to handle the states and yup to validate the data. Formik and yup are installed via npm, npm install --save formik yup Integrating Formik with Material-UI Formik integrates nicely with Material-UI components via Formik's useField hook. This hook takes care of the form state aspects, but doesn't account for any label, helper text or required marker which will need to be specified by props. I like the styling of outlined inputs with normal margins, which is what I'll use in the components below. Checkbox Field We'll need a checkbox field to indicate if a Todo is complete or to indicate that the user should be remembered on login. The following should be added to frontend/src/components/CheckboxField.tsx , import Checkbox from \"@material-ui/core/Checkbox\" ; import FormControl from \"@material-ui/core/FormControl\" ; import FormControlLabel from \"@material-ui/core/FormControlLabel\" ; import FormHelperText from \"@material-ui/core/FormHelperText\" ; import { FieldHookConfig , useField } from \"formik\" ; import React from \"react\" ; type IProps = FieldHookConfig < boolean > & { fullWidth? : boolean ; helperText? : string ; label : string ; required? : boolean ; }; const CheckboxField = ( props : IProps ) => { const [ field , meta ] = useField < boolean > ( props ); let helperText : any ; if ( Boolean ( meta . error ) && meta . touched ) { helperText = ` ${ meta . error } . ${ props . helperText ?? \"\" } ` ; } else { helperText = props . helperText ; } return ( < FormControl component = \"fieldset\" error = { Boolean ( meta . error ) && meta . touched } fullWidth = { props . fullWidth } margin = \"normal\" required = { props . required } > < FormControlLabel control = { < Checkbox {... field } checked = { field . value } /> } label = { props . label } /> < FormHelperText > { helperText } < /FormHelperText> < /FormControl> ); }; export default CheckboxField ; Date Field We'll need a date field for the user to specify a due date for a Todo. The following should be added to frontend/src/components/DateField.tsx , import MUITextField , { TextFieldProps } from \"@material-ui/core/TextField\" ; import { format , parseISO } from \"date-fns\" ; import { FieldHookConfig , useField } from \"formik\" ; import React from \"react\" ; import { useUID } from \"react-uid\" ; const DateField = ( props : FieldHookConfig < Date > & TextFieldProps ) => { const id = useUID (); const [ field , meta , helpers ] = useField < Date > ( props ); let helperText : any ; if ( Boolean ( meta . error ) && meta . touched ) { helperText = ` ${ meta . error } . ${ props . helperText ?? \"\" } ` ; } else { helperText = props . helperText ; } const value = field . value ? format ( field . value , \"yyyy-MM-dd\" ) : \"\" ; return ( < MUITextField {... props } error = { Boolean ( meta . error ) && meta . touched } helperText = { helperText } id = { id } InputLabelProps = {{ shrink : true , }} margin = \"normal\" type = \"date\" variant = \"outlined\" {... field } onChange = {( event ) => { if ( event . target . value ) { helpers . setValue ( parseISO ( event . target . value )); } else { helpers . setValue ( null ); } }} value = { value } /> ); }; export default DateField ; Note that the label must always be in the shrunk state to stop it overlapping with any input mask added by the browser. Email Field We'll need an email field for the user to login. The following should be added to frontend/src/components/EmailField.tsx , import MUITextField , { TextFieldProps } from \"@material-ui/core/TextField\" ; import { FieldHookConfig , useField } from \"formik\" ; import React from \"react\" ; import { useUID } from \"react-uid\" ; const EmailField = ( props : FieldHookConfig < string > & TextFieldProps ) => { const id = useUID (); const [ field , meta ] = useField < string > ( props ); let helperText : any ; if ( Boolean ( meta . error ) && meta . touched ) { helperText = ` ${ meta . error } . ${ props . helperText ?? \"\" } ` ; } else { helperText = props . helperText ; } return ( < MUITextField {... props } autoComplete = \"email\" error = { Boolean ( meta . error ) && meta . touched } helperText = { helperText } id = { id } margin = \"normal\" type = \"email\" variant = \"outlined\" {... field } /> ); }; export default EmailField ; Password Field We'll need the password field for the user to login and change their password. Unlike the other fields the password field has a button to toggle visibility of the password, which helps the user get their password correct. Note though this button is taken out of the tab flow, as users don't expect to tab onto this button. The following should be added to frontend/src/components/PasswordField.tsx , import IconButton from \"@material-ui/core/IconButton\" ; import InputAdornment from \"@material-ui/core/InputAdornment\" ; import MUITextField , { TextFieldProps } from \"@material-ui/core/TextField\" ; import Visibility from \"@material-ui/icons/Visibility\" ; import VisibilityOff from \"@material-ui/icons/VisibilityOff\" ; import { FieldHookConfig , useField } from \"formik\" ; import React from \"react\" ; import { useUID } from \"react-uid\" ; const PasswordField = ( props : FieldHookConfig < string > & TextFieldProps ) => { const id = useUID (); const [ field , meta ] = useField < string > ( props ); const [ showPassword , setShowPassword ] = React . useState ( false ); let helperText : any ; if ( Boolean ( meta . error ) && meta . touched ) { helperText = ` ${ meta . error } . ${ props . helperText ?? \"\" } ` ; } else { helperText = props . helperText ; } return ( < MUITextField {... props } InputProps = {{ endAdornment : ( < InputAdornment position = \"end\" > < IconButton onClick = {() => setShowPassword (( value ) => ! value )} tabIndex = { - 1 } > { showPassword ? < Visibility /> : < VisibilityOff /> } < /IconButton> < /InputAdornment> ), }} error = { Boolean ( meta . error ) && meta . touched } helperText = { helperText } id = { id } margin = \"normal\" type = { showPassword ? \"text\" : \"password\" } variant = \"outlined\" {... field } /> ); }; export default PasswordField ; Text Field We'll also need a text field for content of a todo. The following should be added to frontend/src/components/TextField.tsx , import MUITextField , { TextFieldProps } from \"@material-ui/core/TextField\" ; import { FieldHookConfig , useField } from \"formik\" ; import React from \"react\" ; import { useUID } from \"react-uid\" ; const TextField = ( props : FieldHookConfig < string > & TextFieldProps ) => { const id = useUID (); const [ field , meta ] = useField < string > ( props ); let helperText : any ; if ( Boolean ( meta . error ) && meta . touched ) { helperText = ` ${ meta . error } . ${ props . helperText ?? \"\" } ` ; } else { helperText = props . helperText ; } return ( < MUITextField {... props } error = { Boolean ( meta . error ) && meta . touched } helperText = { helperText } id = { id } margin = \"normal\" type = \"text\" variant = \"outlined\" {... field } /> ); }; export default TextField ; Submit Button We should also allow the user to submit the form and show an indication that it is processing i.e. while the request to the backend is taking place. I like to do this by disabling the button and adding a circular spinner over the top whilst the submission is processing. The following should be added to frontend/src/components/SubmitButton.tsx , import Button from \"@material-ui/core/Button\" ; import CircularProgress from \"@material-ui/core/CircularProgress\" ; import React from \"react\" ; import styled from \"styled-components\" ; interface IDivProps { fullwidth? : boolean ; } const SDiv = styled . div < IDivProps > ` align-items: center; display: inline-flex; margin-bottom: 8px; margin-right: 8px; margin-top: 16px; position: relative; width: ${ ( props ) => ( props . fullwidth ? \"100%\" : \"initial\" ) } ; & svg { margin-left: 4px; } & .MuiCircularProgress-root { left: 50%; margin-left: -12px; margin-top: -12px; position: absolute; top: 50%; } & .MuiCircularProgress-root svg { margin: 2px; } ` ; interface IProps { className? : string ; fullWidth? : boolean ; label : string ; submitting? : boolean ; } const SubmitButton = ({ className , label , submitting , fullWidth , } : IProps ) : JSX . Element => ( < SDiv className = { className } fullwidth = { fullWidth } > < Button color = \"primary\" disabled = { submitting } fullWidth = { fullWidth } type = \"submit\" variant = \"contained\" > { label } < /Button> { submitting ? < CircularProgress size = { 24 } /> : null } < /SDiv> ); export default SubmitButton ; Note the styling is required to position the CircularProgress element in the center of the Button. Secondary button Finally we will need a way for the user to change their mind and visit another page, or simply go back i.e. perform a secondary action other than submitting the form. The following should be added to frontend/src/components/SecondaryButton.tsx , import Button from \"@material-ui/core/Button\" ; import React from \"react\" ; import { Link , LinkProps } from \"react-router-dom\" ; import styled from \"styled-components\" ; const SButton = styled ( Button ) ` margin-right: 8px; ` as typeof Button ; interface IProps extends Pick < LinkProps , \"to\" > { label : string ; } const SecondaryButton = ({ label , to } : IProps ) => ( < SButton component = { Link } to = { to } variant = \"outlined\" > { label } < /SButton> ); export default SecondaryButton ; Note the styling is required to ensure that the buttons have a space between them.","title":"Form handling"},{"location":"frontend/forms/#integrating-formik-with-material-ui","text":"Formik integrates nicely with Material-UI components via Formik's useField hook. This hook takes care of the form state aspects, but doesn't account for any label, helper text or required marker which will need to be specified by props. I like the styling of outlined inputs with normal margins, which is what I'll use in the components below.","title":"Integrating Formik with Material-UI"},{"location":"frontend/forms/#checkbox-field","text":"We'll need a checkbox field to indicate if a Todo is complete or to indicate that the user should be remembered on login. The following should be added to frontend/src/components/CheckboxField.tsx , import Checkbox from \"@material-ui/core/Checkbox\" ; import FormControl from \"@material-ui/core/FormControl\" ; import FormControlLabel from \"@material-ui/core/FormControlLabel\" ; import FormHelperText from \"@material-ui/core/FormHelperText\" ; import { FieldHookConfig , useField } from \"formik\" ; import React from \"react\" ; type IProps = FieldHookConfig < boolean > & { fullWidth? : boolean ; helperText? : string ; label : string ; required? : boolean ; }; const CheckboxField = ( props : IProps ) => { const [ field , meta ] = useField < boolean > ( props ); let helperText : any ; if ( Boolean ( meta . error ) && meta . touched ) { helperText = ` ${ meta . error } . ${ props . helperText ?? \"\" } ` ; } else { helperText = props . helperText ; } return ( < FormControl component = \"fieldset\" error = { Boolean ( meta . error ) && meta . touched } fullWidth = { props . fullWidth } margin = \"normal\" required = { props . required } > < FormControlLabel control = { < Checkbox {... field } checked = { field . value } /> } label = { props . label } /> < FormHelperText > { helperText } < /FormHelperText> < /FormControl> ); }; export default CheckboxField ;","title":"Checkbox Field"},{"location":"frontend/forms/#date-field","text":"We'll need a date field for the user to specify a due date for a Todo. The following should be added to frontend/src/components/DateField.tsx , import MUITextField , { TextFieldProps } from \"@material-ui/core/TextField\" ; import { format , parseISO } from \"date-fns\" ; import { FieldHookConfig , useField } from \"formik\" ; import React from \"react\" ; import { useUID } from \"react-uid\" ; const DateField = ( props : FieldHookConfig < Date > & TextFieldProps ) => { const id = useUID (); const [ field , meta , helpers ] = useField < Date > ( props ); let helperText : any ; if ( Boolean ( meta . error ) && meta . touched ) { helperText = ` ${ meta . error } . ${ props . helperText ?? \"\" } ` ; } else { helperText = props . helperText ; } const value = field . value ? format ( field . value , \"yyyy-MM-dd\" ) : \"\" ; return ( < MUITextField {... props } error = { Boolean ( meta . error ) && meta . touched } helperText = { helperText } id = { id } InputLabelProps = {{ shrink : true , }} margin = \"normal\" type = \"date\" variant = \"outlined\" {... field } onChange = {( event ) => { if ( event . target . value ) { helpers . setValue ( parseISO ( event . target . value )); } else { helpers . setValue ( null ); } }} value = { value } /> ); }; export default DateField ; Note that the label must always be in the shrunk state to stop it overlapping with any input mask added by the browser.","title":"Date Field"},{"location":"frontend/forms/#email-field","text":"We'll need an email field for the user to login. The following should be added to frontend/src/components/EmailField.tsx , import MUITextField , { TextFieldProps } from \"@material-ui/core/TextField\" ; import { FieldHookConfig , useField } from \"formik\" ; import React from \"react\" ; import { useUID } from \"react-uid\" ; const EmailField = ( props : FieldHookConfig < string > & TextFieldProps ) => { const id = useUID (); const [ field , meta ] = useField < string > ( props ); let helperText : any ; if ( Boolean ( meta . error ) && meta . touched ) { helperText = ` ${ meta . error } . ${ props . helperText ?? \"\" } ` ; } else { helperText = props . helperText ; } return ( < MUITextField {... props } autoComplete = \"email\" error = { Boolean ( meta . error ) && meta . touched } helperText = { helperText } id = { id } margin = \"normal\" type = \"email\" variant = \"outlined\" {... field } /> ); }; export default EmailField ;","title":"Email Field"},{"location":"frontend/forms/#password-field","text":"We'll need the password field for the user to login and change their password. Unlike the other fields the password field has a button to toggle visibility of the password, which helps the user get their password correct. Note though this button is taken out of the tab flow, as users don't expect to tab onto this button. The following should be added to frontend/src/components/PasswordField.tsx , import IconButton from \"@material-ui/core/IconButton\" ; import InputAdornment from \"@material-ui/core/InputAdornment\" ; import MUITextField , { TextFieldProps } from \"@material-ui/core/TextField\" ; import Visibility from \"@material-ui/icons/Visibility\" ; import VisibilityOff from \"@material-ui/icons/VisibilityOff\" ; import { FieldHookConfig , useField } from \"formik\" ; import React from \"react\" ; import { useUID } from \"react-uid\" ; const PasswordField = ( props : FieldHookConfig < string > & TextFieldProps ) => { const id = useUID (); const [ field , meta ] = useField < string > ( props ); const [ showPassword , setShowPassword ] = React . useState ( false ); let helperText : any ; if ( Boolean ( meta . error ) && meta . touched ) { helperText = ` ${ meta . error } . ${ props . helperText ?? \"\" } ` ; } else { helperText = props . helperText ; } return ( < MUITextField {... props } InputProps = {{ endAdornment : ( < InputAdornment position = \"end\" > < IconButton onClick = {() => setShowPassword (( value ) => ! value )} tabIndex = { - 1 } > { showPassword ? < Visibility /> : < VisibilityOff /> } < /IconButton> < /InputAdornment> ), }} error = { Boolean ( meta . error ) && meta . touched } helperText = { helperText } id = { id } margin = \"normal\" type = { showPassword ? \"text\" : \"password\" } variant = \"outlined\" {... field } /> ); }; export default PasswordField ;","title":"Password Field"},{"location":"frontend/forms/#text-field","text":"We'll also need a text field for content of a todo. The following should be added to frontend/src/components/TextField.tsx , import MUITextField , { TextFieldProps } from \"@material-ui/core/TextField\" ; import { FieldHookConfig , useField } from \"formik\" ; import React from \"react\" ; import { useUID } from \"react-uid\" ; const TextField = ( props : FieldHookConfig < string > & TextFieldProps ) => { const id = useUID (); const [ field , meta ] = useField < string > ( props ); let helperText : any ; if ( Boolean ( meta . error ) && meta . touched ) { helperText = ` ${ meta . error } . ${ props . helperText ?? \"\" } ` ; } else { helperText = props . helperText ; } return ( < MUITextField {... props } error = { Boolean ( meta . error ) && meta . touched } helperText = { helperText } id = { id } margin = \"normal\" type = \"text\" variant = \"outlined\" {... field } /> ); }; export default TextField ;","title":"Text Field"},{"location":"frontend/forms/#submit-button","text":"We should also allow the user to submit the form and show an indication that it is processing i.e. while the request to the backend is taking place. I like to do this by disabling the button and adding a circular spinner over the top whilst the submission is processing. The following should be added to frontend/src/components/SubmitButton.tsx , import Button from \"@material-ui/core/Button\" ; import CircularProgress from \"@material-ui/core/CircularProgress\" ; import React from \"react\" ; import styled from \"styled-components\" ; interface IDivProps { fullwidth? : boolean ; } const SDiv = styled . div < IDivProps > ` align-items: center; display: inline-flex; margin-bottom: 8px; margin-right: 8px; margin-top: 16px; position: relative; width: ${ ( props ) => ( props . fullwidth ? \"100%\" : \"initial\" ) } ; & svg { margin-left: 4px; } & .MuiCircularProgress-root { left: 50%; margin-left: -12px; margin-top: -12px; position: absolute; top: 50%; } & .MuiCircularProgress-root svg { margin: 2px; } ` ; interface IProps { className? : string ; fullWidth? : boolean ; label : string ; submitting? : boolean ; } const SubmitButton = ({ className , label , submitting , fullWidth , } : IProps ) : JSX . Element => ( < SDiv className = { className } fullwidth = { fullWidth } > < Button color = \"primary\" disabled = { submitting } fullWidth = { fullWidth } type = \"submit\" variant = \"contained\" > { label } < /Button> { submitting ? < CircularProgress size = { 24 } /> : null } < /SDiv> ); export default SubmitButton ; Note the styling is required to position the CircularProgress element in the center of the Button.","title":"Submit Button"},{"location":"frontend/forms/#secondary-button","text":"Finally we will need a way for the user to change their mind and visit another page, or simply go back i.e. perform a secondary action other than submitting the form. The following should be added to frontend/src/components/SecondaryButton.tsx , import Button from \"@material-ui/core/Button\" ; import React from \"react\" ; import { Link , LinkProps } from \"react-router-dom\" ; import styled from \"styled-components\" ; const SButton = styled ( Button ) ` margin-right: 8px; ` as typeof Button ; interface IProps extends Pick < LinkProps , \"to\" > { label : string ; } const SecondaryButton = ({ label , to } : IProps ) => ( < SButton component = { Link } to = { to } variant = \"outlined\" > { label } < /SButton> ); export default SecondaryButton ; Note the styling is required to ensure that the buttons have a space between them.","title":"Secondary button"},{"location":"frontend/i18n/","text":"To demonstrate how to support multiple languages and locales we will support english and german in the Tozo app. To do this I like to use React-i18next due to it's nice hook support. React-i18next is installed via npm and requires i18next, npm install --save i18next react-i18next We can also install i18next-browser-languagedetector to detect the browser's language and use it as the default, npm install --save i18next-browser-languagedetector With these installed we can setup internationalization by adding the following to frontend/src/i18n.ts , import i18n from \"i18next\" ; import LanguageDetector from \"i18next-browser-languagedetector\" ; import { initReactI18next } from \"react-i18next\" ; const resources = { de : { translation : {} }, en : { translation : {} }, }; i18n . use ( initReactI18next ) . use ( LanguageDetector ) . init ({ debug : process.env.NODE_ENV === \"development\" , detection : { order : [ \"navigator\" ] }, fallbackLng : \"en\" , interpolation : { escapeValue : false }, keySeparator : false , load : \"languageOnly\" , resources , }); export default i18n ; Note that we have set english as the fallback language if the user's prefered language is one we don't support. We have also ignored regional aspects and focused on the language only i.e. en rather than en-GB . Finally we need to import this file from frontend/src/index.tsx to complete the setup. Translation keys The translation associate arrays are keyed by a translation key. To help identify where each key is used I like to construct the key as the ComponentName.field , for example LanguageSelector.change . Language picker The language detector may not pick the right language for the user so we should offer the ability to choose the language from within the app. We can do this via a LanguageSelector component by placing the following in frontend/src/components/LanguageSelector.tsx , import Button from \"@material-ui/core/Button\" ; import Menu from \"@material-ui/core/Menu\" ; import MenuItem from \"@material-ui/core/MenuItem\" ; import Tooltip from \"@material-ui/core/Tooltip\" ; import ExpandMoreIcon from \"@material-ui/icons/ExpandMore\" ; import LanguageIcon from \"@material-ui/icons/Translate\" ; import React from \"react\" ; import { useTranslation } from \"react-i18next\" ; import { useUID } from \"react-uid\" ; const LanguageSelector = () => { const [ anchorEl , setAnchorEl ] = React . useState < null | HTMLElement > ( null ); const { t , i18n } = useTranslation (); const menuID = useUID (); const onMenuOpen = ( event : React.MouseEvent < HTMLElement > ) => { setAnchorEl ( event . currentTarget ); }; const onMenuClose = () => { setAnchorEl ( null ); }; const changeLanguage = ( language : string ) => () => { i18n . changeLanguage ( language ); onMenuClose (); }; return ( <> < Tooltip enterDelay = { 300 } title = { t ( \"LanguageSelector.change\" ) as string } > < Button aria - haspopup = \"true\" aria - owns = { menuID } color = \"inherit\" endIcon = { < ExpandMoreIcon fontSize = \"small\" /> } onClick = { onMenuOpen } startIcon = { < LanguageIcon /> } > { t ( \"LanguageSelector.change\" )} < /Button> < /Tooltip> < Menu anchorEl = { anchorEl } anchorOrigin = {{ horizontal : \"right\" , vertical : \"top\" , }} id = { menuID } keepMounted onClose = { onMenuClose } open = { Boolean ( anchorEl )} transformOrigin = {{ horizontal : \"right\" , vertical : \"top\" , }} > { /* eslint-disable i18next/no-literal-string */ } < MenuItem onClick = { changeLanguage ( \"en\" )} > English < /MenuItem> < MenuItem onClick = { changeLanguage ( \"de\" )} > Deutsch < /MenuItem> { /* eslint-enable */ } < /Menu> < /> ); }; export default LanguageSelector ; The translation entries for this component are, de : { translation : { \"LanguageSelector.change\" : \"Deutsch\" , } }, en : { translation : { \"LanguageSelector.change\" : \"English\" , } }","title":"Internationalization (i18n)"},{"location":"frontend/i18n/#translation-keys","text":"The translation associate arrays are keyed by a translation key. To help identify where each key is used I like to construct the key as the ComponentName.field , for example LanguageSelector.change .","title":"Translation keys"},{"location":"frontend/i18n/#language-picker","text":"The language detector may not pick the right language for the user so we should offer the ability to choose the language from within the app. We can do this via a LanguageSelector component by placing the following in frontend/src/components/LanguageSelector.tsx , import Button from \"@material-ui/core/Button\" ; import Menu from \"@material-ui/core/Menu\" ; import MenuItem from \"@material-ui/core/MenuItem\" ; import Tooltip from \"@material-ui/core/Tooltip\" ; import ExpandMoreIcon from \"@material-ui/icons/ExpandMore\" ; import LanguageIcon from \"@material-ui/icons/Translate\" ; import React from \"react\" ; import { useTranslation } from \"react-i18next\" ; import { useUID } from \"react-uid\" ; const LanguageSelector = () => { const [ anchorEl , setAnchorEl ] = React . useState < null | HTMLElement > ( null ); const { t , i18n } = useTranslation (); const menuID = useUID (); const onMenuOpen = ( event : React.MouseEvent < HTMLElement > ) => { setAnchorEl ( event . currentTarget ); }; const onMenuClose = () => { setAnchorEl ( null ); }; const changeLanguage = ( language : string ) => () => { i18n . changeLanguage ( language ); onMenuClose (); }; return ( <> < Tooltip enterDelay = { 300 } title = { t ( \"LanguageSelector.change\" ) as string } > < Button aria - haspopup = \"true\" aria - owns = { menuID } color = \"inherit\" endIcon = { < ExpandMoreIcon fontSize = \"small\" /> } onClick = { onMenuOpen } startIcon = { < LanguageIcon /> } > { t ( \"LanguageSelector.change\" )} < /Button> < /Tooltip> < Menu anchorEl = { anchorEl } anchorOrigin = {{ horizontal : \"right\" , vertical : \"top\" , }} id = { menuID } keepMounted onClose = { onMenuClose } open = { Boolean ( anchorEl )} transformOrigin = {{ horizontal : \"right\" , vertical : \"top\" , }} > { /* eslint-disable i18next/no-literal-string */ } < MenuItem onClick = { changeLanguage ( \"en\" )} > English < /MenuItem> < MenuItem onClick = { changeLanguage ( \"de\" )} > Deutsch < /MenuItem> { /* eslint-enable */ } < /Menu> < /> ); }; export default LanguageSelector ; The translation entries for this component are, de : { translation : { \"LanguageSelector.change\" : \"Deutsch\" , } }, en : { translation : { \"LanguageSelector.change\" : \"English\" , } }","title":"Language picker"},{"location":"frontend/login-page/","text":"The login page exists for users to login to Tozo. To do this we need the user to enter their email, password, and optionally indicate they wish to be remembered and then we'll use the members API to log them in. User's are likely to navigate between the registration, login, and forgotten password pages as they often can't remember if they have an account or what the password was. For this reason we can reduce their effort by persisting any email address they've typed in across these pages and offer links between the pages. The following code to do all this should be placed in frontend/src/pages/Login.tsx , import Box from \"@material-ui/core/Box\" ; import Typography from \"@material-ui/core/Typography\" ; import axios from \"axios\" ; import { Form , Formik , FormikHelpers } from \"formik\" ; import React , { useContext } from \"react\" ; import { useTranslation } from \"react-i18next\" ; import { useHistory , useLocation } from \"react-router\" ; import * as yup from \"yup\" ; import { AuthContext } from \"src/AuthContext\" ; import CheckboxField from \"src/components/CheckboxField\" ; import EmailField from \"src/components/EmailField\" ; import PasswordField from \"src/components/PasswordField\" ; import SecondaryButton from \"src/components/SecondaryButton\" ; import SubmitButton from \"src/components/SubmitButton\" ; import { useMutation } from \"src/query\" ; import { ToastContext } from \"src/ToastContext\" ; interface IForm { email : string ; password : string ; remember : boolean ; } interface ILocationState { email? : string ; from ?: string ; } const Login = () => { const { t } = useTranslation (); const history = useHistory (); const location = useLocation < ILocationState > (); const { setAuthenticated } = useContext ( AuthContext ); const { addToast } = useContext ( ToastContext ); const { mutateAsync : login } = useMutation ( async ( data : IForm ) => { await axios . post ( \"/sessions/\" , data ); }); const validationSchema = yup . object ({ email : yup . string () . email ( t ( \"generic.emailRequired\" )) . required ( t ( \"generic.required\" )), password : yup.string (). required ( t ( \"generic.required\" )), }); const onSubmit = async ( data : IForm , { setFieldError } : FormikHelpers < IForm > , ) => { try { await login ( data ); setAuthenticated ( true ); history . push ( location . state ? . from ?? \"/\" ); } catch ( error ) { if ( error . response ? . status === 401 ) { setFieldError ( \"email\" , t ( \"Login.invalidCredentials\" )); setFieldError ( \"password\" , t ( \"Login.invalidCredentials\" )); } else { addToast ({ category : \"error\" , message : t ( \"generic.tryAgainError\" ) }); } } }; return ( <> < Box mb = { 1 } mt = { 2 } > < Typography component = \"h1\" variant = \"h5\" > { t ( \"Login.lead\" )} < /Typography> < /Box> < Formik < IForm > initialValues = {{ email : location.state?.email ?? \"\" , password : \"\" , remember : false , }} onSubmit = { onSubmit } validationSchema = { validationSchema } > {({ isSubmitting , values }) => ( < Form > < EmailField fullWidth = { true } label = { t ( \"generic.email\" )} name = \"email\" required = { true } /> < PasswordField fullWidth = { true } label = { t ( \"generic.password\" )} name = \"password\" required = { true } /> < CheckboxField fullWidth = { true } label = { t ( \"Login.remember\" )} name = \"remember\" required = { true } /> < SubmitButton label = { t ( \"generic.login\" )} submitting = { isSubmitting } /> < SecondaryButton label = { t ( \"generic.register\" )} to = {{ pathname : \"/register/\" , state : { email : values.email }, }} /> < SecondaryButton label = { t ( \"generic.forgottenPassword\" )} to = {{ pathname : \"/forgotten-password/\" , state : { email : values.email }, }} /> < /Form> )} < /Formik> < /> ); }; export default Login ; Then we can add the page to the routing by adding the following to frontend/src/Router.tsx , import Login from \"src/pages/Login\" ; ... const Router = () => ( < BrowserRouter > ... < Route exact = { true } path = \"/login/\" > < Login /> < /Route> < /BrowserRouter> );","title":"Login"},{"location":"frontend/material-ui/","text":"If you don't have design skills then it is best to follow someone else's design system. A good one is material design as pioneered by Google as there is a great React component library that follows it. The library is called Material-UI and is installed with npm, npm install --save @material-ui/core npm install --save @material-ui/icons which installed 4.11.1. Styling Material-UI components Fortunately Material-UI's components can be styled using styled-components, but for this to work effectively the Material-UI styles must be injected first, this is achieved by adding an outer <StylesProvider> wrapper to the app in frontend/src/App.tsx , import CssBaseline from \"@material-ui/core/CssBaseline\" ; import { StylesProvider } from \"@material-ui/core/styles\" ; ... const App = () => { ... return ( < StylesProvider injectFirst > < CssBaseline /> ... < /StylesProvider> ); } where ... represents the existing code. Theming Material-UI can be themed, allowing for changes to the appearance of the app. The theme is created by createMuiTheme and is styled-components compatible. This allows the following to be added to frontend/src/theme.ts , import { createMuiTheme , Theme } from \"@material-ui/core/styles\" ; const createTheme = ( darkMode : boolean ) : Theme => { const palette = { type : ( darkMode ? \"dark\" : \"light\" ) as any , }; return createMuiTheme ({ palette }); }; export default createTheme ; which allows for dark mode support based on the user's preference by adding the following to frontend/src/App.tsx , import useMediaQuery from \"@material-ui/core/useMediaQuery\" ; import { ThemeProvider as MuiThemeProvider } from \"@material-ui/styles\" ; import { ThemeProvider } from \"styled-components\" ; import createTheme from \"src/theme\" ; const App = () => { const prefersDarkMode = useMediaQuery ( \"(prefers-color-scheme: dark)\" ); const theme = React . useMemo ( () => createTheme ( prefersDarkMode ), [ prefersDarkMode ] ); return ( < ThemeProvider theme = { theme } > < MuiThemeProvider theme = { theme } > ... // Existing code < /MuiThemeProvider> < /ThemeProvider> ); };","title":"Material UI"},{"location":"frontend/material-ui/#styling-material-ui-components","text":"Fortunately Material-UI's components can be styled using styled-components, but for this to work effectively the Material-UI styles must be injected first, this is achieved by adding an outer <StylesProvider> wrapper to the app in frontend/src/App.tsx , import CssBaseline from \"@material-ui/core/CssBaseline\" ; import { StylesProvider } from \"@material-ui/core/styles\" ; ... const App = () => { ... return ( < StylesProvider injectFirst > < CssBaseline /> ... < /StylesProvider> ); } where ... represents the existing code.","title":"Styling Material-UI components"},{"location":"frontend/material-ui/#theming","text":"Material-UI can be themed, allowing for changes to the appearance of the app. The theme is created by createMuiTheme and is styled-components compatible. This allows the following to be added to frontend/src/theme.ts , import { createMuiTheme , Theme } from \"@material-ui/core/styles\" ; const createTheme = ( darkMode : boolean ) : Theme => { const palette = { type : ( darkMode ? \"dark\" : \"light\" ) as any , }; return createMuiTheme ({ palette }); }; export default createTheme ; which allows for dark mode support based on the user's preference by adding the following to frontend/src/App.tsx , import useMediaQuery from \"@material-ui/core/useMediaQuery\" ; import { ThemeProvider as MuiThemeProvider } from \"@material-ui/styles\" ; import { ThemeProvider } from \"styled-components\" ; import createTheme from \"src/theme\" ; const App = () => { const prefersDarkMode = useMediaQuery ( \"(prefers-color-scheme: dark)\" ); const theme = React . useMemo ( () => createTheme ( prefersDarkMode ), [ prefersDarkMode ] ); return ( < ThemeProvider theme = { theme } > < MuiThemeProvider theme = { theme } > ... // Existing code < /MuiThemeProvider> < /ThemeProvider> ); };","title":"Theming"},{"location":"frontend/models/","text":"As with the backend it helps to use models representing the data used. These models help the linters ensure that we are using the data correctly and that the correct types are used. We can also use the model to correctly convert to and from the JSON representation used to communicate with the backend API. As JSON has no date type we use ISO 8601 formatted strings, see the backend validation . To turn these strings into javascript Date instances we'll use date-fns . As it provides all the functionality we'll need using the javascript Date type. date-fns is installed via npm, npm install --save date-fns We need a model for Todo s that can be constructed from a JSON associate array or from user entered form data and then converted back to json when sent to the backend API. The former is achieved by converting the due argument as required into a Date , the latter is achieved via a toJSON method that is automatically called when converting to JSON. The following should be added to frontend/src/models.ts , import { formatISO , parseISO } from \"date-fns\" ; interface ITodoParams { complete : boolean ; due : Date | string | null ; id : number ; task : string ; } export class Todo { complete : boolean ; due : Date | null ; id : number ; task : string ; constructor ({ complete , due , id , task } : ITodoParams ) { this . complete = complete ; if ( due instanceof Date ) { this . due = due ; } else if ( due !== null ) { this . due = parseISO ( due ); } else { this . due = due ; } this . id = id ; this . task = task ; } toJSON () : any { return { complete : this.complete , due : this.due !== null ? formatISO ( this . due , { representation : \"date\" }) : null , id : this.id , task : this.task , }; } }","title":"Data models"},{"location":"frontend/nav/","text":"The app we are building has only a few pages so we don't need much naviagion, if we did the Material-UI Drawer component would be a good choice. Instead we just need a header bar that looks good for logged out users and allows logged in users to navigate to the full todo list, and the change-password page, whilst allowing them to change the language and to logout. First lets create a AccountMenu component that adds the functionality required for logged in users by adding the following to frontend/src/components/AccountMenu.tsx , 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 import Divider from \"@material-ui/core/Divider\" ; import IconButton from \"@material-ui/core/IconButton\" ; import Menu from \"@material-ui/core/Menu\" ; import MenuItem from \"@material-ui/core/MenuItem\" ; import AccountCircle from \"@material-ui/icons/AccountCircle\" ; import axios from \"axios\" ; import React , { useContext , useState } from \"react\" ; import { useTranslation } from \"react-i18next\" ; import { Link } from \"react-router-dom\" ; import { useUID } from \"react-uid\" ; import { AuthContext } from \"src/AuthContext\" ; import { useMutation } from \"src/query\" ; const AccountMenu = () => { const { t } = useTranslation (); const { setAuthenticated } = useContext ( AuthContext ); const [ anchorEl , setAnchorEl ] = useState < null | HTMLElement > ( null ); const menuID = useUID (); const onMenuOpen = ( event : React.MouseEvent < HTMLElement > ) => { setAnchorEl ( event . currentTarget ); }; const onMenuClose = () => { setAnchorEl ( null ); }; const { mutate : logout } = useMutation ( async () => { await axios . delete ( \"/sessions/\" ); }, { onSuccess : () => { setAuthenticated ( false ); onMenuClose (); }, }, ); return ( <> < IconButton aria - label = \"account of current user\" aria - controls = \"menu-appbar\" aria - haspopup = \"true\" color = \"inherit\" onClick = { onMenuOpen } > < AccountCircle /> < /IconButton> < Menu anchorEl = { anchorEl } anchorOrigin = {{ horizontal : \"right\" , vertical : \"top\" , }} id = { menuID } keepMounted onClose = { onMenuClose } open = { Boolean ( anchorEl )} transformOrigin = {{ horizontal : \"right\" , vertical : \"top\" , }} > < MenuItem component = { Link } onClick = { onMenuClose } to = \"/change-password/\" > { t ( \"AccountMenu.changePassword\" )} < /MenuItem> < Divider /> < MenuItem onClick = {() => logout ()} > { t ( \"AccountMenu.signout\" )} < /MenuItem> < /Menu> < /> ); }; export default AccountMenu ; The use mutation on lines 29-39 actually logs the user out via a call to the backend. Everything else is boilerplate for a menu that is anchored to the account icon button. Note also on line 67 the usage of the Link component as this ensure the correct HTML semantic element is used. We can then make use of this component in a TopBar component, by adding the following to frontend/src/components/TopBar.tsx , 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 import AppBar from \"@material-ui/core/AppBar\" ; import Button from \"@material-ui/core/Button\" ; import Toolbar from \"@material-ui/core/Toolbar\" ; import React , { useContext } from \"react\" ; import { Link } from \"react-router-dom\" ; import styled from \"styled-components\" ; import { AuthContext } from \"src/AuthContext\" ; import AccountMenu from \"src/components/AccountMenu\" ; import LanguageSelector from \"src/components/LanguageSelector\" ; const SToolbar = styled ( Toolbar ) ` padding-left: constant(safe-area-inset-left); /* iOS 11.0 */ padding-left: env(safe-area-inset-left); /* iOS 11.2 */ padding-right: constant(safe-area-inset-right); /* iOS 11.0 */ padding-right: env(safe-area-inset-right); /* iOS 11.2 */ padding-top: constant(safe-area-inset-top); /* iOS 11.0 */ padding-top: env(safe-area-inset-top); /* iOS 11.2 */ ` ; const SLeft = styled . div ` flex-grow: 1; ` ; const TopBar = () => { const { authenticated } = useContext ( AuthContext ); return ( <> < AppBar position = \"fixed\" > < SToolbar > < SLeft > < Button color = \"inherit\" component = { Link } to = \"/\" > { /* eslint-disable i18next/no-literal-string */ } Tozo { /* eslint-enable */ } < /Button> < /SLeft> < LanguageSelector /> { authenticated ? < AccountMenu /> : null } < /SToolbar> < /AppBar> < SToolbar /> < /> ); }; export default TopBar ; The toolbar styling on lines 12-19 extends the TopBar such that it fills in any non-rectangular display space, most notably the iPhone notch. Read more here . The additional Toolbar on line 43 after the AppBar ensures that the content that follows this component does not render underneath the AppBar. Finnally the TopBar is used by adding it within the BrowserRouter in frontend/src/Router.tsx and translation keys are added to frontend/src/i18n.ts .","title":"Navigation"},{"location":"frontend/passwords/","text":"When users create an account or change their password they will need to enter a password we consider strong enough. Whilst this is primarily for the user's benefit they will find it very annoying if we don't help them understand what strong means. In the past sites would mandate that special, upper, and lower case characters be present. Yet this, sadly, leads to weaker passwords. So instead we will require the password to have enough entropy. This is something we already do in the backend API via the zxcvbn tool. Only checking the strength in the backend API call leads to a poor user experience as it takes too long for the user to receive feedback on the strength of their password. Fortunately there is a JS zxcvbn version which we can use to provide users instant feedback on the strength of their password. zxcvbn can be installed via npm, npm install --save zxcvbn npm install --save-dev @types/zxcvbn Then we can a LinearProgressMeter alongside our existing PasswordField, by adding the following to frontend/src/components/MeteredPasswordField.tsx , import FormHelperText from \"@material-ui/core/FormHelperText\" ; import LinearProgress from \"@material-ui/core/LinearProgress\" ; import { TextFieldProps } from \"@material-ui/core/TextField\" ; import { FieldHookConfig , useField } from \"formik\" ; import React from \"react\" ; import { useTranslation } from \"react-i18next\" ; import zxcvbn from \"zxcvbn\" ; import PasswordField from \"src/components/PasswordField\" ; const MeteredPasswordField = ( props : FieldHookConfig < string > & TextFieldProps , ) => { const [ field ] = useField < string > ( props ); const { t } = useTranslation (); const result = zxcvbn ( field . value ?? \"\" ); let key ; switch ( result . score ) { case 3 : key = \"MeteredPasswordField.good\" ; break ; case 4 : key = \"MeteredPasswordField.strong\" ; break ; default : key = \"MeteredPasswordField.weak\" ; } return ( <> < PasswordField {... props } /> < LinearProgress value = { result . score * 25 } variant = \"determinate\" /> < FormHelperText > { t ( key )} < /FormHelperText> < /> ); }; export default MeteredPasswordField ; Code splitting As you can check via the npm run analyse we added in the frontend tooling section zxcvbn has a large impact on the bundle size. This is because zxcvbn includes a dictionary of bad passwords and general words. Therefore we only wish the use to download the bundle including zxcvbn when they need to use it. We can split out the MeteredPasswordField from the main bundle by always lazily loading it and falling back to the simpler PasswordField via the following snippet, import PasswordField from \"src/components/PasswordField\" ; const MeteredPasswordField = React . lazy ( () => import ( \"src/components/MeteredPasswordField\" ), ); const jsx = ( < Suspense fallback = { < PasswordField /> } > < MeteredPasswordField /> < /Suspense> );","title":"Password strength"},{"location":"frontend/passwords/#code-splitting","text":"As you can check via the npm run analyse we added in the frontend tooling section zxcvbn has a large impact on the bundle size. This is because zxcvbn includes a dictionary of bad passwords and general words. Therefore we only wish the use to download the bundle including zxcvbn when they need to use it. We can split out the MeteredPasswordField from the main bundle by always lazily loading it and falling back to the simpler PasswordField via the following snippet, import PasswordField from \"src/components/PasswordField\" ; const MeteredPasswordField = React . lazy ( () => import ( \"src/components/MeteredPasswordField\" ), ); const jsx = ( < Suspense fallback = { < PasswordField /> } > < MeteredPasswordField /> < /Suspense> );","title":"Code splitting"},{"location":"frontend/registration-page/","text":"The registration page must allow users to signup to use the app. For our app this means they must supply an email address and a password. Once the user has supplied these we'll use the members API to create the user and then redirect the user to the login page or if the API call fails display a relevant error. Whilst the registration page is necessary it doesn't add any value to the user, so we'll need to make it as quick and easy to complete as possible, starting by only asking for information we need, namely an email and password to login. Then making use of the metered password to show the user if their password is strong enough without having to contact the server. We'll also add form validation and the correct autocomplete values, which should encourage the browser to do most of the work for the user. User's are likely to navigate between the registration, login, and forgotten password pages as they often can't remember if they have an account or what the password was. For this reason we can reduce their effort by persisting any email address they've typed in across these pages and offer links between the pages. The following code to do all this should be placed in frontend/src/pages/Register.tsx , import Box from \"@material-ui/core/Box\" ; import Typography from \"@material-ui/core/Typography\" ; import axios from \"axios\" ; import { Form , Formik , FormikHelpers } from \"formik\" ; import React , { Suspense , useContext } from \"react\" ; import { useTranslation } from \"react-i18next\" ; import { useHistory , useLocation } from \"react-router\" ; import * as yup from \"yup\" ; import EmailField from \"src/components/EmailField\" ; import PasswordField from \"src/components/PasswordField\" ; import SecondaryButton from \"src/components/SecondaryButton\" ; import SubmitButton from \"src/components/SubmitButton\" ; import { useMutation } from \"src/query\" ; import { ToastContext } from \"src/ToastContext\" ; const MeteredPasswordField = React . lazy ( () => import ( \"src/components/MeteredPasswordField\" ), ); interface IForm { email : string ; password : string ; } interface ILocationState { email? : string ; } const Register = () => { const { t } = useTranslation (); const history = useHistory (); const location = useLocation < ILocationState > (); const { addToast } = useContext ( ToastContext ); const { mutateAsync : register } = useMutation ( async ( data : IForm ) => { await axios . post ( \"/members/\" , data ); }); const validationSchema = yup . object ({ email : yup . string () . email ( t ( \"generic.emailRequired\" )) . required ( t ( \"generic.required\" )), password : yup.string (). required ( t ( \"generic.required\" )), }); const onSubmit = async ( data : IForm , { setFieldError } : FormikHelpers < IForm > , ) => { try { await register ( data ); addToast ({ category : \"success\" , message : t ( \"Register.registered\" ) }); history . push ( \"/login/\" ); } catch ( error ) { if ( error . response && error . response . status === 400 && error . response . data . code === \"WEAK_PASSWORD\" ) { setFieldError ( \"password\" , t ( \"Registration.weakPassword\" )); } else { addToast ({ category : \"error\" , message : t ( \"generic.tryAgainError\" ) }); } } }; return ( <> < Box mb = { 1 } mt = { 2 } > < Typography component = \"h1\" variant = \"h5\" > { t ( \"Register.lead\" )} < /Typography> < /Box> < Formik < IForm > initialValues = {{ email : location.state?.email ?? \"\" , password : \"\" , }} onSubmit = { onSubmit } validationSchema = { validationSchema } > {({ isSubmitting , values }) => ( < Form > < EmailField fullWidth = { true } label = { t ( \"generic.email\" )} name = \"email\" required = { true } /> < Suspense fallback = { < PasswordField autoComplete = \"new-password\" fullWidth = { true } label = { t ( \"generic.password\" )} name = \"password\" required = { true } /> } > < MeteredPasswordField autoComplete = \"new-password\" fullWidth = { true } label = { t ( \"generic.password\" )} name = \"password\" required = { true } /> < /Suspense> < SubmitButton label = { t ( \"generic.register\" )} submitting = { isSubmitting } /> < SecondaryButton label = { t ( \"generic.login\" )} to = {{ pathname : \"/login/\" , state : { email : values.email }, }} /> < SecondaryButton label = { t ( \"generic.forgottenPassword\" )} to = {{ pathname : \"/forgotten-password/\" , state : { email : values.email }, }} /> < /Form> )} < /Formik> < /> ); }; export default Register ; Then we can add the page to the routing by adding the following to frontend/src/Router.tsx , import Register from \"src/pages/Register\" ; ... const Router = () => ( < BrowserRouter > ... < Route exact = { true } path = \"/register/\" > < Register /> < /Route> < /BrowserRouter> );","title":"User registration"},{"location":"frontend/reset-password-page/","text":"The reset password page is only accessed via a special link we've emailed the user. This link contains a token that the backend will use to prove the user is allowed to reset the token. Therefore on the frontend we need to allow the user to enter a new password and send it with the token to the backend. To make it easier for the user we'll use the metered password field, and we'll let them know if their link is invalid or has expired. Lets add the following to frontend/src/pages/ResetPassword.tsx , import Box from \"@material-ui/core/Box\" ; import Typography from \"@material-ui/core/Typography\" ; import axios from \"axios\" ; import { Form , Formik } from \"formik\" ; import React , { Suspense , useContext } from \"react\" ; import { useTranslation } from \"react-i18next\" ; import { useParams } from \"react-router\" ; import * as yup from \"yup\" ; import PasswordField from \"src/components/PasswordField\" ; import SecondaryButton from \"src/components/SecondaryButton\" ; import SubmitButton from \"src/components/SubmitButton\" ; import { useMutation } from \"src/query\" ; import { ToastContext } from \"src/ToastContext\" ; const MeteredPasswordField = React . lazy ( () => import ( \"src/components/MeteredPasswordField\" ), ); interface IForm { password : string ; } interface IParams { token? : string ; } const ResetPassowrd = () => { const { t } = useTranslation (); const { addToast } = useContext ( ToastContext ); const params = useParams < IParams > (); const token = params . token ?? \"\" ; const { mutateAsync : reset } = useMutation ( async ( password : string ) => { await axios . put ( \"/members/reset-password/\" , { password , token }); }); const validationSchema = yup . object ({ password : yup.string (). required ( t ( \"generic.required\" )), }); const onSubmit = async ( data : IForm ) => { try { await reset ( data . password ); } catch ( error ) { if ( error . response ? . status === 400 ) { if ( error . response . data . code === \"WEAK_PASSWORD\" ) { setFieldError ( \"password\" , t ( \"generic.weakPassword\" )); } else if ( error . response . data . code === \"TOKEN_INVALID\" ) { addToast ({ category : \"error\" , message : t ( \"generic.invalidToken\" ) }); } else if ( error . response . data . code === \"TOKEN_EXPIRED\" ) { addToast ({ category : \"error\" , message : t ( \"generic.expiredToken\" ) }); } } else { addToast ({ category : \"error\" , message : t ( \"generic.tryAgainError\" ) }); } } }; return ( <> < Box mb = { 1 } mt = { 2 } > < Typography component = \"h1\" variant = \"h5\" > { t ( \"ResetPassword.lead\" )} < /Typography> < /Box> < Formik < IForm > initialValues = {{ password : \"\" , }} onSubmit = { onSubmit } validationSchema = { validationSchema } > {({ isSubmitting }) => ( < Form > < Suspense fallback = { < PasswordField autoComplete = \"new-password\" fullWidth = { true } label = { t ( \"generic.password\" )} name = \"password\" required = { true } /> } > < MeteredPasswordField autoComplete = \"new-password\" fullWidth = { true } label = { t ( \"generic.password\" )} name = \"password\" required = { true } /> < /Suspense> < SubmitButton label = { t ( \"ResetPassword.reset\" )} submitting = { isSubmitting } /> < SecondaryButton label = { t ( \"generic.login\" )} to = \"/login/\" /> < /Form> )} < /Formik> < /> ); }; export default ResetPassowrd ; Then we can add the page to the routing by adding the following to frontend/src/Router.tsx , import ResetPassword from \"src/pages/ResetPassword\" ; ... const Router = () => ( < BrowserRouter > ... < Route exact = { true } path = \"/reset-password/:token/\" > < ResetPassword /> < /Route> < /BrowserRouter> );","title":"Reset password"},{"location":"frontend/responsive/","text":"We should develop the frontend pages to look good on a mobile sized screen. This is best done by activating developer tools in the browser and using the device toolbar to select a mobile framing. This should ensure that the app looks good from mobile up. However to ensure it looks good on much larger screens we'll contain the content up to the Material-UI md breakpoint by adding the following to frontend/src/App.tsx , import Container from \"@material-ui/core/Container\" ; ... const App = () => { ... return ( ... < Container maxWidth = \"md\" > < Router /> < /Container> ); };","title":"Responsive layout"},{"location":"frontend/routing/","text":"Routing, which is the ability to route different requested paths to different displayed pages, takes place within the browser for the single page app we are building. This is preferable to routing on the server as the user experiences faster page transitions. Note Client side routing does come with the cost of a larger initial download and could harm SEO (although it isn't clear to me if this is the case). It also requires a catch all backend serving route as the backend no longer knows which paths equate to pages. React-Router is a great library to handle routing in React apps, it is installed via npm, npm install --save react-router-dom npm install --save-dev @types/react-router-dom which installed 5.2.0. Our apps routes can be expressed by a few exclusive paths in a Router component, frontend/src/Router.tsx , import { BrowserRouter , Switch , Route } from \"react-router-dom\" ; const Router = () => ( < BrowserRouter > < Switch > // Routes to go here < Route > // Not found page here < /Route> < /Switch> < /BrowserRouter> ); export default Router ; where the Switch enforces that only the first matching Route is rendered. The final Route will then match if no others do, allowing a not found page to be shown. This Router component is then used in the App component within the existing contexts. Scroll to top By default when navigating client side with this setup the scroll position will not change. This means that if the user is viewing the bottom of a page and navigates to another they'll be viewing the bottom of the new page. This is annoying, so I like to scroll the view to the top of the page on navigation using a ScrollToTop component, frontend/src/components/ScrollToTop.tsx , import React from \"react\" ; import { useLocation } from \"react-router\" ; const ScrollToTop = () : null => { const { pathname } = useLocation (); React . useEffect (() => { window . scrollTo ( 0 , 0 ); }, [ pathname ]); return null ; }; export default ScrollToTop ; which is then placed within the BrowserRouter in the Router component. Private Routes A significant fraction of the routes in the app will only be available for users who are logged in. Using the Authentication context allows for a PrivateRoute component that is usable in the same why as Route components but only matches when the user is logged in. Add the following to src/components/PrivateRoute.tsx , import React from \"react\" ; import { Redirect , Route , RouteProps } from \"react-router-dom\" ; import { AuthContext } from \"src/AuthContext\" ; const PrivateRoute = ({ children , ... rest } : RouteProps ) => { const { authenticated } = React . useContext ( AuthContext ); return ( < Route {... rest } render = {( props ) => { if ( authenticated ) { return children ; } else { return ( < Redirect to = {{ pathname : \"/login/\" , state : { from : props . location } }} /> ); } }} /> ); }; export default PrivateRoute ;","title":"Routing"},{"location":"frontend/routing/#scroll-to-top","text":"By default when navigating client side with this setup the scroll position will not change. This means that if the user is viewing the bottom of a page and navigates to another they'll be viewing the bottom of the new page. This is annoying, so I like to scroll the view to the top of the page on navigation using a ScrollToTop component, frontend/src/components/ScrollToTop.tsx , import React from \"react\" ; import { useLocation } from \"react-router\" ; const ScrollToTop = () : null => { const { pathname } = useLocation (); React . useEffect (() => { window . scrollTo ( 0 , 0 ); }, [ pathname ]); return null ; }; export default ScrollToTop ; which is then placed within the BrowserRouter in the Router component.","title":"Scroll to top"},{"location":"frontend/routing/#private-routes","text":"A significant fraction of the routes in the app will only be available for users who are logged in. Using the Authentication context allows for a PrivateRoute component that is usable in the same why as Route components but only matches when the user is logged in. Add the following to src/components/PrivateRoute.tsx , import React from \"react\" ; import { Redirect , Route , RouteProps } from \"react-router-dom\" ; import { AuthContext } from \"src/AuthContext\" ; const PrivateRoute = ({ children , ... rest } : RouteProps ) => { const { authenticated } = React . useContext ( AuthContext ); return ( < Route {... rest } render = {( props ) => { if ( authenticated ) { return children ; } else { return ( < Redirect to = {{ pathname : \"/login/\" , state : { from : props . location } }} /> ); } }} /> ); }; export default PrivateRoute ;","title":"Private Routes"},{"location":"frontend/state-management/","text":"We will need to store the data received in a way that allows it to be used across multiple components. To manage this state we'll use React-Query as I find it much easier to use than say other popular tools like Redux or MobX. React-Query is installed via npm, npm install --save react-query To use React-Query a QueryClient must be provided via React-Query's QueryClientProvider , which is achieved by adding the following to frontend/src/App.tsx , ... // Existing imports import { QueryClient , QueryClientProvider } from \"react-query\" ; const queryClient = new QueryClient (); const App => { ... // Existing code return ( < QueryClientProvider client = { queryClient } > ... // Existing components < /QueryClientProvider> ); }; Handling authentication We need to adapt React-Query so that requests that aren't authenticated result in changes to the AuthContext. This is to handle the case where a user visits a page without logging in first. We'll also only allow retries if the server doesn't respond, or responds with a 5XX status code. To do so we'll write a wrapper around React-Query's useQuery and useMutation by adding the following to frontend/src/query.ts , import { AxiosError } from \"axios\" ; import { useContext } from \"react\" ; import { MutationFunction , QueryFunction , QueryFunctionContext , QueryKey , useMutation as useReactMutation , UseMutationOptions , UseMutationResult , useQuery as useReactQuery , UseQueryOptions , UseQueryResult , } from \"react-query\" ; import { AuthContext } from \"src/AuthContext\" ; const MAX_FAILURES = 2 ; export function useQuery < TQueryFnData = unknown , TData = TQueryFnData , TQueryKey extends QueryKey = QueryKey , > ( queryKey : TQueryKey , queryFn : QueryFunction < TQueryFnData , TQueryKey > , options? : UseQueryOptions < TQueryFnData , AxiosError , TData , TQueryKey > , ) : UseQueryResult < TData , AxiosError > { const { setAuthenticated } = useContext ( AuthContext ); return useReactQuery < TQueryFnData , AxiosError , TData , TQueryKey > ( queryKey , async ( context : QueryFunctionContext < TQueryKey > ) => { try { return await queryFn ( context ); } catch ( error ) { if ( error . response && error . response . status === 401 ) { setAuthenticated ( false ); } throw error ; } }, { retry : ( _ : any , error : AxiosError ) => failureCount < MAX_FAILURES && ( ! error . response || error . response . status >= 500 ), ... options , }, ); } export function useMutation < TData = unknown , TVariables = void , TContext = unknown , > ( mutationFn : MutationFunction < TData , TVariables > , options? : UseMutationOptions < TData , AxiosError , TVariables , TContext > , ) : UseMutationResult < TData , AxiosError , TVariables , TContext > { const { setAuthenticated } = useContext ( AuthContext ); return useReactMutation < TData , AxiosError , TVariables , TContext > ( async ( variables : TVariables ) => { try { return await mutationFn ( variables ); } catch ( error ) { if ( error . response && error . response . status === 401 ) { setAuthenticated ( false ); } throw error ; } }, { retry : ( _ : any , error : AxiosError ) => failureCount < MAX_FAILURES && ( ! error . response || error . response . status >= 500 ), ... options , }, ); }","title":"State management"},{"location":"frontend/state-management/#handling-authentication","text":"We need to adapt React-Query so that requests that aren't authenticated result in changes to the AuthContext. This is to handle the case where a user visits a page without logging in first. We'll also only allow retries if the server doesn't respond, or responds with a 5XX status code. To do so we'll write a wrapper around React-Query's useQuery and useMutation by adding the following to frontend/src/query.ts , import { AxiosError } from \"axios\" ; import { useContext } from \"react\" ; import { MutationFunction , QueryFunction , QueryFunctionContext , QueryKey , useMutation as useReactMutation , UseMutationOptions , UseMutationResult , useQuery as useReactQuery , UseQueryOptions , UseQueryResult , } from \"react-query\" ; import { AuthContext } from \"src/AuthContext\" ; const MAX_FAILURES = 2 ; export function useQuery < TQueryFnData = unknown , TData = TQueryFnData , TQueryKey extends QueryKey = QueryKey , > ( queryKey : TQueryKey , queryFn : QueryFunction < TQueryFnData , TQueryKey > , options? : UseQueryOptions < TQueryFnData , AxiosError , TData , TQueryKey > , ) : UseQueryResult < TData , AxiosError > { const { setAuthenticated } = useContext ( AuthContext ); return useReactQuery < TQueryFnData , AxiosError , TData , TQueryKey > ( queryKey , async ( context : QueryFunctionContext < TQueryKey > ) => { try { return await queryFn ( context ); } catch ( error ) { if ( error . response && error . response . status === 401 ) { setAuthenticated ( false ); } throw error ; } }, { retry : ( _ : any , error : AxiosError ) => failureCount < MAX_FAILURES && ( ! error . response || error . response . status >= 500 ), ... options , }, ); } export function useMutation < TData = unknown , TVariables = void , TContext = unknown , > ( mutationFn : MutationFunction < TData , TVariables > , options? : UseMutationOptions < TData , AxiosError , TVariables , TContext > , ) : UseMutationResult < TData , AxiosError , TVariables , TContext > { const { setAuthenticated } = useContext ( AuthContext ); return useReactMutation < TData , AxiosError , TVariables , TContext > ( async ( variables : TVariables ) => { try { return await mutationFn ( variables ); } catch ( error ) { if ( error . response && error . response . status === 401 ) { setAuthenticated ( false ); } throw error ; } }, { retry : ( _ : any , error : AxiosError ) => failureCount < MAX_FAILURES && ( ! error . response || error . response . status >= 500 ), ... options , }, ); }","title":"Handling authentication"},{"location":"frontend/toasts/","text":"Toasts can be used to show contextual messages to the user that are not part of the page. A good example is showing an error message if a request to the backend fails. Another would be showing a success message after the user changes their password - as there is no direct confirmation via the page content. Firstly lets create a ToastContext that we can use throughout the app to add toasts as required by adding the following to frontend/src/ToastContext.tsx , import { Color } from \"@material-ui/lab/Alert\" ; import React from \"react\" ; export interface IToast { category? : Color ; message : string ; } interface IToastContext { addToast : ( toast : IToast ) => void ; setToasts : React.Dispatch < React . SetStateAction < IToast [] >> ; toasts : IToast []; } export const ToastContext = React . createContext < IToastContext > ({ addToast : () => {}, setToasts : () => {}, toasts : [], }); interface IProps { children? : React.ReactNode ; } export const ToastContextProvider = ({ children } : IProps ) => { const [ toasts , setToasts ] = React . useState < IToast [] > ([]); const addToast = ( toast : IToast ) => { setToasts (( toasts ) => [... toasts , toast ]); }; return ( < ToastContext . Provider value = {{ addToast , setToasts , toasts }} > { children } < /ToastContext.Provider> ); }; We'll use the Material-UI snackbar to display toasts, and the Material-UI Alert to style the snack depending on the category (error, success, etc). The Alert is currently part of the Material-UI lab that can be installed via npm, npm install --save @material-ui/lab We can then create a Toasts component to display them. Note that only one toast should be displayed at any point in time, so a useEffect is setup to take and display a toast whenever there are toasts to display and there isn't an open one. The following should be added to frontend/src/components/Toasts.tsx , import Snackbar from \"@material-ui/core/Snackbar\" ; import Alert from \"@material-ui/lab/Alert\" ; import React , { useEffect } from \"react\" ; import { ToastContext , IToast } from \"src/ToastContext\" ; const Toasts = () => { const { toasts , setToasts } = React . useContext ( ToastContext ); const [ open , setOpen ] = React . useState ( false ); const [ currentToast , setCurrentToast ] = React . useState < IToast | undefined > (); useEffect (() => { if ( ! open && toasts . length ) { setCurrentToast ( toasts [ 0 ]); setToasts (( prev ) => prev . slice ( 1 )); setOpen ( true ); } }, [ open , setCurrentToast , setOpen , setToasts , toasts ]); const onClose = ( event? : React.SyntheticEvent , reason? : string ) => { if ( reason !== \"clickaway\" ) { setOpen ( false ); } }; return ( < Snackbar anchorOrigin = {{ horizontal : \"center\" , vertical : \"top\" , }} autoHideDuration = { 6000 } onClose = { onClose } onExited = {() => setCurrentToast ( undefined )} open = { open } > < Alert onClose = { onClose } severity = { currentToast ? . category } variant = \"filled\" > { currentToast ? . message } < /Alert> < /Snackbar> ); }; export default Toasts ; Finally we can add the following to src/App.tsx to enable toasts in the app, ... import Toasts from \"src/components/Toasts\" ; import { ToastContextProvider } from \"src/ToastContext\" ; const App = () => { ... return ( < ToastContextProvider > < Toasts /> ... < /ToastContextProvider> ); }","title":"Toasts"},{"location":"frontend/todo-pages/","text":"We will need to provide pages for users to create a new todo and edit any existing ones. These pages both require a form that describes a todo, which can be the same for both. This reduces the code we need to write and removes duplication. This todo-form component will need props for its initial values, a label for the submit button, and a callable to be called on submission. The following should be added to frontend/src/components/TodoForm.tsx , import { Form , Formik } from \"formik\" ; import React from \"react\" ; import { useTranslation } from \"react-i18next\" ; import * as yup from \"yup\" ; import CheckboxField from \"src/components/CheckboxField\" ; import DateField from \"src/components/DateField\" ; import SecondaryButton from \"src/components/SecondaryButton\" ; import SubmitButton from \"src/components/SubmitButton\" ; import TextField from \"src/components/TextField\" ; export interface IForm { complete : boolean ; due : Date | null ; task : string ; } interface IProps { initialValues : IForm ; label : string ; onSubmit : ( data : IForm ) => Promise < any > ; } const TodoForm = ({ initialValues , label , onSubmit } : IProps ) => { const { t } = useTranslation (); const validationSchema = yup . object ({ complete : yup.boolean (), due : yup.date (). nullable (), task : yup.string (). required ( t ( \"generic.required\" )), }); return ( < Formik < IForm > initialValues = { initialValues } onSubmit = { onSubmit } validationSchema = { validationSchema } > {({ isSubmitting }) => ( < Form > < TextField fullWidth = { true } label = { t ( \"todo.task\" )} name = \"task\" required = { true } /> < DateField fullWidth = { true } label = { t ( \"todo.due\" )} name = \"due\" /> < CheckboxField fullWidth = { true } label = { t ( \"todo.complete\" )} name = \"complete\" /> < SubmitButton label = { label } submitting = { isSubmitting } /> < SecondaryButton label = { t ( \"generic.back\" )} to = \"/todos/\" /> < /Form> )} < /Formik> ); }; export default TodoForm ; Creating a todo We can then use the TodoForm in a page to create a todo by adding the following to frontend/src/pages/CreateTodo.tsx , import Box from \"@material-ui/core/Box\" ; import Typography from \"@material-ui/core/Typography\" ; import axios from \"axios\" ; import React , { useContext } from \"react\" ; import { useTranslation } from \"react-i18next\" ; import { useQueryClient } from \"react-query\" ; import { useHistory } from \"react-router\" ; import TodoForm , { IForm } from \"src/components/TodoForm\" ; import { Todo } from \"src/models\" ; import { useMutation } from \"src/query\" ; import { ToastContext } from \"src/ToastContext\" ; const CreateTodo = () => { const { t } = useTranslation (); const history = useHistory (); const { addToast } = useContext ( ToastContext ); const queryClient = useQueryClient (); const { mutateAsync : createTodo } = useMutation ( async ( data : IForm ) => { const response = await axios . post ( \"/todos/\" , data ); return new Todo ( response . data ); }, { onSuccess : async ( todo : Todo ) => { queryClient . setQueryData ([ \"todos\" , todo . id . toString ()], todo ); if ( queryClient . getQueryState ( \"todos\" ) !== undefined ) { queryClient . setQueryData ( \"todos\" , ( data : Todo [] | undefined ) => data ! . map (( datum ) => ( datum . id === todo . id ? todo : datum )), ); } }, }, ); const onSubmit = async ( data : IForm ) => { try { await createTodo ( data ); history . push ( \"/\" ); } catch { addToast ({ category : \"error\" , message : t ( \"generic.tryAgainError\" ) }); } }; return ( <> < Box mb = { 1 } mt = { 2 } > < Typography component = \"h1\" variant = \"h5\" > { t ( \"CreateTodo.lead\" )} < /Typography> < /Box> < TodoForm initialValues = {{ complete : false , due : null , task : \"\" }} label = { t ( \"CreateTodo.create\" )} onSubmit = { onSubmit } /> < /> ); }; export default CreateTodo ; Note I like to use an additional onSubmit function that calls the mutation ( createTodo ) function with the latter handling any changes to the query ( queryClient ) state and the former handling everything else. Editing a todo We can also use the TodoForm to allow editing of a todo - as identified by its ID in the path. Much like with the Todos page we can improve the user experience by showing a skeleton whilst we wait for the backend to respond. The following should be added to frontend/src/pages/EditTodo.tsx , import Box from \"@material-ui/core/Box\" ; import Typography from \"@material-ui/core/Typography\" ; import Skeleton from \"@material-ui/lab/Skeleton\" ; import axios from \"axios\" ; import React , { useContext } from \"react\" ; import { useTranslation } from \"react-i18next\" ; import { useQueryClient } from \"react-query\" ; import { useHistory , useParams } from \"react-router\" ; import TodoForm , { IForm } from \"src/components/TodoForm\" ; import { Todo } from \"src/models\" ; import { useMutation , useQuery } from \"src/query\" ; import { ToastContext } from \"src/ToastContext\" ; interface IParams { id : string ; } const EditTodo = () => { const { t } = useTranslation (); const history = useHistory (); const params = useParams < IParams > (); const todoId = parseInt ( params . id , 10 ); const { addToast } = useContext ( ToastContext ); const queryClient = useQueryClient (); const { data : todo } = useQuery < Todo > ( [ \"todos\" , todoId . toString ()], async () => { const response = await axios . get ( `/todos/ ${ todoId } /` ); return new Todo ( response . data ); }, { initialData : () => { return queryClient . getQueryData < Todo [] > ( \"todos\" ) ? . filter (( todo : Todo ) => todo . id === todoId )[ 0 ]; }, }, ); const { mutateAsync : editTodo } = useMutation ( async ( data : IForm ) => { const response = await axios . put ( `/todos/ ${ todoId } /` , data ); return new Todo ( response . data ); }, { onSuccess : async ( todo : Todo ) => { queryClient . setQueryData ([ \"todos\" , todo . id . toString ()], todo ); if ( queryClient . getQueryState ( \"todos\" ) !== undefined ) { queryClient . setQueryData ( \"todos\" , ( data : Todo [] | undefined ) => data ! . map (( datum ) => ( datum . id === todo . id ? todo : datum )), ); } history . push ( \"/\" ); }, }, ); const onSubmit = async ( data : IForm ) => { try { await editTodo ( data ); history . push ( \"/\" ); } catch { addToast ({ category : \"error\" , message : t ( \"generic.tryAgainError\" ) }); } }; return ( <> < Box mb = { 1 } mt = { 2 } > < Typography component = \"h1\" variant = \"h5\" > { t ( \"EditTodo.lead\" )} < /Typography> < /Box> { todo === undefined ? ( <> < Skeleton height = \"80px\" /> < Skeleton height = \"80px\" /> < Skeleton height = \"80px\" width = \"200px\" /> < Skeleton height = \"80px\" width = \"200px\" /> < /> ) : ( < TodoForm initialValues = {{ complete : todo.complete , due : todo.due ?? null , task : todo.task , }} label = { t ( \"EditTodo.edit\" )} onSubmit = { onSubmit } /> )} < /> ); }; export default EditTodo ; Routing changes Both pages need to be added to the routing to be reachable, by adding the following to frontend/src/Router.tsx , import PrivateRoute from \"src/components/PrivateRoute\" ; import Todos from \"src/pages/Todos\" ; ... const Router = () => ( < BrowserRouter > ... < PrivateRoute exact = { true } path = \"/todos/new/\" > < CreateTodo /> < /PrivateRoute> < PrivateRoute exact = { true } path = \"/todos/:id(\\d+)/\" > < EditTodo /> < /PrivateRoute> < /BrowserRouter> );","title":"Create and edit todos"},{"location":"frontend/todo-pages/#creating-a-todo","text":"We can then use the TodoForm in a page to create a todo by adding the following to frontend/src/pages/CreateTodo.tsx , import Box from \"@material-ui/core/Box\" ; import Typography from \"@material-ui/core/Typography\" ; import axios from \"axios\" ; import React , { useContext } from \"react\" ; import { useTranslation } from \"react-i18next\" ; import { useQueryClient } from \"react-query\" ; import { useHistory } from \"react-router\" ; import TodoForm , { IForm } from \"src/components/TodoForm\" ; import { Todo } from \"src/models\" ; import { useMutation } from \"src/query\" ; import { ToastContext } from \"src/ToastContext\" ; const CreateTodo = () => { const { t } = useTranslation (); const history = useHistory (); const { addToast } = useContext ( ToastContext ); const queryClient = useQueryClient (); const { mutateAsync : createTodo } = useMutation ( async ( data : IForm ) => { const response = await axios . post ( \"/todos/\" , data ); return new Todo ( response . data ); }, { onSuccess : async ( todo : Todo ) => { queryClient . setQueryData ([ \"todos\" , todo . id . toString ()], todo ); if ( queryClient . getQueryState ( \"todos\" ) !== undefined ) { queryClient . setQueryData ( \"todos\" , ( data : Todo [] | undefined ) => data ! . map (( datum ) => ( datum . id === todo . id ? todo : datum )), ); } }, }, ); const onSubmit = async ( data : IForm ) => { try { await createTodo ( data ); history . push ( \"/\" ); } catch { addToast ({ category : \"error\" , message : t ( \"generic.tryAgainError\" ) }); } }; return ( <> < Box mb = { 1 } mt = { 2 } > < Typography component = \"h1\" variant = \"h5\" > { t ( \"CreateTodo.lead\" )} < /Typography> < /Box> < TodoForm initialValues = {{ complete : false , due : null , task : \"\" }} label = { t ( \"CreateTodo.create\" )} onSubmit = { onSubmit } /> < /> ); }; export default CreateTodo ; Note I like to use an additional onSubmit function that calls the mutation ( createTodo ) function with the latter handling any changes to the query ( queryClient ) state and the former handling everything else.","title":"Creating a todo"},{"location":"frontend/todo-pages/#editing-a-todo","text":"We can also use the TodoForm to allow editing of a todo - as identified by its ID in the path. Much like with the Todos page we can improve the user experience by showing a skeleton whilst we wait for the backend to respond. The following should be added to frontend/src/pages/EditTodo.tsx , import Box from \"@material-ui/core/Box\" ; import Typography from \"@material-ui/core/Typography\" ; import Skeleton from \"@material-ui/lab/Skeleton\" ; import axios from \"axios\" ; import React , { useContext } from \"react\" ; import { useTranslation } from \"react-i18next\" ; import { useQueryClient } from \"react-query\" ; import { useHistory , useParams } from \"react-router\" ; import TodoForm , { IForm } from \"src/components/TodoForm\" ; import { Todo } from \"src/models\" ; import { useMutation , useQuery } from \"src/query\" ; import { ToastContext } from \"src/ToastContext\" ; interface IParams { id : string ; } const EditTodo = () => { const { t } = useTranslation (); const history = useHistory (); const params = useParams < IParams > (); const todoId = parseInt ( params . id , 10 ); const { addToast } = useContext ( ToastContext ); const queryClient = useQueryClient (); const { data : todo } = useQuery < Todo > ( [ \"todos\" , todoId . toString ()], async () => { const response = await axios . get ( `/todos/ ${ todoId } /` ); return new Todo ( response . data ); }, { initialData : () => { return queryClient . getQueryData < Todo [] > ( \"todos\" ) ? . filter (( todo : Todo ) => todo . id === todoId )[ 0 ]; }, }, ); const { mutateAsync : editTodo } = useMutation ( async ( data : IForm ) => { const response = await axios . put ( `/todos/ ${ todoId } /` , data ); return new Todo ( response . data ); }, { onSuccess : async ( todo : Todo ) => { queryClient . setQueryData ([ \"todos\" , todo . id . toString ()], todo ); if ( queryClient . getQueryState ( \"todos\" ) !== undefined ) { queryClient . setQueryData ( \"todos\" , ( data : Todo [] | undefined ) => data ! . map (( datum ) => ( datum . id === todo . id ? todo : datum )), ); } history . push ( \"/\" ); }, }, ); const onSubmit = async ( data : IForm ) => { try { await editTodo ( data ); history . push ( \"/\" ); } catch { addToast ({ category : \"error\" , message : t ( \"generic.tryAgainError\" ) }); } }; return ( <> < Box mb = { 1 } mt = { 2 } > < Typography component = \"h1\" variant = \"h5\" > { t ( \"EditTodo.lead\" )} < /Typography> < /Box> { todo === undefined ? ( <> < Skeleton height = \"80px\" /> < Skeleton height = \"80px\" /> < Skeleton height = \"80px\" width = \"200px\" /> < Skeleton height = \"80px\" width = \"200px\" /> < /> ) : ( < TodoForm initialValues = {{ complete : todo.complete , due : todo.due ?? null , task : todo.task , }} label = { t ( \"EditTodo.edit\" )} onSubmit = { onSubmit } /> )} < /> ); }; export default EditTodo ;","title":"Editing a todo"},{"location":"frontend/todo-pages/#routing-changes","text":"Both pages need to be added to the routing to be reachable, by adding the following to frontend/src/Router.tsx , import PrivateRoute from \"src/components/PrivateRoute\" ; import Todos from \"src/pages/Todos\" ; ... const Router = () => ( < BrowserRouter > ... < PrivateRoute exact = { true } path = \"/todos/new/\" > < CreateTodo /> < /PrivateRoute> < PrivateRoute exact = { true } path = \"/todos/:id(\\d+)/\" > < EditTodo /> < /PrivateRoute> < /BrowserRouter> );","title":"Routing changes"},{"location":"frontend/todos-page/","text":"The todos page is effectively the user's homepage, it needs to show the user's todos, and provide actions to create new ones and edit the existing. The action to create a todo is a good use case for a floating action button, as it should have an unambiguous meaning. Whereas the editing action is best triggered by clicking each individual todo. To provide a better user experience we can show skeleton todos whilst we wait for the todo API to respond. I've chosen to show 3 skeleton todos to give an indication that there will be a few. Note also the due date is formatted according to the user's chosen language. The following code to do all this should be placed in frontend/src/pages/Todos.tsx , import Checkbox from \"@material-ui/core/Checkbox\" ; import Fab from \"@material-ui/core/Fab\" ; import List from \"@material-ui/core/List\" ; import ListItem from \"@material-ui/core/ListItem\" ; import ListItemIcon from \"@material-ui/core/ListItemIcon\" ; import ListItemText from \"@material-ui/core/ListItemText\" ; import AddIcon from \"@material-ui/icons/Add\" ; import Skeleton from \"@material-ui/lab/Skeleton\" ; import axios from \"axios\" ; import { format } from \"date-fns\" ; import { enGB , de } from \"date-fns/locale\" ; import React from \"react\" ; import { useTranslation } from \"react-i18next\" ; import { Link } from \"react-router-dom\" ; import styled from \"styled-components\" ; import { Todo } from \"src/models\" ; import { useQuery } from \"src/query\" ; const SFab : typeof Fab = styled ( Fab ) ` bottom: ${ ( props ) => props . theme . spacing ( 2 ) } px; position: fixed; right: ${ ( props ) => props . theme . spacing ( 2 ) } px; ` ; const Todos = () => { const { data : todos } = useQuery < Todo [] > ( \"todos\" , async () => { const response = await axios . get ( \"/todos/\" ); return response . data . todos . map (( json : any ) => new Todo ( json )); }); const { i18n } = useTranslation (); const locale = i18n . language === \"en\" ? enGB : de ; return ( <> < List > { todos ? . map (( todo : Todo ) => { const secondary = todo . due ? format ( todo . due , \"P\" , { locale }) : undefined ; return ( < ListItem key = { todo . id } button = { true } component = { Link } to = { `/todos/ ${ todo . id } /` } > < ListItemIcon > < Checkbox checked = { todo . complete } disabled = { true } disableRipple = { true } edge = \"start\" tabIndex = { - 1 } /> < /ListItemIcon> < ListItemText primary = { todo . task } secondary = { secondary } /> < /ListItem> ); }) ?? [ 1 , 2 , 3 ]. map (( id ) => ( < ListItem key = { id } > < ListItemIcon > < Checkbox disabled = { true } disableRipple = { true } edge = \"start\" tabIndex = { - 1 } /> < /ListItemIcon> < ListItemText primary = { < Skeleton /> } secondary = { < Skeleton width = \"200px\" /> } /> < /ListItem> ))} < /List> < SFab component = { Link } to = \"/todos/new/\" > < AddIcon /> < /SFab> < /> ); }; export default Todos ; Then we can add the page to the routing (twice for the two relevant paths) by adding the following to frontend/src/Router.tsx , import PrivateRoute from \"src/components/PrivateRoute\" ; import Todos from \"src/pages/Todos\" ; ... const Router = () => ( < BrowserRouter > ... < PrivateRoute exact = { true } path = \"/\" > < Todos /> < /PrivateRoute> < PrivateRoute exact = { true } path = \"/todos/\" > < Todos /> < /PrivateRoute> < /BrowserRouter> );","title":"View todos"},{"location":"local-setup/aims/","text":"The aim of this chapter is to install and setup enough tooling to make development easier and hence quicker. This will mean we can ship updates to the customer earlier and with greater confidence the experience will be great. Local development The shorter the time between making a change to code, and being able to run and see the affect of the change the better. As this feedback loop is the main way to develop. For this reason we'll ensure that we can run all the code locally ideally with it auto reloading on any change. Autoformatting The style of code matters as code written in a different style to the one you are used to will take longer to understand and may, in addition, lead to missed bugs. This is problematic as almost everyone has a different preferred style, and this changes over time. In the past I've used tooling to check the styling and report on any inconsistencies. This is helpful but wasteful, as every inconsistency must be fixed manually. Fortunately most languages now have an official, or dominant, autoformatter that both defines a style and changes all the code to match it. We'll aim to set up our tooling such that there are autoformatters for as much of the code as is possible. Linting I think of linting in two parts, type checking and static analysis 1 . I type hint, or used typed languages, where possible as this catches a large number of errors I typically make. It also helps document the code in that it makes it clear what objects (types) are expected. Whilst typing costs more effort to write, I think it easily pays off in bugs avoided. Therefore checking the typing should be our first aim of linting. I also like to use linters to look for potential issues in naming, usage of functions, possible bugs, security issues, unused code, and to flag code that is too complex or poorly constructed. These linters are a very low cost sanity check as they are quick and easy to run and give few false issues. Testing Linting can only find some many issues, notably it cannot detect logic errors where correctly written code in fact does the wrong thing. For this writing tests is the best option. Often when tests are discussed a coverage target is introduced, with coverage defined as lines tested over total lines of code. I think this is an unhelpful definition, instead I'd encourage you to consider coverage in terms of what the user cares about i.e. have you tested the use cases your users rely on? Analysing the code without running it i.e. statically. \u21a9","title":"Local setup aims"},{"location":"local-setup/aims/#local-development","text":"The shorter the time between making a change to code, and being able to run and see the affect of the change the better. As this feedback loop is the main way to develop. For this reason we'll ensure that we can run all the code locally ideally with it auto reloading on any change.","title":"Local development"},{"location":"local-setup/aims/#autoformatting","text":"The style of code matters as code written in a different style to the one you are used to will take longer to understand and may, in addition, lead to missed bugs. This is problematic as almost everyone has a different preferred style, and this changes over time. In the past I've used tooling to check the styling and report on any inconsistencies. This is helpful but wasteful, as every inconsistency must be fixed manually. Fortunately most languages now have an official, or dominant, autoformatter that both defines a style and changes all the code to match it. We'll aim to set up our tooling such that there are autoformatters for as much of the code as is possible.","title":"Autoformatting"},{"location":"local-setup/aims/#linting","text":"I think of linting in two parts, type checking and static analysis 1 . I type hint, or used typed languages, where possible as this catches a large number of errors I typically make. It also helps document the code in that it makes it clear what objects (types) are expected. Whilst typing costs more effort to write, I think it easily pays off in bugs avoided. Therefore checking the typing should be our first aim of linting. I also like to use linters to look for potential issues in naming, usage of functions, possible bugs, security issues, unused code, and to flag code that is too complex or poorly constructed. These linters are a very low cost sanity check as they are quick and easy to run and give few false issues.","title":"Linting"},{"location":"local-setup/aims/#testing","text":"Linting can only find some many issues, notably it cannot detect logic errors where correctly written code in fact does the wrong thing. For this writing tests is the best option. Often when tests are discussed a coverage target is introduced, with coverage defined as lines tested over total lines of code. I think this is an unhelpful definition, instead I'd encourage you to consider coverage in terms of what the user cares about i.e. have you tested the use cases your users rely on? Analysing the code without running it i.e. statically. \u21a9","title":"Testing"},{"location":"local-setup/backend-tooling/","text":"Poetry has a scripting feature that can be used to map poetry commands to arbitrary python code. For example poetry run hello can be mapped to, def hello (): print ( \"Hello\" ) This is useful as it makes it easier to remember the commands. This is done by creating a backend/scripts.py and editing the backend/pyproject.toml file. Most of these mappings will be to shell commands, for example poetry run test will ideally be mapped to pytest tests/ . The following helper function ensures that any output is from the shell command alone without any additional, and confusing, stack trace. It should be added to backend/scripts.py , import sys from subprocess import CalledProcessError , check_call def _check_call_quiet ( commands : list [ str ], * , shell : bool = False ) -> None : try : check_call ( commands , shell = shell ) except CalledProcessError as error : sys . exit ( error . returncode ) Formatting Python does not have an official format/formatter, however black is the de-facto formatter. We should add it to the project, as a development depenedency, poetry add --allow-prereleases --dev black which installed 20.8b1 (a pre release as black hasn't reached release stage yet). Whilst Black formats the code it doesn't order the imports, which is something I find very useful 1 . Therefore I also use isort which can be added, poetry add --dev isort Both Black and isort require configuring, which should be added to the backend/pyproject.toml . These are my preferred settings, [tool.black] line-length = 100 target-version = [\"py39\"] [tool.isort] combine_as_imports = true force_grid_wrap = 0 include_trailing_comma = true known_first_party = \"backend\" line_length = 100 multi_line_output = 3 no_lines_before = \"LOCALFOLDER\" order_by_type = false Black and isort format python code in .py files, however any code in templates will be left unformatted. Thankfully djhtml can be used to format the templates, it is added, poetry add --dev djhtml This allows two commands reformat to autoformat the code and format to check the formatting of the code to be added in the backend/pyproject.toml file, [tool.poetry.scripts] format = \"scripts:format\" reformat = \"scripts:reformat\" and the backend/scripts.py file, def format () -> None : _check_call_quiet ([ \"black\" , \"--check\" , \"--diff\" , \"src/\" , \"tests/\" ]) _check_call_quiet ([ \"isort\" , \"--check\" , \"--diff\" , \"src\" , \"tests\" ]) _check_call_quiet ( \"find src/ -name *.html | xargs djhtml --tabwidth 2 --check\" , shell = True , ) def reformat () -> None : _check_call_quiet ([ \"black\" , \"src/\" , \"tests/\" ]) _check_call_quiet ([ \"isort\" , \"src\" , \"tests\" ]) _check_call_quiet ( \"find src/ -name *.html | xargs djhtml --tabwidth 2 --in-place\" , shell = True , ) which allows, poetry run reformat poetry run format Remeber Whenever we install a new third party dependency the isort configuration needs updating, specifically the backend/pyproject.toml file should gain the name of the import, e.g. for quart-auth , [tool.isort] known_third_party = \"..., quart_auth\" where ... is the existing value. Linting Checking that the type hinting is consistent throughout i.e. the code is being called with the types the author expected catches a fair number of bugs. I use mypy to check this, as installed, poetry add --dev mypy and configured by adding the following to backend/pyproject.toml , [tool.mypy] allow_redefinition = true disallow_untyped_defs = true warn_unused_ignores = true Flake8 is my goto Python linting tool, along with the flake8-print , and pep8-naming plugins. These ensure I have readable (easier to understand) code, without any print statements. To install these, poetry add --dev flake8 flake8-print pep8-naming and configured in the backend/setup.cfg file 2 , (these settings avoid conflicts with the other tooling), [flake8] ignore = E203, E252, W503, W504 max_line_length = 100 I like to check that there is no dead code, i.e. code that is never called. This happens when I forget to delete, or get confused. My goto tool is vulture , which can be installed, poetry add --dev vulture and configured in the backend/pyproject.toml file, [tool.vulture] min_confidence = 100 Finally I like to check, and get some reassurance, that the code has no obvious security vulnerabilities. For this I use bandit , as installed, poetry add --dev bandit which requires no special configuration. These can then be combined into a single lint command, with these additions to backend/pyproject.toml , [tool.poetry.scripts] lint = \"scripts:lint\" ... and backend/scripts.py file, def lint () -> None : _check_call_quiet ([ \"mypy\" , \"src/backend/\" , \"tests/\" ]) _check_call_quiet ([ \"flake8\" , \"src/\" , \"tests/\" ]) _check_call_quiet ([ \"vulture\" , \"src/\" ]) _check_call_quiet ([ \"bandit\" , \"-r\" , \"src/\" ]) Testing Python has unittest as part of its standard library, however I think pytest is a superior option. As pytest is very feature rich (see fixtures) and allows for very simple and clear tests, def test_addition (): assert 1 + 1 == 2 To install pytest, and the pytest-asyncio plugin, poetry add --dev pytest pytest-asyncio and configured to ensure that locals are shown on error (as this really helps debug the failure), by adding the following to backend/pyproject.toml , [tool.pytest.ini_options] addopts = \"--showlocals\" This allows a test command, with these additions to backend/pyproject.toml , [tool.poetry.scripts] test = \"scripts:test\" ... and backend/scripts.py file, def test () -> None : _check_call_quiet ([ \"pytest\" , \"tests/\" , * sys . argv [ 1 :]]) passing the additional arguments allows commands like poetry run test -k test_basic.py to run just the tests in a test_basic.py file. Ordered imports make it very clear where imported code is from in terms or 1st, or 3rd party, or standard library. \u21a9 Saldy flake8 does not yet support configuring via the pyproject.toml file, see this issue \u21a9","title":"Backend: Tooling"},{"location":"local-setup/backend-tooling/#formatting","text":"Python does not have an official format/formatter, however black is the de-facto formatter. We should add it to the project, as a development depenedency, poetry add --allow-prereleases --dev black which installed 20.8b1 (a pre release as black hasn't reached release stage yet). Whilst Black formats the code it doesn't order the imports, which is something I find very useful 1 . Therefore I also use isort which can be added, poetry add --dev isort Both Black and isort require configuring, which should be added to the backend/pyproject.toml . These are my preferred settings, [tool.black] line-length = 100 target-version = [\"py39\"] [tool.isort] combine_as_imports = true force_grid_wrap = 0 include_trailing_comma = true known_first_party = \"backend\" line_length = 100 multi_line_output = 3 no_lines_before = \"LOCALFOLDER\" order_by_type = false Black and isort format python code in .py files, however any code in templates will be left unformatted. Thankfully djhtml can be used to format the templates, it is added, poetry add --dev djhtml This allows two commands reformat to autoformat the code and format to check the formatting of the code to be added in the backend/pyproject.toml file, [tool.poetry.scripts] format = \"scripts:format\" reformat = \"scripts:reformat\" and the backend/scripts.py file, def format () -> None : _check_call_quiet ([ \"black\" , \"--check\" , \"--diff\" , \"src/\" , \"tests/\" ]) _check_call_quiet ([ \"isort\" , \"--check\" , \"--diff\" , \"src\" , \"tests\" ]) _check_call_quiet ( \"find src/ -name *.html | xargs djhtml --tabwidth 2 --check\" , shell = True , ) def reformat () -> None : _check_call_quiet ([ \"black\" , \"src/\" , \"tests/\" ]) _check_call_quiet ([ \"isort\" , \"src\" , \"tests\" ]) _check_call_quiet ( \"find src/ -name *.html | xargs djhtml --tabwidth 2 --in-place\" , shell = True , ) which allows, poetry run reformat poetry run format Remeber Whenever we install a new third party dependency the isort configuration needs updating, specifically the backend/pyproject.toml file should gain the name of the import, e.g. for quart-auth , [tool.isort] known_third_party = \"..., quart_auth\" where ... is the existing value.","title":"Formatting"},{"location":"local-setup/backend-tooling/#linting","text":"Checking that the type hinting is consistent throughout i.e. the code is being called with the types the author expected catches a fair number of bugs. I use mypy to check this, as installed, poetry add --dev mypy and configured by adding the following to backend/pyproject.toml , [tool.mypy] allow_redefinition = true disallow_untyped_defs = true warn_unused_ignores = true Flake8 is my goto Python linting tool, along with the flake8-print , and pep8-naming plugins. These ensure I have readable (easier to understand) code, without any print statements. To install these, poetry add --dev flake8 flake8-print pep8-naming and configured in the backend/setup.cfg file 2 , (these settings avoid conflicts with the other tooling), [flake8] ignore = E203, E252, W503, W504 max_line_length = 100 I like to check that there is no dead code, i.e. code that is never called. This happens when I forget to delete, or get confused. My goto tool is vulture , which can be installed, poetry add --dev vulture and configured in the backend/pyproject.toml file, [tool.vulture] min_confidence = 100 Finally I like to check, and get some reassurance, that the code has no obvious security vulnerabilities. For this I use bandit , as installed, poetry add --dev bandit which requires no special configuration. These can then be combined into a single lint command, with these additions to backend/pyproject.toml , [tool.poetry.scripts] lint = \"scripts:lint\" ... and backend/scripts.py file, def lint () -> None : _check_call_quiet ([ \"mypy\" , \"src/backend/\" , \"tests/\" ]) _check_call_quiet ([ \"flake8\" , \"src/\" , \"tests/\" ]) _check_call_quiet ([ \"vulture\" , \"src/\" ]) _check_call_quiet ([ \"bandit\" , \"-r\" , \"src/\" ])","title":"Linting"},{"location":"local-setup/backend-tooling/#testing","text":"Python has unittest as part of its standard library, however I think pytest is a superior option. As pytest is very feature rich (see fixtures) and allows for very simple and clear tests, def test_addition (): assert 1 + 1 == 2 To install pytest, and the pytest-asyncio plugin, poetry add --dev pytest pytest-asyncio and configured to ensure that locals are shown on error (as this really helps debug the failure), by adding the following to backend/pyproject.toml , [tool.pytest.ini_options] addopts = \"--showlocals\" This allows a test command, with these additions to backend/pyproject.toml , [tool.poetry.scripts] test = \"scripts:test\" ... and backend/scripts.py file, def test () -> None : _check_call_quiet ([ \"pytest\" , \"tests/\" , * sys . argv [ 1 :]]) passing the additional arguments allows commands like poetry run test -k test_basic.py to run just the tests in a test_basic.py file. Ordered imports make it very clear where imported code is from in terms or 1st, or 3rd party, or standard library. \u21a9 Saldy flake8 does not yet support configuring via the pyproject.toml file, see this issue \u21a9","title":"Testing"},{"location":"local-setup/backend/","text":"The backend will be written in Python, so we need Python installed to run it locally. You may already have a version of Python installed, but we need to use Python>=3.9 so I'd recommend installing, brew install python which installed Python 3.9.0. Creating a backend project Brew, the package manager we've used so far, doesn't know how to install and manage Python packages. So we also need another package manager. There are many choices in Python, and I think Poetry is the best, so lets install, brew install poetry which installed Poetry 1.1.0. We'll keep the backend code separate in a backend folder, so please create it at the top level of the project and then create a new poetry project within that folder, poetry new --src backend which should give the following folder structure, tozo \u2514\u2500\u2500 backend \u251c\u2500\u2500 pyproject.toml \u251c\u2500\u2500 README.rst \u251c\u2500\u2500 src \u2502 \u2514\u2500\u2500 backend \u2502 \u2514\u2500\u2500 __init__.py \u2514\u2500\u2500 tests \u251c\u2500\u2500 __init__.py \u2514\u2500\u2500 test_backend.py only the pyproject.toml and folder structure matter at the moment, so you can delete or adapt the other files as you'd like.","title":"Backend: Python"},{"location":"local-setup/backend/#creating-a-backend-project","text":"Brew, the package manager we've used so far, doesn't know how to install and manage Python packages. So we also need another package manager. There are many choices in Python, and I think Poetry is the best, so lets install, brew install poetry which installed Poetry 1.1.0. We'll keep the backend code separate in a backend folder, so please create it at the top level of the project and then create a new poetry project within that folder, poetry new --src backend which should give the following folder structure, tozo \u2514\u2500\u2500 backend \u251c\u2500\u2500 pyproject.toml \u251c\u2500\u2500 README.rst \u251c\u2500\u2500 src \u2502 \u2514\u2500\u2500 backend \u2502 \u2514\u2500\u2500 __init__.py \u2514\u2500\u2500 tests \u251c\u2500\u2500 __init__.py \u2514\u2500\u2500 test_backend.py only the pyproject.toml and folder structure matter at the moment, so you can delete or adapt the other files as you'd like.","title":"Creating a backend project"},{"location":"local-setup/brew/","text":"I'm assuming you don't have tooling such as Python installed and so the first step is to install a package manager than can install Python and everything else you'll need. In my view Homebrew is the best package manager for this and works on MacOS, brew.sh , or Linux, linuxbrew.sh . (I don't use Windows so I'm not sure what to use). Note A package manager is used to install packages, for example specific versions of Python or Node. This is useful as it is often not trivial to install these packages, except when a package manager does it for you. With brew installed you can now install packages, e.g. to install python brew install python or to view the packages you have installed, brew list From this point on I'll assumed you have brew installed and that you are using it to manage you system packages.","title":"Installing packages"},{"location":"local-setup/database-tooling/","text":"The database is used from the backend code, and so the tooling to control the database is best placed with the backend tooling. Firstly we need commands to delete/drop the database (and user) and then to create them. This will be invoked via, poetry run recreate_db by adding the following to the backend/pyproject.toml file, [tool.poetry.scripts] recreate_db = \"scripts:recreate_db\" ... and to the backend/scripts.py file, from subprocess import call , DEVNULL def create_db ( database : str = \"tozo\" ) -> None : call ( [ \"psql\" , \"-U\" , \"postgres\" , \"-c\" , \"CREATE USER tozo LOGIN PASSWORD 'tozo' CREATEDB\" ], stdout = DEVNULL , stderr = DEVNULL , ) call ( [ \"psql\" , \"-U\" , \"postgres\" , \"-c\" , f \"CREATE DATABASE { database } \" ], stdout = DEVNULL , stderr = DEVNULL , ) def drop_db ( database : str = \"tozo\" ) -> None : call ( [ \"psql\" , \"-U\" , \"postgres\" , \"-c\" , f \"DROP DATABASE { database } \" ], stdout = DEVNULL , stderr = DEVNULL , ) call ( [ \"psql\" , \"-U\" , \"postgres\" , \"-c\" , \"DROP USER tozo\" ], stdout = DEVNULL , stderr = DEVNULL , ) def recreate_db ( database : str = \"tozo\" ) -> None : drop_db ( database ) create_db ( database ) Note call is used here rather than check_output used elsewhere as these calls shouldn't error on failure. This is to allow the command to succeed if there is no existing database to drop and to allow the individual commands (create_db, drop_db) to be called multiple times without failing. Testing locally It can be tempting to try and mock the database in our tests, however in my experience this reduces the utility of the tests and takes a huge amount of effort. Instead we'll test against an actual postgres database. As we want our tests to be deterministic we should create a new clean database before running any tests, we can do this by using the recreate_db function in the existing test function in backend/scripts.py so that it becomes, def test () -> None : recreate_db ( \"tozo_test\" ) _check_call_quiet ([ \"pytest\" , \"tests/\" , * sys . argv [ 1 :]]) Note The database name is different, tozo_test instead of tozo so as to prevent tests changing our development database. Testing in CI In CI we will use a database service to test against. As it is created for us so the recreate_db command isn't required. Therefore we need a new script command, test_ci defined in backend/pyproject.toml , [tool.poetry.scripts] test_ci = \"scripts:test_ci\" ... and in backend/scripts.py , def test_ci () -> None : _check_call_quiet ([ \"pytest\" , \"tests/\" , * sys . argv [ 1 :]])","title":"Database, Tooling"},{"location":"local-setup/database-tooling/#testing-locally","text":"It can be tempting to try and mock the database in our tests, however in my experience this reduces the utility of the tests and takes a huge amount of effort. Instead we'll test against an actual postgres database. As we want our tests to be deterministic we should create a new clean database before running any tests, we can do this by using the recreate_db function in the existing test function in backend/scripts.py so that it becomes, def test () -> None : recreate_db ( \"tozo_test\" ) _check_call_quiet ([ \"pytest\" , \"tests/\" , * sys . argv [ 1 :]]) Note The database name is different, tozo_test instead of tozo so as to prevent tests changing our development database.","title":"Testing locally"},{"location":"local-setup/database-tooling/#testing-in-ci","text":"In CI we will use a database service to test against. As it is created for us so the recreate_db command isn't required. Therefore we need a new script command, test_ci defined in backend/pyproject.toml , [tool.poetry.scripts] test_ci = \"scripts:test_ci\" ... and in backend/scripts.py , def test_ci () -> None : _check_call_quiet ([ \"pytest\" , \"tests/\" , * sys . argv [ 1 :]])","title":"Testing in CI"},{"location":"local-setup/database/","text":"The data used in the app will will need to be stored somewhere. The relational database postgres is my go to choice. We'll need it installed locally for development, which we can do using brew, brew install postgres which installed postgres 13. You can then access the local database using the psql client, psql -U postgres note that postgres is the default user and may not exist, if it isn't create it using, createuser -s postgres We'll use the postgres superuser to create a specific user for our app later.","title":"Database, Postgres"},{"location":"local-setup/frontend-tooling/","text":"npm has a built in scripting tool that allows to map npm run commands to specific shell calls. For example, npm run hello can be mapped to echo \"Hello\" This is useful as it makes it easier to remember the commands. This is done by adding to the \"scripts\" mapping in frontend/package.json (as shown below). Formatting Typescript does not have an official format/formatter, however prettier is the de-facto formatter. We should add it to the project, as a development depenedency, npm install --save-dev prettier to match the Python style I configure prettier by adding to frontend/.prettierrc.json , { \"trailingComma\" : \"all\" } This allows two commands reformat to autoformat the code and format to check the formatting of the code to be added in the frontend/package.json file, \"scripts\" : { \"format\" : \"prettier --parser typescript --list-different \\\"src/**/*.{ts,tsx}\\\"\" , \"reformat\" : \"prettier --parser typescript --write \\\"src/**/*.{ts,tsx}\\\"\" , ... } and used npm run reformat npm run format Linting Linting the Typescript code ESLint is the de facto Typescript (Javascript) linter, however the default configuration has possible incompatibilities with prettier, so eslint-config-prettier is required. As with the backend I also like to order imports, for which eslint-plugin-import can be used. Finally we'll add langauge translations to the frontend, which are easily missed without eslint-plugin-i18next , npm install --save-dev eslint eslint-config-prettier eslint-plugin-i18next eslint-plugin-import as most of the configuration is already correct I change the \"eslintConfig\" section of the frontend/package.json to, (with the import rules matching the backend configuration), \"eslintConfig\" : { \"extends\" : [ \"react-app\" , \"react-app/jest\" , \"plugin:import/errors\" , \"plugin:import/warnings\" , \"plugin:import/typescript\" , \"prettier\" ], \"plugins\" : [ \"i18next\" ], \"rules\" : { \"i18next/no-literal-string\" : [ \"warn\" , { \"markupOnly\" : true , \"onlyAttribute\" : [ \"label\" ] } ], \"import/newline-after-import\" : \"error\" , \"import/no-unresolved\" : \"off\" , \"import/order\" : [ \"error\" , { \"alphabetize\" : { \"order\" : \"asc\" , \"caseInsensitive\" : true }, \"groups\" : [ \"builtin\" , \"external\" , \"internal\" ], \"pathGroups\" : [ { \"pattern\" : \"src/**\" , \"group\" : \"external\" , \"position\" : \"after\" } ], \"pathGroupsExcludedImportTypes\" : [ \"builtin\" ], \"newlines-between\" : \"always\" } ], \"no-console\" : \"warn\" , \"react-hooks/exhaustive-deps\" : \"error\" } } eslint can also automatically fix issues it finds, as this saves effort it is good to add this to the reformat command, by changing it in frontend/package.json to, \"scripts\" : { \"reformat\" : \"eslint --fix \\\"src/**/*.{ts,tsx}\\\"; prettier --parser typescript --write \\\"src/**/*.{ts,tsx}\\\"\" } Linting the CSS ESLint only lints the Typescript code, leaving any css unchecked. This is potentially problematic as it will allow errors to creep in to the css. stylelint and stylelint-order solve this problem, npm install --save-dev stylelint stylelint-order stylelint-config-standard These are configured by a stylelint section in the frontend/package.json file, \"stylelint\" : { \"extends\" : [ \"stylelint-config-standard\" ], \"plugins\" : [ \"stylelint-order\" ], \"rules\" : { \"order/properties-alphabetical-order\" : true , \"declaration-block-trailing-semicolon\" : null , \"declaration-colon-newline-after\" : null , \"declaration-empty-line-before\" : null } } Linting command Finnally this allows a lint (in frontend/package.json ) command to be defined, \"scripts\" : { \"lint\" : \"eslint \\\"src/**/*.{ts,tsx}\\\"; stylelint \\\"src/**/*.{ts,tsx}\\\"\" , } and used, npm run lint Testing The Create React App command used to setup the frontend also set up a testing command using jest, npm run test We'll alter the test command (in frontend/package.json ) to add the --passWithNoTests option, in order for the tests to pass whilst there aren't any, \"scripts\" : { \"test\" : \"react-scripts test --passWithNoTests\" , } Bundle analysis The frontend code will be delivered as bundles (in chunks) to the user. These bundles, especially the main bundle should be small so that the user isn't waiting too long for the code to be downloaded. To check the bundle size, and analyse what is included in each bundle I use source-map-explorer , npm install --save-dev source-map-explorer Which allows an analyse command to analyse the bundle sizes, via adding the following to the frontend/package.json file, \"scripts\" : { \"analyse\" : \"npm run build && source-map-explorer \\\"build/static/js/*.js\\\"\" , ... } and used npm run analyse","title":"Frontend: Tooling"},{"location":"local-setup/frontend-tooling/#formatting","text":"Typescript does not have an official format/formatter, however prettier is the de-facto formatter. We should add it to the project, as a development depenedency, npm install --save-dev prettier to match the Python style I configure prettier by adding to frontend/.prettierrc.json , { \"trailingComma\" : \"all\" } This allows two commands reformat to autoformat the code and format to check the formatting of the code to be added in the frontend/package.json file, \"scripts\" : { \"format\" : \"prettier --parser typescript --list-different \\\"src/**/*.{ts,tsx}\\\"\" , \"reformat\" : \"prettier --parser typescript --write \\\"src/**/*.{ts,tsx}\\\"\" , ... } and used npm run reformat npm run format","title":"Formatting"},{"location":"local-setup/frontend-tooling/#linting","text":"","title":"Linting"},{"location":"local-setup/frontend-tooling/#linting-the-typescript-code","text":"ESLint is the de facto Typescript (Javascript) linter, however the default configuration has possible incompatibilities with prettier, so eslint-config-prettier is required. As with the backend I also like to order imports, for which eslint-plugin-import can be used. Finally we'll add langauge translations to the frontend, which are easily missed without eslint-plugin-i18next , npm install --save-dev eslint eslint-config-prettier eslint-plugin-i18next eslint-plugin-import as most of the configuration is already correct I change the \"eslintConfig\" section of the frontend/package.json to, (with the import rules matching the backend configuration), \"eslintConfig\" : { \"extends\" : [ \"react-app\" , \"react-app/jest\" , \"plugin:import/errors\" , \"plugin:import/warnings\" , \"plugin:import/typescript\" , \"prettier\" ], \"plugins\" : [ \"i18next\" ], \"rules\" : { \"i18next/no-literal-string\" : [ \"warn\" , { \"markupOnly\" : true , \"onlyAttribute\" : [ \"label\" ] } ], \"import/newline-after-import\" : \"error\" , \"import/no-unresolved\" : \"off\" , \"import/order\" : [ \"error\" , { \"alphabetize\" : { \"order\" : \"asc\" , \"caseInsensitive\" : true }, \"groups\" : [ \"builtin\" , \"external\" , \"internal\" ], \"pathGroups\" : [ { \"pattern\" : \"src/**\" , \"group\" : \"external\" , \"position\" : \"after\" } ], \"pathGroupsExcludedImportTypes\" : [ \"builtin\" ], \"newlines-between\" : \"always\" } ], \"no-console\" : \"warn\" , \"react-hooks/exhaustive-deps\" : \"error\" } } eslint can also automatically fix issues it finds, as this saves effort it is good to add this to the reformat command, by changing it in frontend/package.json to, \"scripts\" : { \"reformat\" : \"eslint --fix \\\"src/**/*.{ts,tsx}\\\"; prettier --parser typescript --write \\\"src/**/*.{ts,tsx}\\\"\" }","title":"Linting the Typescript code"},{"location":"local-setup/frontend-tooling/#linting-the-css","text":"ESLint only lints the Typescript code, leaving any css unchecked. This is potentially problematic as it will allow errors to creep in to the css. stylelint and stylelint-order solve this problem, npm install --save-dev stylelint stylelint-order stylelint-config-standard These are configured by a stylelint section in the frontend/package.json file, \"stylelint\" : { \"extends\" : [ \"stylelint-config-standard\" ], \"plugins\" : [ \"stylelint-order\" ], \"rules\" : { \"order/properties-alphabetical-order\" : true , \"declaration-block-trailing-semicolon\" : null , \"declaration-colon-newline-after\" : null , \"declaration-empty-line-before\" : null } }","title":"Linting the CSS"},{"location":"local-setup/frontend-tooling/#linting-command","text":"Finnally this allows a lint (in frontend/package.json ) command to be defined, \"scripts\" : { \"lint\" : \"eslint \\\"src/**/*.{ts,tsx}\\\"; stylelint \\\"src/**/*.{ts,tsx}\\\"\" , } and used, npm run lint","title":"Linting command"},{"location":"local-setup/frontend-tooling/#testing","text":"The Create React App command used to setup the frontend also set up a testing command using jest, npm run test We'll alter the test command (in frontend/package.json ) to add the --passWithNoTests option, in order for the tests to pass whilst there aren't any, \"scripts\" : { \"test\" : \"react-scripts test --passWithNoTests\" , }","title":"Testing"},{"location":"local-setup/frontend-tooling/#bundle-analysis","text":"The frontend code will be delivered as bundles (in chunks) to the user. These bundles, especially the main bundle should be small so that the user isn't waiting too long for the code to be downloaded. To check the bundle size, and analyse what is included in each bundle I use source-map-explorer , npm install --save-dev source-map-explorer Which allows an analyse command to analyse the bundle sizes, via adding the following to the frontend/package.json file, \"scripts\" : { \"analyse\" : \"npm run build && source-map-explorer \\\"build/static/js/*.js\\\"\" , ... } and used npm run analyse","title":"Bundle analysis"},{"location":"local-setup/frontend/","text":"The frontend will be written in Typescript, so we need Node installed to run it. To install node, brew install node which installed Node 16.2.0. As with Python brew doesn't know how to install javascript/typescript packages fortunately node comes with npm which is the default pacakge manager for JS/TS. Creating a React App As with the backend we'll separate the frontend code into a frontend folder but we'll use the create react app tool to set everything up by running this command in the project directory, npx create-react-app frontend --template typescript which should give the following folder structure, tozo \u251c\u2500\u2500 backend \u2502 \u2514\u2500\u2500 ... \u2514\u2500\u2500 frontend \u251c\u2500\u2500 .gitignore \u251c\u2500\u2500 README.md \u251c\u2500\u2500 node_modules \u251c\u2500\u2500 package.json \u251c\u2500\u2500 package-lock.json \u251c\u2500\u2500 tsconfig.json \u251c\u2500\u2500 public \u2502 \u251c\u2500\u2500 favicon.ico \u2502 \u251c\u2500\u2500 index.html \u2502 \u251c\u2500\u2500 logo192.png \u2502 \u251c\u2500\u2500 logo512.png \u2502 \u251c\u2500\u2500 manifest.json \u2502 \u2514\u2500\u2500 robots.txt \u2514\u2500\u2500 src \u251c\u2500\u2500 App.css \u251c\u2500\u2500 App.tsx \u251c\u2500\u2500 App.test.tsx \u251c\u2500\u2500 index.css \u251c\u2500\u2500 index.tsx \u251c\u2500\u2500 logo.svg \u251c\u2500\u2500 react-app-env.d.ts \u251c\u2500\u2500 reportWebVitals.ts \u2514\u2500\u2500 setupTests.js only the package.json , package-lock.json , tsconfig.json , .gitignore , react-app-env.d.ts , and index.html files matter at the moment, so you can delete or adapt the other files as you'd like.","title":"Frontend: Node"},{"location":"local-setup/frontend/#creating-a-react-app","text":"As with the backend we'll separate the frontend code into a frontend folder but we'll use the create react app tool to set everything up by running this command in the project directory, npx create-react-app frontend --template typescript which should give the following folder structure, tozo \u251c\u2500\u2500 backend \u2502 \u2514\u2500\u2500 ... \u2514\u2500\u2500 frontend \u251c\u2500\u2500 .gitignore \u251c\u2500\u2500 README.md \u251c\u2500\u2500 node_modules \u251c\u2500\u2500 package.json \u251c\u2500\u2500 package-lock.json \u251c\u2500\u2500 tsconfig.json \u251c\u2500\u2500 public \u2502 \u251c\u2500\u2500 favicon.ico \u2502 \u251c\u2500\u2500 index.html \u2502 \u251c\u2500\u2500 logo192.png \u2502 \u251c\u2500\u2500 logo512.png \u2502 \u251c\u2500\u2500 manifest.json \u2502 \u2514\u2500\u2500 robots.txt \u2514\u2500\u2500 src \u251c\u2500\u2500 App.css \u251c\u2500\u2500 App.tsx \u251c\u2500\u2500 App.test.tsx \u251c\u2500\u2500 index.css \u251c\u2500\u2500 index.tsx \u251c\u2500\u2500 logo.svg \u251c\u2500\u2500 react-app-env.d.ts \u251c\u2500\u2500 reportWebVitals.ts \u2514\u2500\u2500 setupTests.js only the package.json , package-lock.json , tsconfig.json , .gitignore , react-app-env.d.ts , and index.html files matter at the moment, so you can delete or adapt the other files as you'd like.","title":"Creating a React App"},{"location":"local-setup/git/","text":"If you've not done much development before (or maybe never developed in a team) it may not be clear why you'd need git or a version control system. I suspect though you are already using a version control system, which if you are like me is just renaming files e.g. main_old.py or main_v2.py . The problem is that your local system is unique to you and probably offers no tooling to make it easier or to share changes with others. git solves these issues and is the best version control system, as most modern tooling is built around it. Note git can be very confusing to use, and you may end up with your repository in a mess. It does get easier with practice and there is plenty of help online. You can always delete your local repository and start again from the remote version (as I have many times). You may already have git installed, try git --version to find out. If you don't lets install it now, brew install git which installed 2.29.2. Now you have git installed lets create a repository for all our code, First lets create a directory for our app, which we'll call tozo and within which run, git init . to create a git repository and by consequence add a .git to your project structure, tozo \u2514\u2500\u2500 .git that we can now ignore :). Clear atomic commits Crafting atomic and well reasoned commits from the start will save you a great deal of time in the future. I've written about this before.","title":"Git"},{"location":"local-setup/infrastructure-tooling/","text":"Unlike the frontend and backend code there is no tool to write scripts in, instead the direct terraform commands should be used. Formatting Terraform comes with an in-build formatter which can be invoked to autoformat your code, terraform fmt and to check if your code meets the formatting rules, terraform fmt --check = true Linting Terraform also comes with a tool to check your code, terraform validate Testing I currently don't know of a good technique to test the Terraform code, other than running terraform plan and checking the output makes sense.","title":"Infrastructure: Tooling"},{"location":"local-setup/infrastructure-tooling/#formatting","text":"Terraform comes with an in-build formatter which can be invoked to autoformat your code, terraform fmt and to check if your code meets the formatting rules, terraform fmt --check = true","title":"Formatting"},{"location":"local-setup/infrastructure-tooling/#linting","text":"Terraform also comes with a tool to check your code, terraform validate","title":"Linting"},{"location":"local-setup/infrastructure-tooling/#testing","text":"I currently don't know of a good technique to test the Terraform code, other than running terraform plan and checking the output makes sense.","title":"Testing"},{"location":"local-setup/infrastructure/","text":"The infrastructure will be controlled using Terraform , rather than via any GUI or direct CLI usage as this ensures that any changes to the infrastructure will be recorded in the repository and hence the infrastructure can be recreated at any time. To install Terraform, brew install terraform which installed 0.13.5. As with the frontend and backend we'll separate the infrastructure code into a infrastructure folder, tozo \u251c\u2500\u2500 backend \u2502 \u2514\u2500\u2500 ... \u251c\u2500\u2500 frontend \u2502 \u2514\u2500\u2500 ... \u2514\u2500\u2500 infrastructure Secrets management Terraform needs accress to, and the ability to store, secrets in order to correctly manage the infrastructure. Storing these secrets directly in the repository is a security risk as anyone who can access the repository has access to the secrets. To avoid this I use Ansible-vault to encrypt the secrets and Terraform's state. First lets install Ansible-vault using pip, (pip is available after you install Python), pip install ansible-vault which can be used to encrypt any files that contain secrets with only the encrypted files should be committed to the repository and shared with others. Ansible-vault requires a password/encryption-key to run, which you should keep safe and only share with people who need to use Terraform. We'll store this password in infrastructure/.ansible-vault and inform ansible it is stored there by adding the following to infrastructure/ansible.cg , [defaults] vault_password_file = .ansible-vault Terraform saves its state including secrets in terraform.tfstate and terraform.tfstate.backup so these will need to be encrypted. I also use a secrets.auto.tfvars file to store all the secrets used as variables in my Terraform scripts. This file is automatically read by Terraform whenever you issue a Terraform command. So it must also be encrypted, ansible-vault encrypt secrets.auto.tfvars --output = secrets.auto.tfvars.vault ansible-vault encrypt terraform.tfstate --output = terraform.tfstate.vault and to decrypt, ansible-vault decrypt secrets.auto.tfvars.vault --output = secrets.auto.tfvars ansible-vault decrypt terraform.tfstate.vault --output = terraform.tfstate For further protection and peace of mind I add the following to a .gitignore file in the infrastructure folder, .ansible-vault secrets.auto.tfvars terraform.tfstate *.backup .terraform.lock.hcl .terraform/ to ensure that I never accidentally commit these secrets to the repository.","title":"Infrastructure: Terraform"},{"location":"local-setup/infrastructure/#secrets-management","text":"Terraform needs accress to, and the ability to store, secrets in order to correctly manage the infrastructure. Storing these secrets directly in the repository is a security risk as anyone who can access the repository has access to the secrets. To avoid this I use Ansible-vault to encrypt the secrets and Terraform's state. First lets install Ansible-vault using pip, (pip is available after you install Python), pip install ansible-vault which can be used to encrypt any files that contain secrets with only the encrypted files should be committed to the repository and shared with others. Ansible-vault requires a password/encryption-key to run, which you should keep safe and only share with people who need to use Terraform. We'll store this password in infrastructure/.ansible-vault and inform ansible it is stored there by adding the following to infrastructure/ansible.cg , [defaults] vault_password_file = .ansible-vault Terraform saves its state including secrets in terraform.tfstate and terraform.tfstate.backup so these will need to be encrypted. I also use a secrets.auto.tfvars file to store all the secrets used as variables in my Terraform scripts. This file is automatically read by Terraform whenever you issue a Terraform command. So it must also be encrypted, ansible-vault encrypt secrets.auto.tfvars --output = secrets.auto.tfvars.vault ansible-vault encrypt terraform.tfstate --output = terraform.tfstate.vault and to decrypt, ansible-vault decrypt secrets.auto.tfvars.vault --output = secrets.auto.tfvars ansible-vault decrypt terraform.tfstate.vault --output = terraform.tfstate For further protection and peace of mind I add the following to a .gitignore file in the infrastructure folder, .ansible-vault secrets.auto.tfvars terraform.tfstate *.backup .terraform.lock.hcl .terraform/ to ensure that I never accidentally commit these secrets to the repository.","title":"Secrets management"},{"location":"remote-setup/aims/","text":"The aim of this chapter is to setup the remote tooling to continuously ensure that the main branch has no detectable errors and can therefore be deployed into production at any time, and to allow multiple developers to collabortate. CI Continuous Integration, CI, is the process of continually and quickly integrating changes to the main branch. To achieve this changes must be tested to ensure that they can be safely integrated, hence CI is often synonymous with linting and testing. Dependency checking Dependency checking is checking that the versions of the dependencies installed have no known (reported) security issues. This is something that I check in CI with the build failing, and hence requiring fixing if there are known issues.","title":"Remote setup aims"},{"location":"remote-setup/aims/#ci","text":"Continuous Integration, CI, is the process of continually and quickly integrating changes to the main branch. To achieve this changes must be tested to ensure that they can be safely integrated, hence CI is often synonymous with linting and testing.","title":"CI"},{"location":"remote-setup/aims/#dependency-checking","text":"Dependency checking is checking that the versions of the dependencies installed have no known (reported) security issues. This is something that I check in CI with the build failing, and hence requiring fixing if there are known issues.","title":"Dependency checking"},{"location":"remote-setup/backend-ci/","text":"As a reminder the commands to check the formatting, lint, and test are, poetry run format poetry run lint poetry run test To have these run as part of CI i.e. for every change to the remote repository the .gitlab-ci.yml file placed in the root of the repository should contain, backend-ci : image : python:3.9-alpine cache : key : poetry-cache paths : - backend/.venv before_script : - apk --update add alpine-sdk cargo gcc libffi-dev musl-dev postgresql-client - pip install poetry - poetry config virtualenvs.in-project true - cd backend - poetry install services : - postgres variables : POSTGRES_DB : tozo_test POSTGRES_USER : tozo POSTGRES_PASSWORD : tozo POSTGRES_HOST_AUTH_METHOD : \"trust\" script : - poetry run format - poetry run lint - poetry run test_ci only : changes : - backend/**/* - .gitlab-ci.yml The postgres service has been added to allow for testing against the database in CI. Security checks Warning The safety tool described in this section requires a license for commercial usage . It is good practice to regularly update any dependencies used, in order to get the latest security fixes and updates. Alongside this it helps to regularly check if there are known security issues, which can be done via the safety tool, safety check Safety can be run periodically using a Gitlab-CI schedule, by adding the following to the .gitlab-ci.yml file placed in the root of the repository, backend-audit : image : python:3.9-alpine before_script : - pip install safety script : - safety check only : - schedules which will run on the schedule defined in the ci setup .","title":"Backend CI"},{"location":"remote-setup/backend-ci/#security-checks","text":"Warning The safety tool described in this section requires a license for commercial usage . It is good practice to regularly update any dependencies used, in order to get the latest security fixes and updates. Alongside this it helps to regularly check if there are known security issues, which can be done via the safety tool, safety check Safety can be run periodically using a Gitlab-CI schedule, by adding the following to the .gitlab-ci.yml file placed in the root of the repository, backend-audit : image : python:3.9-alpine before_script : - pip install safety script : - safety check only : - schedules which will run on the schedule defined in the ci setup .","title":"Security checks"},{"location":"remote-setup/ci/","text":"CI, or continuous integration, is the process of merging code into a shared mainline version. For us this means merging our local changes into the remote repository after checking for errors. I aim for three checks in CI, the code is correctly formatted according to an autoformatter, the code is correctly structured, there are no syntax issues, and there isn't any unused code, the code passes all the tests. Which I'll refer to as the formatting, linting, and testing stages of CI. Activating CI resources We need compute resources to run these stages, so lets make use of Gitlab-CI's shared runners by adding shared_runners_enabled = true to the infrastructure/gitlab.tf file (note only the relevant resource is shown), resource \"gitlab_project\" \"tozo\" { ... shared_runners_enabled = true } with ... representing the existing code. This allows us to write a .gitlab-ci.yml file that runs CI jobs on every push to the remote repository master. It is also useful to schedule jobs e.g. the dependency checker, to run periodically via this addition to the infrastructure/gitlab.tf file, resource \"gitlab_pipeline_schedule\" \"tozo\" { project = gitlab_project.tozo.id description = \"Schedule checks against the codebase\" ref = \"main\" cron = \"0 9 1 * *\" } which will trigger the check at 9am on the 1st day of each month, see crontab guru for more. Remember Remember to re-run terraform apply and re-encrypt the state, ansible-vault encrypt terraform.tfstate --output = terraform.tfstate.vault after making changes to the infrastructure.","title":"CI"},{"location":"remote-setup/ci/#activating-ci-resources","text":"We need compute resources to run these stages, so lets make use of Gitlab-CI's shared runners by adding shared_runners_enabled = true to the infrastructure/gitlab.tf file (note only the relevant resource is shown), resource \"gitlab_project\" \"tozo\" { ... shared_runners_enabled = true } with ... representing the existing code. This allows us to write a .gitlab-ci.yml file that runs CI jobs on every push to the remote repository master. It is also useful to schedule jobs e.g. the dependency checker, to run periodically via this addition to the infrastructure/gitlab.tf file, resource \"gitlab_pipeline_schedule\" \"tozo\" { project = gitlab_project.tozo.id description = \"Schedule checks against the codebase\" ref = \"main\" cron = \"0 9 1 * *\" } which will trigger the check at 9am on the 1st day of each month, see crontab guru for more. Remember Remember to re-run terraform apply and re-encrypt the state, ansible-vault encrypt terraform.tfstate --output = terraform.tfstate.vault after making changes to the infrastructure.","title":"Activating CI resources"},{"location":"remote-setup/frontend-ci/","text":"As a reminder the commands to check the formatting, lint, and test are, npm run format npm run lint npm run test In addition it is helpful to try to build the frontend as part of the CI, so as to ensure it can be built with the changes. This can be done via, npm run build To have these run as part of CI i.e. for every change to the remote repository the .gitlab-ci.yml file placed in the root of the repository should contain, frontend-ci : image : node:15-alpine cache : key : node-cache paths : - frontend/node_modules/ - frontend/.npm/ before_script : - cd frontend - npm ci --cache .npm --prefer-offline script : - npm run format - npm run lint - npm run test - npm run build only : changes : - frontend/**/* - .gitlab-ci.yml Security checks It is good practice to regularly update any dependencies used, in order to get the latest security fixes and updates. Alongside this it helps to regularly check if there are known security issues, which can be done via the audit command, npm audit This can be run periodically using a Gitlab-CI schedule, by adding the following to the .gitlab-ci.yml file placed in the root of the repository, audit-check : image : node:15-alpine cache : key : node-cache paths : - frontend/node_modules/ - frontend/.npm/ before_script : - cd frontend - npm ci --cache .npm --prefer-offline script : - npm audit only : - schedules which will run on the schedule defined in the ci setup .","title":"Frontend CI"},{"location":"remote-setup/frontend-ci/#security-checks","text":"It is good practice to regularly update any dependencies used, in order to get the latest security fixes and updates. Alongside this it helps to regularly check if there are known security issues, which can be done via the audit command, npm audit This can be run periodically using a Gitlab-CI schedule, by adding the following to the .gitlab-ci.yml file placed in the root of the repository, audit-check : image : node:15-alpine cache : key : node-cache paths : - frontend/node_modules/ - frontend/.npm/ before_script : - cd frontend - npm ci --cache .npm --prefer-offline script : - npm audit only : - schedules which will run on the schedule defined in the ci setup .","title":"Security checks"},{"location":"remote-setup/infrastructure-ci/","text":"As a reminder the commands to check the formatting and lint are, terraform fmt --check = true terraform validate To have these run as part of CI i.e. for every change to the remote repository a .gitlab-ci.yml file placed in the root of the repository should contain, infrastructure-ci : image : alpine:latest before_script : - apk update - apk add terraform - cd infrastructure - terraform init script : - terraform fmt --check=true - terraform validate only : changes : - infrastructure/**/* - .gitlab-ci.yml","title":"Infrastructure CI"},{"location":"remote-setup/repository/","text":"A remote repository acts as a backup for all your code and makes it much easier to setup continuous integration, CI (testing, linting etc). We'll use gitlab , although you could also use github. Rather than creating the repository through gitlab's UI we'll use Terraform as setup previously . To do so we'll first need an access token . This token is a secret, and hence best placed in the infrastructure/secrets.auto.tfvars as so, gitlab_token = \"abc1234\" We can then instruct terraform to use the gitlab provider to create a gitlab project, called tozo (change as appropriate ), by adding the following to infrastructure/main.tf , terraform { required_providers { gitlab = { source = \"gitlabhq/gitlab\" version = \">=3.3.0\" } } required_version = \">=0.14\" } to configure terraform with gitlab, and then the following to infrastructure/gitlab.tf , variable \"gitlab_token\" { sensitive = true } provider \"gitlab\" { token = var.gitlab_token } resource \"gitlab_project\" \"tozo\" { name = \"tozo\" visibility_level = \"private\" default_branch = \"main\" } which you can then apply via following commands, terraform init terraform apply Committing and pushing Now we've run these commands we should encrypt the secrets and state as both have now changed, ansible-vault encrypt secrets.auto.tfvars --output = secrets.auto.tfvars.vault ansible-vault encrypt terraform.tfstate --output = terraform.tfstate.vault which should result in these useful files in the repository, tozo \u251c\u2500\u2500 backend \u251c\u2500\u2500 frontend \u2514\u2500\u2500 infrastructure \u251c\u2500\u2500 .gitignore \u251c\u2500\u2500 ansible.cfg \u251c\u2500\u2500 gitlab.tf \u251c\u2500\u2500 main.tf \u251c\u2500\u2500 secrets.auto.tfvars \u251c\u2500\u2500 secrets.auto.tfvars.vault \u251c\u2500\u2500 terraform.tfstate \u2514\u2500\u2500 terraform.tfstate.vault so lets commit those (excluding secrets.auto.tfvars and terraform.tfstate ) and push to the remote (with your namespace and project names), git remote add origin git@gitlab.com:namespace/tozo git push origin main","title":"Repository"},{"location":"remote-setup/repository/#committing-and-pushing","text":"Now we've run these commands we should encrypt the secrets and state as both have now changed, ansible-vault encrypt secrets.auto.tfvars --output = secrets.auto.tfvars.vault ansible-vault encrypt terraform.tfstate --output = terraform.tfstate.vault which should result in these useful files in the repository, tozo \u251c\u2500\u2500 backend \u251c\u2500\u2500 frontend \u2514\u2500\u2500 infrastructure \u251c\u2500\u2500 .gitignore \u251c\u2500\u2500 ansible.cfg \u251c\u2500\u2500 gitlab.tf \u251c\u2500\u2500 main.tf \u251c\u2500\u2500 secrets.auto.tfvars \u251c\u2500\u2500 secrets.auto.tfvars.vault \u251c\u2500\u2500 terraform.tfstate \u2514\u2500\u2500 terraform.tfstate.vault so lets commit those (excluding secrets.auto.tfvars and terraform.tfstate ) and push to the remote (with your namespace and project names), git remote add origin git@gitlab.com:namespace/tozo git push origin main","title":"Committing and pushing"}]}